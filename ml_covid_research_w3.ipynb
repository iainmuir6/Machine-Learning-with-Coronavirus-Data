{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 4993 Independent Study – Machine Learning with COVID Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Professor: [Haiyang Shen](https://engineering.virginia.edu/faculty/haiying-shen)***  \n",
    "***Researcher: [Iain Muir](https://www.linkedin.com/in/iain-muir-b37718164/) | iam9ez***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Github Project:* https://github.com/iainmuir6/machineLearning_covidData  \n",
    "*Last Updated: June 14th, 2021*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*References*\n",
    "* [CS 4774 ML Material – Professor Rich Nguyen](https://www.cs.virginia.edu/~nn4pj/teaching)\n",
    "* [Steps to Building Machine Learning Model](https://analyticsindiamag.com/the-7-key-steps-to-build-your-machine-learning-model/)\n",
    "* [Steps to Data Preprocessing](https://hackernoon.com/what-steps-should-one-take-while-doing-data-preprocessing-502c993e1caa)\n",
    "* [Handling Missing Values](https://towardsdatascience.com/7-ways-to-handle-missing-values-in-machine-learning-1a6326adf79e)\n",
    "* [Feature Selection I](https://towardsdatascience.com/the-5-feature-selection-algorithms-every-data-scientist-need-to-know-3a6b566efd2)\n",
    "* [Feature Selection II](https://machinelearningmastery.com/feature-selection-machine-learning-python/)\n",
    "* [Keras Neural Network I](https://towardsdatascience.com/3-ways-to-create-a-machine-learning-model-with-keras-and-tensorflow-2-0-de09323af4d3)\n",
    "* [GAN Github Repository – codyznash](https://github.com/codyznash/GANs_for_Credit_Card_Data/blob/7f7e2dfb6ab15eb0d520fa6611fe03d6f8646141/GAN_171103.py#L47)\n",
    "* [GAN I](https://datasciencecampus.ons.gov.uk/projects/generative-adversarial-networks-gans-for-synthetic-dataset-generation-with-binary-classes/)\n",
    "* [GAN II](https://nbviewer.jupyter.org/github/codyznash/GANs_for_Credit_Card_Data/blob/master/GAN_comparisons.ipynb#Generated%20Data%20Testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents <a class=\"anchor\" id=\"toc\"></a>\n",
    "* **[0. Import Packages](#setup)**\n",
    "    * [0.1 General Imports](#imp1)\n",
    "    * [0.2 ML Imports](#imp2)\n",
    "* **[1. Read Excel File](#data)**\n",
    "    * [1.1 Data Overview](#overview)\n",
    "    * [1.2 Descriptive Statistics](#stats)\n",
    "    * [1.3 Inspect Null Data](#null)\n",
    "* **[2. Data Preparation](#prep)**\n",
    "    * [2.1 Drop Columns](#drop)\n",
    "    * [2.2 Handle Categorical Variables](#handle1)\n",
    "        * *[2.2.1 Manual Conversion](#manual)*\n",
    "        * *[2.2.2 Encoding](#encoding)*\n",
    "        * *[2.2.3 Categorical Codes](#codes)*\n",
    "    * [2.3 Handle Missing Values](#handle2)\n",
    "    * [2.4 Feature Scaling](#scaling)\n",
    "    * [2.5 Train / Test Split](#split)\n",
    "    * [2.6 Final Prepared Data](#final_data)\n",
    "* **[3. Feature Selection I](#feature)**\n",
    "    * [3.1 Pearson Correlation](#corr)\n",
    "    * [3.2 Chi-Squared Test](#chi_sq)\n",
    "    * [3.3 Recursive Feature Elimination](#rfe)\n",
    "    * [3.4 SelectFromModel: Lasso](#lasso)\n",
    "    * [3.5 SelectFromModel: Random Forest Classifier](#rfc)\n",
    "    * [3.6 Cumulative Feature Selection](#cum)\n",
    "* **[4. Model Selection](#model)**\n",
    "    * [4.1 Train / Test Data](#tt)\n",
    "    * [4.2 Model Evaluation Functions](#funcs)\n",
    "    * [4.3 Model Construction](#models)\n",
    "        * *[4.3.1 Decision Tree](#dt)*\n",
    "        * *[4.3.2 Random Forest Classifier](#rfc2)*\n",
    "        * *[4.3.3 Simple Deep Neural Network](#dnn)*\n",
    "        * *[4.3.4 Convolutional Neural Network](#cnn)*\n",
    "    * [4.4 Simultaneous Model Evaluation](#eval)\n",
    "    * [4.5 RandomizedSearch](#search)\n",
    "* **[5. Generative Adverserial Networks](#gan)**\n",
    "    * [5.1 Network Setup](#setup2)\n",
    "    * [5.2 Training GAN Models](#train)\n",
    "        * [5.2.1 GAN](#gan2)\n",
    "        * [5.2.2 CGAN](#cgan)\n",
    "        * [5.2.3 WGAN + WCGAN](#wgan)\n",
    "    * [5.3 Loss Information](#loss)\n",
    "    * [5.4 Generate New Data](#new_data)\n",
    "    * [5.5 Training Models on New Data](#train_gan)\n",
    "    * [5.6 Plot Real vs Test Data](#plot)\n",
    "    * [5.7 Feature Importance](#importance)\n",
    "* **[6. Retrain Models with GAN Data](#retrain)**\n",
    "    * [6.1 Re-Prepare Data](#prep2)\n",
    "    * [6.2 Re-Train Models](#retrain2)\n",
    "* **[7. Final Model Training with Feature Selection](#final)**\n",
    "    * [7.1 Define Models and Variables](#define)\n",
    "    * [7.2 Model Performance w/o GAN](#perf1)\n",
    "    * [7.3 Model Performance with GAN](#perf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 0. Import Packages <a class=\"anchor\" id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1 General Imports <a class=\"anchor\" id=\"imp1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, Image, display\n",
    "from scipy.stats import reciprocal\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2 ML Imports <a class=\"anchor\" id=\"imp2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE, SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals.six import StringIO\n",
    "import pydotplus\n",
    "import sklearn\n",
    "\n",
    "from keras.layers import Dense, InputLayer, Dropout, Conv2D, MaxPooling2D, Flatten, Embedding, LSTM\n",
    "from keras.layers import LeakyReLU, PReLU, BatchNormalization, Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow import keras\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import xgboost as xgb\n",
    "from GAN import GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.2'"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read Excel File <a class=\"anchor\" id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Data Overview <a class=\"anchor\" id=\"overview\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/xlrd/sheet.py\u001b[0m in \u001b[0;36mput_cell_unragged\u001b[0;34m(self, rowx, colx, ctype, value, xf_index)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cell_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrowx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cell_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrowx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-343-6ecb37385328>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ed_pred.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, engine)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mformatting_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatting_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mon_demand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_demand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 \u001b[0mragged_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mragged_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             )\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/xlrd/xlsx.py\u001b[0m in \u001b[0;36mopen_workbook_2007_xml\u001b[0;34m(zf, component_names, logfile, verbosity, use_mmap, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0mx12sheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX12Sheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0mheading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Sheet %r (sheetx=%d) from %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheetx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mx12sheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzflo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mzflo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/xlrd/xlsx.py\u001b[0m in \u001b[0;36mown_process_stream\u001b[0;34m(self, stream, heading)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow_tag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m                 \u001b[0mself_do_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m                 \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# destroy all child elements (cells)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mU_SSML12\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"dimension\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/xlrd/xlsx.py\u001b[0m in \u001b[0;36mdo_row\u001b[0;34m(self, row_elem)\u001b[0m\n\u001b[1;32m    690\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXL_CELL_BLANK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxf_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxf_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mcell_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"s\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0;31m# s = index into shared string table. 2nd most frequent type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/xlrd/sheet.py\u001b[0m in \u001b[0;36mput_cell_unragged\u001b[0;34m(self, rowx, colx, ctype, value, xf_index)\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mnc\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutter_max_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mnr\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutter_max_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;31m# The row self._first_full_rowx and all subsequent rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "df = pd.read_excel('ed_pred.xlsx')\n",
    "df = df.reset_index()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'COVIDResult'\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Column Description\n",
    "Note (src - [Walk-In-Lab](https://www.walkinlab.com/products/view/complete-blood-count-cbc-comprehensive-metabolic-panel-cmp-14-blood-test-panel#:~:text=A%20CBC%20also%20helps%20your,anemia%2C%20and%20several%20other%20disorders.&text=Comprehensive%20Metabolic%20Panel%20)): \n",
    "\n",
    "CBC == [Complete Blood Count](https://www.mayoclinic.org/tests-procedures/complete-blood-count/about/pac-20384919)\n",
    "* Complete Blood Count (CBC) gives important information about the numbers and kinds of cells in the blood, especially red blood cells, white blood cells, and platelets. A CBC helps your health professional check any symptoms, such as fatigue, weakness, or bruising, that you may have. A CBC also helps your health professional diagnose conditions, such as infection, anemia, and several other disorders.\n",
    "\n",
    "CMP == [Comprehensive Metabolic Panel](https://www.mayocliniclabs.com/test-catalog/Clinical+and+Interpretive/113631)\n",
    "* Comprehensive Metabolic Panel (CMP-14) with eGFR is a group of 14 laboratory tests ordered to give information about the current status of your liver, kidneys, and electrolyte and acid/base balance.  The test gives the current status of your blood sugar and blood proteins also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Descriptive Statistics <a class=\"anchor\" id=\"stats\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df[target].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "none_detected_dups = sum(df.loc[df[target]=='None Detected'].duplicated())\n",
    "detected_dups = sum(df.loc[df[target]=='Detected'].duplicated())\n",
    "total_dups = none_detected_dups + detected_dups\n",
    "\n",
    "print('None Detected Duplicates:', none_detected_dups)\n",
    "print('Detected Duplicates:', detected_dups)\n",
    "print('Total Duplicates:', total_dups)\n",
    "print('Fraction Duplicated:', total_dups / len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Inspect Null Data <a class=\"anchor\" id=\"null\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Total Number of NULL Data Points:', df.isnull().sum().sum())\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = {\n",
    "    col: round(df[col].isnull().sum() * 100 / len(df[col]), 4)\n",
    "    for col in df\n",
    "}\n",
    "d = dict(sorted(d.items(), key=lambda item: item[1], reverse=True))\n",
    "majority_null = [k for k, v in d.items() if v > 50.0]\n",
    "\n",
    "print(\"Null Data Points by variable\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "msno.matrix(df)\n",
    "# msno.heatmap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation <a class=\"anchor\" id=\"prep\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Drop Columns <a class=\"anchor\" id=\"drop\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if drop:\n",
    "    trim_df = df.drop(columns=majority_null)\n",
    "    trim_df = trim_df.drop(columns=['index', 'patno'])\n",
    "    trim_df.head(5)\n",
    "else:\n",
    "    trim_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Handle Categorical Variables <a class=\"anchor\" id=\"handle1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.2.1 Manual Conversion <a class=\"anchor\" id=\"manual\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_cat_cols = [\n",
    "    'cmp_bicarbonate', 'cmp_bun', 'cmp_creatinine', 'cmp_alt', 'cmp_bilirubin'\n",
    "]\n",
    "less_than_list = [\n",
    "    '<5', '<2', '<0.2', '<6', '<0.1'\n",
    "]\n",
    "\n",
    "\n",
    "def replace_cat(val, less, num):\n",
    "    if val == less:\n",
    "        return random.uniform(0, num) if \".\" in less else random.randint(0, num)\n",
    "    else:\n",
    "        return float(val)\n",
    "\n",
    "    \n",
    "trim_df2 = trim_df.copy()\n",
    "for col, less_than in zip(num_cat_cols, less_than_list):\n",
    "    upper_range = float(less_than[1:])\n",
    "    trim_df2[col] = trim_df2[col].apply(lambda x: replace_cat(x, less_than, upper_range))\n",
    "\n",
    "trim_df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trim_df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.2.2 Encoding <a class=\"anchor\" id=\"encoding\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = list(trim_df2.select_dtypes(include=['object']).columns)\n",
    "\n",
    "trim_df3 = trim_df2.copy()\n",
    "trim_df3['FirstRace'] = trim_df3['FirstRace'].fillna(\"Unspecified\")\n",
    "if not drop:\n",
    "    trim_df3['AdmittingDepartment'] = trim_df3['AdmittingDepartment'].fillna('N/A')\n",
    "for col in cat_cols:\n",
    "    enc = OrdinalEncoder()\n",
    "    y = enc.fit_transform(trim_df3[[col]])\n",
    "    if col == 'COVIDResult':\n",
    "        y = 1 - y\n",
    "    trim_df3[col + \"_Encoded\"] = y\n",
    "trim_df3.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.2.3 Categorical Codes <a class=\"anchor\" id=\"codes\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    if col == 'AdmittingDepartment':\n",
    "        continue\n",
    "    display(Markdown(\"**{}**\".format(col)))\n",
    "    for each in trim_df3.groupby([col, col + '_Encoded']).indices:\n",
    "        print(each)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trim_df3 = trim_df3.drop(columns=cat_cols)\n",
    "trim_df3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trim_df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Handle Missing Values <a class=\"anchor\" id=\"handle2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_option = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_cols = list(trim_df2.select_dtypes(include=['float64']).columns)\n",
    "\n",
    "trim_df4 = trim_df3.copy()\n",
    "for col in num_cols:\n",
    "    if fill_option == 'A':\n",
    "        trim_df4[col] = trim_df4[col].fillna(0)\n",
    "    else:\n",
    "        trim_df4[col] = trim_df4[col].replace(np.NaN, trim_df4[col].mean())\n",
    "    \n",
    "trim_df4.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_df3.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_df4.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Feature Scaling <a class=\"anchor\" id=\"scaling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_cols = [\n",
    "    'Admitted', 'FirstRace_Encoded', 'Ethnicity_Encoded', 'Sex_Encoded',\n",
    "    'AdmittingDepartment_Encoded', 'COVIDResult_Encoded'\n",
    "]\n",
    "\n",
    "if drop:\n",
    "    code_cols.remove('AdmittingDepartment_Encoded')\n",
    "\n",
    "codes_df = trim_df4[code_cols]\n",
    "trim_df5 = trim_df4.drop(columns=code_cols)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(trim_df5)\n",
    "scaled_df = pd.DataFrame(data=scaled, columns=trim_df5.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df = pd.concat([scaled_df, codes_df], axis=1)\n",
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Train / Test Split <a class=\"anchor\" id=\"split\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(merged_df, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Final Prepared Data <a class=\"anchor\" id=\"final_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = merged_df.copy()\n",
    "final_train = train.copy()\n",
    "final_test = test.copy()\n",
    "target = 'COVIDResult_Encoded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_train[target].value_counts())\n",
    "print(final_test[target].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection <a class=\"anchor\" id=\"feature\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_data.loc[:, final_data.columns != target]\n",
    "pos_X = trim_df4.loc[:, trim_df4.columns != target]\n",
    "X_norm = MinMaxScaler().fit_transform(pos_X)\n",
    "Y = final_data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Number of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_feats = len(X.columns)\n",
    "# top_n_feats = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(scores, selector):\n",
    "    plt.bar(range(len(scores)), scores, color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Pearson Correlation <a class=\"anchor\" id=\"corr\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_selector(x, y):\n",
    "    correl_dict = {\n",
    "        col: np.corrcoef(x[col], y)[0, 1] for col in x.columns.tolist()\n",
    "    }\n",
    "    correl_dict = {\n",
    "        col: 0 if np.isnan(cor) else np.abs(cor) for col, cor in correl_dict.items()\n",
    "    }\n",
    "    plot_scores(list(correl_dict.values()), 'correlation')\n",
    "    \n",
    "    correl_dict = dict(sorted(correl_dict.items(), key=lambda item: item[1], reverse=True)[:top_n_feats])\n",
    "    top_n = np.array([\n",
    "        True if col in list(correl_dict.keys()) else False for col in x.columns.tolist()\n",
    "    ])\n",
    "    return top_n\n",
    "\n",
    "\n",
    "corr_top_n = correlation_selector(X, Y)\n",
    "corr_top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Chi-Squared <a class=\"anchor\" id=\"chi_sq\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_selector(y):\n",
    "    chi_sq = SelectKBest(chi2, k=top_n_feats)\n",
    "    chi_sq.fit(X_norm, y)\n",
    "    top_n = chi_sq.get_support()\n",
    "    plot_scores(chi_sq.scores_, 'chi-squared')\n",
    "    return top_n\n",
    "\n",
    "\n",
    "chi_top_n = chi_selector(Y)\n",
    "chi_top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Recursive Feature Elimination <a class=\"anchor\" id=\"rfe\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_selector(y):\n",
    "    rfe = RFE(estimator=LogisticRegression(), n_features_to_select=top_n_feats, step=10, verbose=0)\n",
    "    rfe.fit(X_norm, y)\n",
    "    top_n = rfe.get_support()\n",
    "    return top_n\n",
    "\n",
    "\n",
    "rfe_top_n = rfe_selector(Y)\n",
    "rfe_top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Lasso: SelectFromModel <a class=\"anchor\" id=\"lasso\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_selector(y):\n",
    "    lasso = SelectFromModel(LogisticRegression(penalty=\"l2\"), max_features=top_n_feats)\n",
    "    lasso.fit(X_norm, y)\n",
    "    top_n = lasso.get_support()\n",
    "    return top_n\n",
    "\n",
    "\n",
    "lasso_top_n = lasso_selector(Y)\n",
    "lasso_top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 RandomForestClassifier: SelectFromModel <a class=\"anchor\" id=\"rfc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc_selector(x, y):\n",
    "    rfc = SelectFromModel(RandomForestClassifier(n_estimators=100), max_features=top_n_feats)\n",
    "    rfc.fit(x, y)\n",
    "    top_n = rfc.get_support()\n",
    "    return top_n\n",
    "\n",
    "\n",
    "rfc_top_n = rfc_selector(X, Y)\n",
    "rfc_top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Cumulative Feature Selection <a class=\"anchor\" id=\"cum\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cumm_df = pd.DataFrame({\n",
    "    'feature': X.columns.tolist(),\n",
    "    'correlation': corr_top_n,\n",
    "    'chi-sq': chi_top_n,\n",
    "    'rfe': rfe_top_n,\n",
    "    'lasso': lasso_top_n,\n",
    "    'rfc': rfc_top_n\n",
    "})\n",
    "cumm_df['total'] = np.sum(cumm_df, axis=1)\n",
    "cumm_df = cumm_df.sort_values(['total', 'feature'], ascending=False)\n",
    "cumm_df.index = range(1, len(cumm_df) + 1)\n",
    "cumm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_n_features = list(cumm_df.iloc[:top_n_feats]['feature'])\n",
    "top_n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Selection <a class=\"anchor\" id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Train / Test Data <a class=\"anchor\" id=\"tt\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = final_train[top_n_features]\n",
    "y_train = final_train[target]\n",
    "X_test = final_test[top_n_features]\n",
    "y_test = final_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train', X_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print()\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Model Evaluation Functions <a class=\"anchor\" id=\"funcs\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(hist, metric):\n",
    "    train_metrics = hist.history[metric]\n",
    "    val_metrics = hist.history['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and Validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(hist):\n",
    "    display(Markdown('**Training/Validation Loss and Accuracy**'))\n",
    "    pd.DataFrame(hist.history).plot(figsize=(8,5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_evaluation(y_test, y_pred, labels=True):\n",
    "    if labels:\n",
    "        display(Markdown('**Metric Scores**'))\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "    print(\"Precision: {:.2f}%\".format(precision_score(y_test, y_pred) * 100))\n",
    "    print(\"Recall: {:.2f}%\".format(recall_score(y_test, y_pred) * 100))\n",
    "    print(\"F1: {:.2f}%\".format(f1_score(y_test, y_pred) * 100))\n",
    "    if labels:\n",
    "        display(Markdown('**Confusion Matrix**'))\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_pred, labels=['None Detected', 'Detected']):\n",
    "    cm_df = pd.DataFrame(\n",
    "        confusion_matrix(y_test, y_pred), columns=labels, index=labels\n",
    "    )\n",
    "    ax = sns.heatmap(\n",
    "        data=cm_df, cmap=cm.Blues, annot=True, fmt='d'\n",
    "    )\n",
    "    ax.set(xlabel='Predicted', ylabel='Actual')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 200\n",
    "VAL_SPLIT = 0.2\n",
    "X_train, y_train, X_test, y_test = xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(models, xy, isolate=None):\n",
    "    X_train, y_train, X_test, y_test = xy\n",
    "    X_train = np.array(X_train.values.tolist())\n",
    "    y_train = np.array(y_train)\n",
    "    for i, m in enumerate(models):\n",
    "        name, model, loss, optimizer, binary = m.values()\n",
    "        if isolate is not None and i + 1 != isolate:\n",
    "            print('Skipping Model {}...'.format(i + 1))\n",
    "            continue\n",
    "        \n",
    "        display(Markdown('### Model {} – {}'.format(i + 1, name)))\n",
    "        \n",
    "        # 1. Compile\n",
    "        model.compile(\n",
    "            loss=loss, optimizer=optimizer, metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # 2. Fit\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=VAL_SPLIT, shuffle=True, verbose=0\n",
    "        )\n",
    "        \n",
    "        # 3. Visualize Model\n",
    "        display(Markdown(\"**Summary**\"))\n",
    "        model.summary()\n",
    "        plot_history(history)\n",
    "        \n",
    "        # 4. Evaluate\n",
    "        display(Markdown(\"**Evaluation and Prediction**\"))\n",
    "        loss, accuracy = model.evaluate(x=X_test, y=y_test)\n",
    "        print(\"\\nLoss: {:.2f}%\".format(loss * 100))\n",
    "        print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "        \n",
    "        # 5. Predict\n",
    "        y_prediction_array = model.predict(X_test)\n",
    "        \n",
    "        if not binary:\n",
    "            y_prediction = np.argmax(y_prediction_array, axis=1)\n",
    "        else:\n",
    "            y_prediction = np.round(y_prediction_array)\n",
    "        \n",
    "        # 6. Visualize Predictions\n",
    "        metric_evaluation(y_test, y_prediction)\n",
    "        plot_confusion_matrix(y_test, y_prediction)\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Model Construction <a class=\"anchor\" id=\"models\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')\n",
    "tf.set_random_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.3.1 Decision Trees <a class=\"anchor\" id=\"dt\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(\n",
    "    max_depth=4, criterion=\"entropy\", random_state=SEED\n",
    ")\n",
    "dt = dt.fit(X_train, y_train)\n",
    "y_prediction = dt.predict(X_test)\n",
    "metric_evaluation(y_test, y_prediction)\n",
    "plot_confusion_matrix(y_test, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(dt, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True, feature_names=top_n_features, class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "# graph.write_png('rfc.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.3.2 Random Forest Classifier <a class=\"anchor\" id=\"rfc2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "    n_estimators=100, bootstrap=True, max_features='sqrt', random_state=SEED\n",
    ")\n",
    "rfc.fit(X_train, y_train)\n",
    "y_prediction = rfc.predict(X_test)\n",
    "metric_evaluation(y_test, y_prediction)\n",
    "plot_confusion_matrix(y_test, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(rfc.feature_importances_,index=top_n_features).sort_values(ascending=False).iloc[:10]\n",
    "sns.barplot(x=feature_importance, y=feature_importance.index)\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.3.3 Simple Deep Neural Network <a class=\"anchor\" id=\"dnn\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = Sequential([\n",
    "    Dense(top_n_feats//2, activation='relu', input_shape=(top_n_feats,)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_models([\n",
    "    {'name': 'Simple Deep Neural Network', 'model': dnn,\n",
    "     'loss': 'sparse_categorical_crossentropy', 'optimizer': RMSprop(learning_rate=1e-2), 'binary': False}\n",
    "], (X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.3.4 Convolutional Neural Network <a class=\"anchor\" id=\"cnn\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn = Sequential([\n",
    "#     Conv2D(32, kernel_size=(3, 3), activation='linear', input_shape=(top_n_feats,0,0), padding='same'),\n",
    "#     LeakyReLU(alpha=0.1),\n",
    "#     MaxPooling2D((2, 2), padding='same'),\n",
    "#     Conv2D(64, (3, 3), activation='linear',padding='same'),\n",
    "#     LeakyReLU(alpha=0.1),\n",
    "#     MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "#     Conv2D(128, (3, 3), activation='linear',padding='same'),\n",
    "#     LeakyReLU(alpha=0.1),\n",
    "#     MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "#     Flatten(),\n",
    "#     Dense(128, activation='linear'),\n",
    "#     LeakyReLU(alpha=0.1),\n",
    "#     Dense(2, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lst = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Retired Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLPs are more linear...\n",
    "mlp1 = Sequential([\n",
    "    Dense(12, input_dim=top_n_feats, kernel_initializer='uniform', activation='relu'),\n",
    "    Dense(8, kernel_initializer='uniform', activation='relu'),\n",
    "    Dense(1, kernel_initializer='uniform', activation='sigmoid')\n",
    "])\n",
    "mlp2 = Sequential([\n",
    "    Dense(top_n_feats, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "mlp3 = Sequential([\n",
    "    Dense(64,activation='relu',input_dim=X_train.shape[1]),\n",
    "    Dense(1)\n",
    "])\n",
    "seq = Sequential([\n",
    "    Dense(top_n_feats, activation='relu'),\n",
    "    Dense(6, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# RNNs are more for Time-Series Data\n",
    "rnn = Sequential([\n",
    "    Embedding(len(X_train) + 1, 64),\n",
    "    LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "#model_lst = [\n",
    "#     {'name': 'MLP: Binary Classification', 'model': mlp1,\n",
    "#      'loss': 'binary_crossentropy', 'optimizer': Adam(learning_rate=1e-2), 'binary': True},\n",
    "#     {'name': 'MLP: Multi-Class Classification', 'model': mlp2,\n",
    "#      'loss': 'sparse_categorical_crossentropy', 'optimizer': RMSprop(learning_rate=1e-2), 'binary': False},\n",
    "#     {'name': 'MLP: Regression', 'model': mlp3,\n",
    "#      'loss': 'mse', 'optimizer': RMSprop(learning_rate=1e-2), 'binary': False},\n",
    "#     {'name': 'Sequential: Dense Layers, ReLU Activation', 'model': seq,\n",
    "#      'loss': 'sparse_categorical_crossentropy', 'optimizer': Adam(learning_rate=1e-2), 'binary': False},\n",
    "#     {'name': 'Convolutional Neural Network', 'model': cnn,\n",
    "#      'loss': 'sparse_categorical_crossentropy', 'optimizer': RMSprop(learning_rate=1e-4, decay=1e-6), 'binary': False},\n",
    "#     {'name': 'Recurrent Neural Network', 'model': rnn,\n",
    "#      'loss': 'binary_crossentropy', 'optimizer': Adam(learning_rate=1e-4), 'binary': True},\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Simultaneous Model Evaluation <a class=\"anchor\" id=\"eval\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_models(model_lst, (X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Randomized Search <a class=\"anchor\" id=\"search\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[top_n_feats]):\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=input_shape)\n",
    "    ])\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'n_hidden': [0, 1, 2, 3],\n",
    "    'n_neurons': np.arange(1, 100),\n",
    "    'learning_rate': reciprocal(3e-4, 3e-2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg, hyperparameters, n_iter=10, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if run:\n",
    "    rnd_search_cv.fit(\n",
    "        X_train, y_train, epochs=EPOCHS, validation_split=VAL_SPLIT, callbacks=[EarlyStopping(patience=10)], verbose=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnd_search_results(rscv):\n",
    "    global final_top_x_models\n",
    "    \n",
    "    # 1. Best Model Params\n",
    "    display(Markdown(\"**Best Parameters**\"))\n",
    "    best_params = rscv.best_params_\n",
    "    for k, v in best_params:\n",
    "        print(k + \":\", v)\n",
    "    print(\"Best Score: {}\".format(rscv.best_score_))\n",
    "    \n",
    "    # 2. CV Results\n",
    "    cv_results = pd.DataFrame(rnd_search_cv.cv_results_)\n",
    "    print(cv_results)\n",
    "    \n",
    "    # 3. Top X\n",
    "    top_x = 3\n",
    "    top_x_models = cv_results.loc[cv_results['rank_test_score'].isin(range(1, top_x+1))].sort_values(\n",
    "        by=['rank_test_score']\n",
    "    )\n",
    "    final_top_x_models = top_x_models.reset_index()\n",
    "    print(final_top_x_models)\n",
    "    \n",
    "    # 4. Best!\n",
    "    print(cv_results.iloc[rnd_search_cv.best_index_])\n",
    "\n",
    "    \n",
    "if run:\n",
    "    rnd_search_results(rnd_search_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(n_hidden, n_neurons):\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=[top_n_feats])\n",
    "    ])\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_models_list = [{\n",
    "#     'name': 'Randomized Search: #{} Model'.format(idx + 1),\n",
    "#     'model': build_model2(n_hidden=model['param_n_hidden'], n_neurons=model['param_n_neurons']),\n",
    "#     'loss': 'sparse_categorical_crossentropy',\n",
    "#     'optimizer': SGD(learning_rate=model['param_learning_rate'])\n",
    "# } for idx, model in final_top_x_models.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_models(best_models_list, (X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generative Adverserial Networks (GAN) <a class=\"anchor\" id=\"gan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Network Setup <a class=\"anchor\" id=\"setup2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND_DIM = 32\n",
    "NB_STEPS = 500 + 1\n",
    "BASE_N_COUNT = 128\n",
    "BATCH_SIZE = 128\n",
    "NUM_UPDATES_D = 1         # number of critic network updates per adversarial training step\n",
    "NUM_UPDATES_G = 1         # number of generator network updates per adversarial training step\n",
    "NUM_PRE_TRAIN_STEPS = 100 # number of steps to pre-train the critic before starting adversarial training\n",
    "LOG_INTERVAL = 100        # interval (in steps) at which to log loss summaries and save plots of image samples to disc\n",
    "LEARNING_RATE = 5e-4 \n",
    "DIRECTORY = 'GAN/outputs/'\n",
    "SHOW = True\n",
    "generator_model_path, discriminator_model_path, loss_pickle_path = None, None, None\n",
    "\n",
    "arguments = [\n",
    "    RAND_DIM, NB_STEPS, BATCH_SIZE, NUM_UPDATES_D, NUM_UPDATES_G, NUM_PRE_TRAIN_STEPS, LOG_INTERVAL,\n",
    "    LEARNING_RATE, BASE_N_COUNT, DIRECTORY, generator_model_path, discriminator_model_path, loss_pickle_path, SHOW\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'COVIDResult_Encoded'\n",
    "if all_data:\n",
    "    train = final_data.copy()\n",
    "else:\n",
    "    all_detected = final_data.loc[final_data[target] == 1]\n",
    "    train = all_detected.copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = list(train.columns.tolist())\n",
    "data_cols = all_columns[:-1]\n",
    "label_cols = [target]\n",
    "train_no_label = train[data_cols] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Train GAN Models <a class=\"anchor\" id=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model = 'cgan'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5.2.1 GAN <a class=\"anchor\" id=\"gan2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# GAN\n",
    "if gan_model == 'gan':\n",
    "    GAN.adversarial_training_GAN(\n",
    "        arguments=arguments, train=train_no_label, data_cols=data_cols, seed=SEED\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5.2.2 CGAN <a class=\"anchor\" id=\"cgan\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# CGAN\n",
    "if gan_model == 'cgan':\n",
    "    GAN.adversarial_training_GAN(\n",
    "        arguments=arguments, train=train, data_cols=data_cols, label_cols=label_cols, seed=SEED\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5.2.3 WGAN and WCGAN <a class=\"anchor\" id=\"wgan\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # WGAN\n",
    "# GAN.adversarial_training_WGAN(\n",
    "#     arguments=arguments, train=train_no_label, data_cols=data_cols, seed=SEED\n",
    "# )\n",
    "# # WCGAN\n",
    "# GAN.adversarial_training_WGAN(\n",
    "#     arguments=arguments, train=train, data_cols=data_cols, label_cols=label_cols, seed=SEED\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Loss Information <a class=\"anchor\" id=\"loss\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "TYPE_ = 'CGAN'\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.6, wspace=0.6)\n",
    "for i, step in zip(range(1, 7), range(0, 600, 100)):\n",
    "    [combined_loss, disc_loss_generated, disc_loss_real, xgb_losses] = pickle.load(\n",
    "        open('{}{}_losses_step_{}.pkl'.format(DIRECTORY, TYPE_, step), 'rb')\n",
    "    )\n",
    "    \n",
    "    ax = fig.add_subplot(2, 3, i)\n",
    "    ax.plot(pd.DataFrame(xgb_losses).rolling(10).mean())\n",
    "    ax.title.set_text('Step {}'.format(step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Generate New Data <a class=\"anchor\" id=\"new_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "NEW = 6000\n",
    "DATA_DIM = len(data_cols)\n",
    "LABEL_DIM = len(label_cols)\n",
    "WITH_CLASS = True if LABEL_DIM > 0 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_helper(size, generator):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    x = GAN.get_data_batch(train, size, seed=SEED)\n",
    "    labels = x[:, -LABEL_DIM:]\n",
    "    \n",
    "    if all_data: \n",
    "        z = np.random.normal(size=(size, RAND_DIM))\n",
    "        g_z = generator.predict([z, labels]) if WITH_CLASS else generator.predict(z)\n",
    "    else:\n",
    "        for _ in range(NEW//size):\n",
    "            new_z = np.random.normal(size=(size, RAND_DIM))\n",
    "            new_g_z = generator.predict([new_z, labels]) if WITH_CLASS else generator.predict(new_z)\n",
    "            try:\n",
    "                g_z = np.append(g_z, new_g_z, axis=0)\n",
    "            except:\n",
    "                g_z = new_g_z\n",
    "    \n",
    "    return np.array(x), np.array(g_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():  \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # 1. Define Models\n",
    "    generator, discriminator, combined = GAN.define_models_CGAN(\n",
    "        RAND_DIM, DATA_DIM, LABEL_DIM, BASE_N_COUNT\n",
    "    )\n",
    "    generator.load_weights('GAN/outputs/CGAN_generator_model_weights_step_500.h5')\n",
    "    \n",
    "    # 2. Generate Batches of Data\n",
    "    test_size = len(train)\n",
    "    x, g_z = generate_helper(test_size, generator)\n",
    "        \n",
    "    # 3. Visualize Accuracy + New Data\n",
    "    print(\"Accuracy:\", GAN.CheckAccuracy(\n",
    "        x, g_z, data_cols, label_cols, seed=SEED, with_class=WITH_CLASS, data_dim=DATA_DIM\n",
    "    ))\n",
    "    GAN.PlotData(\n",
    "        x, g_z, data_cols, label_cols, seed=SEED, with_class=WITH_CLASS, data_dim=DATA_DIM\n",
    "    )\n",
    "    return x, g_z\n",
    "    \n",
    "batch, generated = generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 Test New Data on Models <a class=\"anchor\" id=\"train_gan\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = pd.DataFrame(batch, columns=data_cols+label_cols)\n",
    "real['syn_label'] = 0\n",
    "real.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(generated, columns=data_cols+label_cols)\n",
    "test['syn_label'] = 1\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_real, n_test = int(len(real)*SPLIT), int(len(test)*SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan = pd.concat([real[:n_real], test[:n_test]], axis=0)\n",
    "train_gan = train_gan.sample(frac=1).reset_index(drop=True) # shuffle\n",
    "test_gan = pd.concat([real[n_real:], test[n_test:]], axis=0)\n",
    "test_gan = test_gan.sample(frac=1).reset_index(drop=True) # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_gan.columns[:-2]\n",
    "y = train_gan.columns[-1]\n",
    "y_true = test_gan[y]\n",
    "d_train = xgb.DMatrix(train_gan[X], train_gan[y], feature_names=X)\n",
    "d_test = xgb.DMatrix(test_gan[X], feature_names=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'max_depth': 4,\n",
    "    'objective': 'binary:logistic',\n",
    "    'random_state': SEED,\n",
    "    'eval_metric': 'auc'\n",
    "}\n",
    "xgb_clf = xgb.train(parameters, d_train, num_boost_round=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_clf.predict(d_test)\n",
    "metric_evaluation(np.round(y_pred), y_true)\n",
    "plot_confusion_matrix(np.round(y_pred), y_true, labels=['Real', 'Fake'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6 Plot Real vs Test Data <a class=\"anchor\" id=\"plot\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(X)-1, 2):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(6,2))\n",
    "\n",
    "    ax[0].scatter(test_gan[:n_real][X[i]], test_gan[:n_real][X[i + 1]], c=y_pred[:n_real], cmap='plasma')\n",
    "    ax[0].set_title('real')\n",
    "    ax[0].set_ylabel(X[i + 1])\n",
    "\n",
    "    ax[1].scatter(test_gan[n_real:][X[i]], test_gan[n_real:][X[i + 1]], c=y_pred[n_real:], cmap='plasma')\n",
    "    ax[1].set_title('test')\n",
    "    ax[1].set_xlim(ax[0].get_xlim()), ax[1].set_ylim(ax[0].get_ylim())\n",
    "\n",
    "    for a in ax:\n",
    "        a.set_xlabel(X[i])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors = ['red','blue']\n",
    "markers = ['o','^']\n",
    "labels = ['normal','detected']\n",
    "\n",
    "target = 'COVIDResult_Encoded'\n",
    "\n",
    "for i in range(0, len(X), 2):\n",
    "    col1, col2 = i, i + 1\n",
    "    if col2 >= len(X):\n",
    "        continue\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(6,2))\n",
    "    for group, color, marker, label in zip( test_gan[:n_real].groupby(target), colors, markers, labels):\n",
    "        ax[0].scatter( group[1][X[col1]], group[1][X[col2]], label=label, c=color, marker=marker, alpha=0.2) \n",
    "    ax[0].legend()\n",
    "    ax[0].set_title('real')\n",
    "    ax[0].set_ylabel(X[col2])\n",
    "\n",
    "    for group, color, marker, label in zip( test_gan[n_real:].groupby(target), colors, markers, labels):\n",
    "        ax[1].scatter(group[1][X[col1]], group[1][X[col2]], label=label, c=color, marker=marker, alpha=0.2) \n",
    "    ax[1].set_xlim(ax[0].get_xlim()), ax[1].set_ylim(ax[0].get_ylim())\n",
    "    ax[1].legend()\n",
    "    ax[1].set_title('generated')\n",
    "\n",
    "    for a in ax:\n",
    "        a.set_xlabel(X[col1])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.7 Feature Importance <a class=\"anchor\" id=\"importance\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "xgb.plot_importance(xgb_clf, max_num_features=MAX_FEATURES, height=0.5, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Retrain Models with GAN Data <a class=\"anchor\" id=\"retrain\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Re-Prepare Data <a class=\"anchor\" id=\"prep2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = final_data.copy()\n",
    "fake_data = test.copy().drop(columns=['syn_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([real_data, fake_data], axis=0)\n",
    "combined = combined.sample(frac=1).reset_index(drop=True) # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain, retest = train_test_split(combined, test_size=0.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'COVIDResult_Encoded'\n",
    "X_cols = combined.columns.tolist()\n",
    "X_cols.remove(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_retrain = retrain[X_cols]\n",
    "y_retrain = retrain[target]\n",
    "X_retest = retest[X_cols]\n",
    "y_retest = retest[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Re-Train Models <a class=\"anchor\" id=\"retrain2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(\n",
    "    max_depth=4, criterion=\"entropy\", random_state=SEED\n",
    ")\n",
    "dt = dt.fit(X_retrain, y_retrain)\n",
    "y_prediction = dt.predict(X_retest)\n",
    "metric_evaluation(y_retest, y_prediction)\n",
    "plot_confusion_matrix(y_retest, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(dt, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True, feature_names=top_n_features, class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "# graph.write_png('rfc.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "    n_estimators=100, bootstrap=True, max_features='sqrt', random_state=SEED\n",
    ")\n",
    "rfc.fit(X_retrain, y_retrain)\n",
    "y_prediction = rfc.predict(X_retest)\n",
    "metric_evaluation(y_retest, y_prediction)\n",
    "plot_confusion_matrix(y_retest, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(rfc.feature_importances_,index=top_n_features).sort_values(ascending=False).iloc[:10]\n",
    "sns.barplot(x=feature_importance, y=feature_importance.index)\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = Sequential([\n",
    "    Dense(top_n_feats//2, activation='relu', input_shape=(top_n_feats,)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_models([\n",
    "    {'name': 'Simple Deep Neural Network', 'model': dnn,\n",
    "     'loss': 'sparse_categorical_crossentropy', 'optimizer': RMSprop(learning_rate=1e-2), 'binary': False}\n",
    "], (X_retrain, y_retrain, X_retest, y_retest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Model Training with Feature Selection <a class=\"anchor\" id=\"final\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Define Models and Variables <a class=\"anchor\" id=\"define\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    DecisionTreeClassifier(max_depth=4, criterion=\"entropy\", random_state=SEED),\n",
    "    RandomForestClassifier(n_estimators=100, bootstrap=True, max_features='sqrt', random_state=SEED),\n",
    "    'Sequential'\n",
    "]\n",
    "names = [\n",
    "    'Decision Tree Classifier',\n",
    "    'Random Forest Classifier',\n",
    "    'Deep Neural Network'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=0, splitter='best')\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
      "                       warm_start=False)\n",
      "Sequential\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = [\n",
    "    ('sbp', 'dbp'),\n",
    "    'pulse_ox',\n",
    "    'cmp_glucose',\n",
    "    'resp_rate',\n",
    "    None\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'Accuracy',\n",
    "    'Precision',\n",
    "    'Recall',\n",
    "    'F1'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 200\n",
    "VAL_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_evaluation2(y_test, y_pred):\n",
    "    acc = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "    prec = round(precision_score(y_test, y_pred) * 100, 2)\n",
    "    rec = round(recall_score(y_test, y_pred) * 100, 2)\n",
    "    f1 = round(f1_score(y_test, y_pred) * 100, 2)\n",
    "    return [acc, prec, rec, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_final_models(models_lst, xy):\n",
    "    X_train, y_train, X_test, y_test = xy\n",
    "    X_cols = [\n",
    "        'Age',\n",
    "        'FirstRace_Encoded',\n",
    "        'Ethnicity_Encoded',\n",
    "        'Sex_Encoded',\n",
    "        'height',\n",
    "        'wght',\n",
    "        'heart_rate',\n",
    "        'sbp',\n",
    "        'dbp',\n",
    "        'pulse_ox',\n",
    "        'resp_rate',\n",
    "        'cmp_glucose'\n",
    "    ]\n",
    "    \n",
    "    metric_scores_lst = []\n",
    "    index_tuples = []\n",
    "    \n",
    "    for num, drop in enumerate(drops):\n",
    "        display(Markdown('#### {} Features'.format(len(X_cols))))\n",
    "        metric_scores = []\n",
    "        \n",
    "        for model, name in zip(models_lst, names):\n",
    "            display(Markdown('<u>{}</u>'.format(name)))\n",
    "            \n",
    "            if model == 'Sequential':\n",
    "                nn = True\n",
    "                model = Sequential([\n",
    "                            Dense(len(X_cols)//2, activation='relu', input_shape=(len(X_cols),)),\n",
    "                            Dense(8, activation='relu'),\n",
    "                            Dense(8, activation='relu'),\n",
    "                            Dense(8, activation='relu'),\n",
    "                            Dense(4, activation='relu'),\n",
    "                            Dense(2, activation='softmax')\n",
    "                        ])\n",
    "                model.compile(\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    optimizer=RMSprop(learning_rate=1e-2),\n",
    "                    metrics=['accuracy']\n",
    "                )\n",
    "                model.fit(\n",
    "                    X_train[X_cols], y_train,\n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=VAL_SPLIT, shuffle=True, verbose=0\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                nn = False\n",
    "                model.fit(X_train[X_cols], y_train)\n",
    "\n",
    "            y_prediction = model.predict(X_test[X_cols])\n",
    "            y_prediction = np.argmax(y_prediction, axis=1) if nn else np.round(y_prediction)\n",
    "            metric_evaluation(y_test, y_prediction, labels=False)\n",
    "            \n",
    "            metric_scores.extend(metric_evaluation2(y_test, y_prediction))\n",
    "            if num == 0:\n",
    "                for metric in metrics:\n",
    "                    index_tuples.append((name, metric))\n",
    "                \n",
    "        \n",
    "        \n",
    "        metric_scores_lst.append(metric_scores)\n",
    "        \n",
    "        if drop is not None:\n",
    "            if not isinstance(drop, str):\n",
    "                X_cols.remove(drop[0])\n",
    "                display(Markdown('*Dropping {}...*'.format(drop[0])))\n",
    "                X_cols.remove(drop[1])\n",
    "                display(Markdown('*Dropping {}...*'.format(drop[1])))\n",
    "                \n",
    "            else:\n",
    "                X_cols.remove(drop)\n",
    "                display(Markdown('*Dropping {}...*'.format(drop)))\n",
    "           \n",
    "    index = pd.MultiIndex.from_tuples(index_tuples)\n",
    "    transposed = map(list, zip(*metric_scores_lst))\n",
    "    return pd.DataFrame(transposed, columns=['12', '10', '9', '8', '7'], index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Model Performance without GAN (Real Data) <a class=\"anchor\" id=\"perf1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### 12 Features"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<u>Decision Tree Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.70%\n",
      "Precision: 46.67%\n",
      "Recall: 7.61%\n",
      "F1: 13.08%\n",
      "[[1376    8]\n",
      " [  85    7]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Random Forest Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.11%\n",
      "Precision: 77.78%\n",
      "Recall: 7.61%\n",
      "F1: 13.86%\n",
      "[[1382    2]\n",
      " [  85    7]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Deep Neural Network</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.77%\n",
      "Precision: 0.00%\n",
      "Recall: 0.00%\n",
      "F1: 0.00%\n",
      "[[1384    0]\n",
      " [  92    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "*Dropping sbp...*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Dropping dbp...*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### 10 Features"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<u>Decision Tree Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.70%\n",
      "Precision: 46.67%\n",
      "Recall: 7.61%\n",
      "F1: 13.08%\n",
      "[[1376    8]\n",
      " [  85    7]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Random Forest Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.97%\n",
      "Precision: 61.54%\n",
      "Recall: 8.70%\n",
      "F1: 15.24%\n",
      "[[1379    5]\n",
      " [  84    8]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Deep Neural Network</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.77%\n",
      "Precision: 0.00%\n",
      "Recall: 0.00%\n",
      "F1: 0.00%\n",
      "[[1384    0]\n",
      " [  92    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "*Dropping pulse_ox...*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### 9 Features"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<u>Decision Tree Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.77%\n",
      "Precision: 0.00%\n",
      "Recall: 0.00%\n",
      "F1: 0.00%\n",
      "[[1384    0]\n",
      " [  92    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Random Forest Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.56%\n",
      "Precision: 42.11%\n",
      "Recall: 8.70%\n",
      "F1: 14.41%\n",
      "[[1373   11]\n",
      " [  84    8]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Deep Neural Network</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.77%\n",
      "Precision: 0.00%\n",
      "Recall: 0.00%\n",
      "F1: 0.00%\n",
      "[[1384    0]\n",
      " [  92    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "*Dropping cmp_glucose...*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### 8 Features"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<u>Decision Tree Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.77%\n",
      "Precision: 50.00%\n",
      "Recall: 3.26%\n",
      "F1: 6.12%\n",
      "[[1381    3]\n",
      " [  89    3]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Random Forest Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.56%\n",
      "Precision: 40.00%\n",
      "Recall: 6.52%\n",
      "F1: 11.21%\n",
      "[[1375    9]\n",
      " [  86    6]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Deep Neural Network</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.77%\n",
      "Precision: 0.00%\n",
      "Recall: 0.00%\n",
      "F1: 0.00%\n",
      "[[1384    0]\n",
      " [  92    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "*Dropping resp_rate...*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### 7 Features"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<u>Decision Tree Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.77%\n",
      "Precision: 50.00%\n",
      "Recall: 3.26%\n",
      "F1: 6.12%\n",
      "[[1381    3]\n",
      " [  89    3]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Random Forest Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.16%\n",
      "Precision: 28.57%\n",
      "Recall: 6.52%\n",
      "F1: 10.62%\n",
      "[[1369   15]\n",
      " [  86    6]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Deep Neural Network</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.77%\n",
      "Precision: 0.00%\n",
      "Recall: 0.00%\n",
      "F1: 0.00%\n",
      "[[1384    0]\n",
      " [  92    0]]\n",
      "[('Decision Tree Classifier', 'Accuracy'), ('Decision Tree Classifier', 'Precision'), ('Decision Tree Classifier', 'Recall'), ('Decision Tree Classifier', 'F1'), ('Random Forest Classifier', 'Accuracy'), ('Random Forest Classifier', 'Precision'), ('Random Forest Classifier', 'Recall'), ('Random Forest Classifier', 'F1'), ('Deep Neural Network', 'Accuracy'), ('Deep Neural Network', 'Precision'), ('Deep Neural Network', 'Recall'), ('Deep Neural Network', 'F1')]\n",
      "[[93.7, 46.67, 7.61, 13.08, 94.11, 77.78, 7.61, 13.86, 93.77, 0.0, 0.0, 0.0], [93.7, 46.67, 7.61, 13.08, 93.97, 61.54, 8.7, 15.24, 93.77, 0.0, 0.0, 0.0], [93.77, 0.0, 0.0, 0.0, 93.56, 42.11, 8.7, 14.41, 93.77, 0.0, 0.0, 0.0], [93.77, 50.0, 3.26, 6.12, 93.56, 40.0, 6.52, 11.21, 93.77, 0.0, 0.0, 0.0], [93.77, 50.0, 3.26, 6.12, 93.16, 28.57, 6.52, 10.62, 93.77, 0.0, 0.0, 0.0]]\n",
      "<map object at 0x17f4a0198>\n",
      "CPU times: user 57.5 s, sys: 1.55 s, total: 59.1 s\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metric_df1 = test_final_models(models, (X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>10</th>\n",
       "      <th>9</th>\n",
       "      <th>8</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Decision Tree Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>93.70</td>\n",
       "      <td>93.70</td>\n",
       "      <td>93.77</td>\n",
       "      <td>93.77</td>\n",
       "      <td>93.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>46.67</td>\n",
       "      <td>46.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>7.61</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>13.08</td>\n",
       "      <td>13.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Random Forest Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>94.11</td>\n",
       "      <td>93.97</td>\n",
       "      <td>93.56</td>\n",
       "      <td>93.56</td>\n",
       "      <td>93.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>77.78</td>\n",
       "      <td>61.54</td>\n",
       "      <td>42.11</td>\n",
       "      <td>40.00</td>\n",
       "      <td>28.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>7.61</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>6.52</td>\n",
       "      <td>6.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>13.86</td>\n",
       "      <td>15.24</td>\n",
       "      <td>14.41</td>\n",
       "      <td>11.21</td>\n",
       "      <td>10.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Deep Neural Network</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>93.77</td>\n",
       "      <td>93.77</td>\n",
       "      <td>93.77</td>\n",
       "      <td>93.77</td>\n",
       "      <td>93.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       12     10      9      8      7\n",
       "Decision Tree Classifier Accuracy   93.70  93.70  93.77  93.77  93.77\n",
       "                         Precision  46.67  46.67   0.00  50.00  50.00\n",
       "                         Recall      7.61   7.61   0.00   3.26   3.26\n",
       "                         F1         13.08  13.08   0.00   6.12   6.12\n",
       "Random Forest Classifier Accuracy   94.11  93.97  93.56  93.56  93.16\n",
       "                         Precision  77.78  61.54  42.11  40.00  28.57\n",
       "                         Recall      7.61   8.70   8.70   6.52   6.52\n",
       "                         F1         13.86  15.24  14.41  11.21  10.62\n",
       "Deep Neural Network      Accuracy   93.77  93.77  93.77  93.77  93.77\n",
       "                         Precision   0.00   0.00   0.00   0.00   0.00\n",
       "                         Recall      0.00   0.00   0.00   0.00   0.00\n",
       "                         F1          0.00   0.00   0.00   0.00   0.00"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Model Performance with GAN <a class=\"anchor\" id=\"perf2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### 12 Features"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<u>Decision Tree Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.07%\n",
      "Precision: 99.93%\n",
      "Recall: 91.75%\n",
      "F1: 95.67%\n",
      "[[3429    2]\n",
      " [ 254 2825]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Random Forest Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.16%\n",
      "Precision: 99.75%\n",
      "Recall: 92.11%\n",
      "F1: 95.78%\n",
      "[[3424    7]\n",
      " [ 243 2836]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Deep Neural Network</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.53%\n",
      "Precision: 98.88%\n",
      "Recall: 91.59%\n",
      "F1: 95.09%\n",
      "[[3399   32]\n",
      " [ 259 2820]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "*Dropping sbp...*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Dropping dbp...*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### 10 Features"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<u>Decision Tree Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.14%\n",
      "Precision: 100.00%\n",
      "Recall: 91.85%\n",
      "F1: 95.75%\n",
      "[[3431    0]\n",
      " [ 251 2828]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Random Forest Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.11%\n",
      "Precision: 99.44%\n",
      "Recall: 92.30%\n",
      "F1: 95.74%\n",
      "[[3415   16]\n",
      " [ 237 2842]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Deep Neural Network</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.55%\n",
      "Precision: 99.61%\n",
      "Recall: 90.94%\n",
      "F1: 95.08%\n",
      "[[3420   11]\n",
      " [ 279 2800]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "*Dropping pulse_ox...*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### 9 Features"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<u>Decision Tree Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.13%\n",
      "Precision: 100.00%\n",
      "Recall: 91.82%\n",
      "F1: 95.73%\n",
      "[[3431    0]\n",
      " [ 252 2827]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Random Forest Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.07%\n",
      "Precision: 99.44%\n",
      "Recall: 92.21%\n",
      "F1: 95.69%\n",
      "[[3415   16]\n",
      " [ 240 2839]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Deep Neural Network</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.15%\n",
      "Precision: 94.06%\n",
      "Recall: 89.02%\n",
      "F1: 91.47%\n",
      "[[3258  173]\n",
      " [ 338 2741]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "*Dropping cmp_glucose...*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### 8 Features"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<u>Decision Tree Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.04%\n",
      "Precision: 99.79%\n",
      "Recall: 91.82%\n",
      "F1: 95.64%\n",
      "[[3425    6]\n",
      " [ 252 2827]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Random Forest Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.99%\n",
      "Precision: 99.13%\n",
      "Recall: 92.34%\n",
      "F1: 95.61%\n",
      "[[3406   25]\n",
      " [ 236 2843]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Deep Neural Network</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.27%\n",
      "Precision: 81.45%\n",
      "Recall: 89.15%\n",
      "F1: 85.13%\n",
      "[[2806  625]\n",
      " [ 334 2745]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "*Dropping resp_rate...*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### 7 Features"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<u>Decision Tree Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.04%\n",
      "Precision: 99.79%\n",
      "Recall: 91.82%\n",
      "F1: 95.64%\n",
      "[[3425    6]\n",
      " [ 252 2827]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Random Forest Classifier</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.75%\n",
      "Precision: 98.44%\n",
      "Recall: 92.47%\n",
      "F1: 95.36%\n",
      "[[3386   45]\n",
      " [ 232 2847]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<u>Deep Neural Network</u>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.73%\n",
      "Precision: 83.40%\n",
      "Recall: 81.91%\n",
      "F1: 82.65%\n",
      "[[2929  502]\n",
      " [ 557 2522]]\n",
      "[('Decision Tree Classifier', 'Accuracy'), ('Decision Tree Classifier', 'Precision'), ('Decision Tree Classifier', 'Recall'), ('Decision Tree Classifier', 'F1'), ('Random Forest Classifier', 'Accuracy'), ('Random Forest Classifier', 'Precision'), ('Random Forest Classifier', 'Recall'), ('Random Forest Classifier', 'F1'), ('Deep Neural Network', 'Accuracy'), ('Deep Neural Network', 'Precision'), ('Deep Neural Network', 'Recall'), ('Deep Neural Network', 'F1')]\n",
      "[[96.07, 99.93, 91.75, 95.67, 96.16, 99.75, 92.11, 95.78, 95.53, 98.88, 91.59, 95.09], [96.14, 100.0, 91.85, 95.75, 96.11, 99.44, 92.3, 95.74, 95.55, 99.61, 90.94, 95.08], [96.13, 100.0, 91.82, 95.73, 96.07, 99.44, 92.21, 95.69, 92.15, 94.06, 89.02, 91.47], [96.04, 99.79, 91.82, 95.64, 95.99, 99.13, 92.34, 95.61, 85.27, 81.45, 89.15, 85.13], [96.04, 99.79, 91.82, 95.64, 95.75, 98.44, 92.47, 95.36, 83.73, 83.4, 81.91, 82.65]]\n",
      "<map object at 0x18676cb00>\n",
      "CPU times: user 1min 3s, sys: 1.82 s, total: 1min 5s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metric_df2 = test_final_models(models, (X_retrain, y_retrain, X_retest, y_retest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>10</th>\n",
       "      <th>9</th>\n",
       "      <th>8</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Decision Tree Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>96.07</td>\n",
       "      <td>96.14</td>\n",
       "      <td>96.13</td>\n",
       "      <td>96.04</td>\n",
       "      <td>96.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>99.93</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.79</td>\n",
       "      <td>99.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>91.75</td>\n",
       "      <td>91.85</td>\n",
       "      <td>91.82</td>\n",
       "      <td>91.82</td>\n",
       "      <td>91.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>95.67</td>\n",
       "      <td>95.75</td>\n",
       "      <td>95.73</td>\n",
       "      <td>95.64</td>\n",
       "      <td>95.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Random Forest Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>96.16</td>\n",
       "      <td>96.11</td>\n",
       "      <td>96.07</td>\n",
       "      <td>95.99</td>\n",
       "      <td>95.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>99.75</td>\n",
       "      <td>99.44</td>\n",
       "      <td>99.44</td>\n",
       "      <td>99.13</td>\n",
       "      <td>98.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>92.11</td>\n",
       "      <td>92.30</td>\n",
       "      <td>92.21</td>\n",
       "      <td>92.34</td>\n",
       "      <td>92.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>95.78</td>\n",
       "      <td>95.74</td>\n",
       "      <td>95.69</td>\n",
       "      <td>95.61</td>\n",
       "      <td>95.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Deep Neural Network</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>95.53</td>\n",
       "      <td>95.55</td>\n",
       "      <td>92.15</td>\n",
       "      <td>85.27</td>\n",
       "      <td>83.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>98.88</td>\n",
       "      <td>99.61</td>\n",
       "      <td>94.06</td>\n",
       "      <td>81.45</td>\n",
       "      <td>83.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>91.59</td>\n",
       "      <td>90.94</td>\n",
       "      <td>89.02</td>\n",
       "      <td>89.15</td>\n",
       "      <td>81.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>95.09</td>\n",
       "      <td>95.08</td>\n",
       "      <td>91.47</td>\n",
       "      <td>85.13</td>\n",
       "      <td>82.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       12      10       9      8      7\n",
       "Decision Tree Classifier Accuracy   96.07   96.14   96.13  96.04  96.04\n",
       "                         Precision  99.93  100.00  100.00  99.79  99.79\n",
       "                         Recall     91.75   91.85   91.82  91.82  91.82\n",
       "                         F1         95.67   95.75   95.73  95.64  95.64\n",
       "Random Forest Classifier Accuracy   96.16   96.11   96.07  95.99  95.75\n",
       "                         Precision  99.75   99.44   99.44  99.13  98.44\n",
       "                         Recall     92.11   92.30   92.21  92.34  92.47\n",
       "                         F1         95.78   95.74   95.69  95.61  95.36\n",
       "Deep Neural Network      Accuracy   95.53   95.55   92.15  85.27  83.73\n",
       "                         Precision  98.88   99.61   94.06  81.45  83.40\n",
       "                         Recall     91.59   90.94   89.02  89.15  81.91\n",
       "                         F1         95.09   95.08   91.47  85.13  82.65"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
