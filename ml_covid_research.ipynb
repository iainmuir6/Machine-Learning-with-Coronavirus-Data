{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 4993 Independent Study – Machine Learning with COVID Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Professor: [Haiyang Shen](https://engineering.virginia.edu/faculty/haiying-shen)***  \n",
    "***Researcher: [Iain Muir](https://www.linkedin.com/in/iain-muir-b37718164/) | iam9ez***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Github Project:* https://github.com/iainmuir6/machineLearning_covidData\n",
    "\n",
    "*Last Updated: June 6th, 2021*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "* [CS 4774 ML Material – Professor Rich Nguyen](https://www.cs.virginia.edu/~nn4pj/teaching)\n",
    "* [Steps to Building Machine Learning Model](https://analyticsindiamag.com/the-7-key-steps-to-build-your-machine-learning-model/)\n",
    "* [Steps to Data Preprocessing](https://hackernoon.com/what-steps-should-one-take-while-doing-data-preprocessing-502c993e1caa)\n",
    "* [Handling Missing Values](https://towardsdatascience.com/7-ways-to-handle-missing-values-in-machine-learning-1a6326adf79e)\n",
    "* [Feature Selection I](https://towardsdatascience.com/the-5-feature-selection-algorithms-every-data-scientist-need-to-know-3a6b566efd2)\n",
    "* [Feature Selection II](https://machinelearningmastery.com/feature-selection-machine-learning-python/)\n",
    "* [Keras Neural Network I](https://towardsdatascience.com/3-ways-to-create-a-machine-learning-model-with-keras-and-tensorflow-2-0-de09323af4d3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO List\n",
    "* Loop through models, incrementally changing nodes/layers\n",
    "* Run Models with Generated Data\n",
    "    * Look more into GAN\n",
    "* Convolution, Pooling, Recurrent, etc. Layers?\n",
    "* Variety of Deep Learning Models\n",
    "    * Organize Models by Performance\n",
    "    \n",
    "Consider...\n",
    "* Alternative method for handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 0. Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1 General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from scipy.stats import reciprocal\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2 ML Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE, SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn\n",
    "\n",
    "from keras.layers import Dense, LeakyReLU, PReLU, BatchNormalization, Activation, InputLayer\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.1'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read Excel File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>patno</th>\n",
       "      <th>Admitted</th>\n",
       "      <th>AdmittingDepartment</th>\n",
       "      <th>COVIDResult</th>\n",
       "      <th>Age</th>\n",
       "      <th>FirstRace</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Sex</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>cmp_bicarbonate</th>\n",
       "      <th>cmp_bun</th>\n",
       "      <th>cmp_creatinine</th>\n",
       "      <th>cmp_glucose</th>\n",
       "      <th>cmp_alt</th>\n",
       "      <th>cmp_ast</th>\n",
       "      <th>cmp_alkaline_phosphatase</th>\n",
       "      <th>cmp_total_protein</th>\n",
       "      <th>cmp_albumin</th>\n",
       "      <th>cmp_bilirubin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>UVHE MICU</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>78</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>14</td>\n",
       "      <td>26.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>23</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>0.9</td>\n",
       "      <td>83.0</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>55</td>\n",
       "      <td>African American</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>123.0</td>\n",
       "      <td>26</td>\n",
       "      <td>29.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>UVHE MICU</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>50</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>1.6</td>\n",
       "      <td>297.0</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>67</td>\n",
       "      <td>African American</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  patno  Admitted AdmittingDepartment    COVIDResult  Age  \\\n",
       "0      0      1         1           UVHE MICU  None Detected   78   \n",
       "1      1      2         0                 NaN  None Detected   23   \n",
       "2      2      3         0                 NaN  None Detected   55   \n",
       "3      3      4         1           UVHE MICU  None Detected   50   \n",
       "4      4      5         0                 NaN  None Detected   67   \n",
       "\n",
       "            FirstRace     Ethnicity     Sex  heart_rate  ...  cmp_bicarbonate  \\\n",
       "0  White or Caucasian  Non-Hispanic  Female        94.0  ...               26   \n",
       "1  White or Caucasian  Non-Hispanic  Female       121.0  ...               19   \n",
       "2    African American  Non-Hispanic    Male        83.0  ...               23   \n",
       "3  White or Caucasian  Non-Hispanic    Male        88.0  ...               30   \n",
       "4    African American  Non-Hispanic  Female        90.0  ...               27   \n",
       "\n",
       "   cmp_bun  cmp_creatinine  cmp_glucose  cmp_alt  cmp_ast  \\\n",
       "0       31             2.5         82.0       14     26.0   \n",
       "1       11             0.9         83.0       73      NaN   \n",
       "2        9             1.2        123.0       26     29.0   \n",
       "3       45             1.6        297.0       22      NaN   \n",
       "4       25             1.0         96.0       12     18.0   \n",
       "\n",
       "   cmp_alkaline_phosphatase  cmp_total_protein  cmp_albumin  cmp_bilirubin  \n",
       "0                      80.0                8.5          4.3            0.5  \n",
       "1                     100.0                8.1          4.6            0.6  \n",
       "2                     106.0                7.1          4.0            0.7  \n",
       "3                      78.0                7.8          3.7            0.5  \n",
       "4                     122.0                7.4          3.5            0.2  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('ed_pred.xlsx')\n",
    "df = df.reset_index()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7380, 41)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'patno', 'Admitted', 'AdmittingDepartment', 'COVIDResult',\n",
       "       'Age', 'FirstRace', 'Ethnicity', 'Sex', 'heart_rate', 'sbp', 'dbp',\n",
       "       'pulse_ox', 'resp_rate', 'height', 'wght', 'cbc_wbc', 'cbc_hematocrit',\n",
       "       'cbc_hemoglobin', 'cbc_platelets', 'cbc_neutrophil_c',\n",
       "       'cbc_eosinophil_perc', 'cbc_lymphocyte_c', 'cbc_lymphocyte_perc',\n",
       "       'cbc_eosinophil_c', 'cbc_eosinophil_perc.1', 'cbc_monocyte_c',\n",
       "       'cbc_eosinophil_perc.2', 'cmp_sodium', 'cmp_potassium', 'cmp_chloride',\n",
       "       'cmp_bicarbonate', 'cmp_bun', 'cmp_creatinine', 'cmp_glucose',\n",
       "       'cmp_alt', 'cmp_ast', 'cmp_alkaline_phosphatase', 'cmp_total_protein',\n",
       "       'cmp_albumin', 'cmp_bilirubin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'COVIDResult'\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Column Description\n",
    "Note (src - [Walk-In-Lab](https://www.walkinlab.com/products/view/complete-blood-count-cbc-comprehensive-metabolic-panel-cmp-14-blood-test-panel#:~:text=A%20CBC%20also%20helps%20your,anemia%2C%20and%20several%20other%20disorders.&text=Comprehensive%20Metabolic%20Panel%20)): \n",
    "\n",
    "CBC == [Complete Blood Count](https://www.mayoclinic.org/tests-procedures/complete-blood-count/about/pac-20384919)\n",
    "* Complete Blood Count (CBC) gives important information about the numbers and kinds of cells in the blood, especially red blood cells, white blood cells, and platelets. A CBC helps your health professional check any symptoms, such as fatigue, weakness, or bruising, that you may have. A CBC also helps your health professional diagnose conditions, such as infection, anemia, and several other disorders.\n",
    "\n",
    "CMP == [Comprehensive Metabolic Panel](https://www.mayocliniclabs.com/test-catalog/Clinical+and+Interpretive/113631)\n",
    "* Comprehensive Metabolic Panel (CMP-14) with eGFR is a group of 14 laboratory tests ordered to give information about the current status of your liver, kidneys, and electrolyte and acid/base balance.  The test gives the current status of your blood sugar and blood proteins also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7380 entries, 0 to 7379\n",
      "Data columns (total 41 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   index                     7380 non-null   int64  \n",
      " 1   patno                     7380 non-null   int64  \n",
      " 2   Admitted                  7380 non-null   int64  \n",
      " 3   AdmittingDepartment       3003 non-null   object \n",
      " 4   COVIDResult               7380 non-null   object \n",
      " 5   Age                       7380 non-null   int64  \n",
      " 6   FirstRace                 7379 non-null   object \n",
      " 7   Ethnicity                 7380 non-null   object \n",
      " 8   Sex                       7380 non-null   object \n",
      " 9   heart_rate                7352 non-null   float64\n",
      " 10  sbp                       7292 non-null   float64\n",
      " 11  dbp                       7292 non-null   float64\n",
      " 12  pulse_ox                  7346 non-null   float64\n",
      " 13  resp_rate                 7312 non-null   float64\n",
      " 14  height                    456 non-null    float64\n",
      " 15  wght                      3248 non-null   float64\n",
      " 16  cbc_wbc                   6256 non-null   float64\n",
      " 17  cbc_hematocrit            6256 non-null   float64\n",
      " 18  cbc_hemoglobin            6257 non-null   float64\n",
      " 19  cbc_platelets             6256 non-null   float64\n",
      " 20  cbc_neutrophil_c          3873 non-null   float64\n",
      " 21  cbc_eosinophil_perc       3872 non-null   float64\n",
      " 22  cbc_lymphocyte_c          3874 non-null   float64\n",
      " 23  cbc_lymphocyte_perc       3874 non-null   float64\n",
      " 24  cbc_eosinophil_c          3872 non-null   float64\n",
      " 25  cbc_eosinophil_perc.1     3872 non-null   float64\n",
      " 26  cbc_monocyte_c            3874 non-null   float64\n",
      " 27  cbc_eosinophil_perc.2     3872 non-null   float64\n",
      " 28  cmp_sodium                6286 non-null   float64\n",
      " 29  cmp_potassium             5570 non-null   float64\n",
      " 30  cmp_chloride              6286 non-null   float64\n",
      " 31  cmp_bicarbonate           6276 non-null   object \n",
      " 32  cmp_bun                   6286 non-null   object \n",
      " 33  cmp_creatinine            6286 non-null   object \n",
      " 34  cmp_glucose               6286 non-null   float64\n",
      " 35  cmp_alt                   5401 non-null   object \n",
      " 36  cmp_ast                   4767 non-null   float64\n",
      " 37  cmp_alkaline_phosphatase  5399 non-null   float64\n",
      " 38  cmp_total_protein         5175 non-null   float64\n",
      " 39  cmp_albumin               5402 non-null   float64\n",
      " 40  cmp_bilirubin             5401 non-null   object \n",
      "dtypes: float64(27), int64(4), object(10)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "target = 'COVIDResult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>patno</th>\n",
       "      <th>Admitted</th>\n",
       "      <th>Age</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pulse_ox</th>\n",
       "      <th>resp_rate</th>\n",
       "      <th>height</th>\n",
       "      <th>...</th>\n",
       "      <th>cbc_monocyte_c</th>\n",
       "      <th>cbc_eosinophil_perc.2</th>\n",
       "      <th>cmp_sodium</th>\n",
       "      <th>cmp_potassium</th>\n",
       "      <th>cmp_chloride</th>\n",
       "      <th>cmp_glucose</th>\n",
       "      <th>cmp_ast</th>\n",
       "      <th>cmp_alkaline_phosphatase</th>\n",
       "      <th>cmp_total_protein</th>\n",
       "      <th>cmp_albumin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7380.000000</td>\n",
       "      <td>7380.000000</td>\n",
       "      <td>7380.000000</td>\n",
       "      <td>7380.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7292.000000</td>\n",
       "      <td>7292.000000</td>\n",
       "      <td>7346.000000</td>\n",
       "      <td>7312.000000</td>\n",
       "      <td>456.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3874.000000</td>\n",
       "      <td>3872.000000</td>\n",
       "      <td>6286.000000</td>\n",
       "      <td>5570.000000</td>\n",
       "      <td>6286.000000</td>\n",
       "      <td>6286.000000</td>\n",
       "      <td>4767.000000</td>\n",
       "      <td>5399.000000</td>\n",
       "      <td>5175.000000</td>\n",
       "      <td>5402.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3689.500000</td>\n",
       "      <td>3690.500000</td>\n",
       "      <td>0.406911</td>\n",
       "      <td>48.977642</td>\n",
       "      <td>94.529788</td>\n",
       "      <td>135.998354</td>\n",
       "      <td>76.034696</td>\n",
       "      <td>97.064661</td>\n",
       "      <td>21.029130</td>\n",
       "      <td>65.971491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740428</td>\n",
       "      <td>1.492485</td>\n",
       "      <td>137.104677</td>\n",
       "      <td>4.043447</td>\n",
       "      <td>102.562997</td>\n",
       "      <td>137.406141</td>\n",
       "      <td>55.627858</td>\n",
       "      <td>114.154843</td>\n",
       "      <td>7.210473</td>\n",
       "      <td>3.846113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2130.566826</td>\n",
       "      <td>2130.566826</td>\n",
       "      <td>0.491291</td>\n",
       "      <td>23.525661</td>\n",
       "      <td>23.352438</td>\n",
       "      <td>27.256409</td>\n",
       "      <td>15.302797</td>\n",
       "      <td>3.832935</td>\n",
       "      <td>6.762566</td>\n",
       "      <td>7.635750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545253</td>\n",
       "      <td>2.276703</td>\n",
       "      <td>4.366669</td>\n",
       "      <td>0.603037</td>\n",
       "      <td>5.600923</td>\n",
       "      <td>92.857337</td>\n",
       "      <td>154.142598</td>\n",
       "      <td>89.983238</td>\n",
       "      <td>0.843891</td>\n",
       "      <td>0.577974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1844.750000</td>\n",
       "      <td>1845.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3689.500000</td>\n",
       "      <td>3690.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5534.250000</td>\n",
       "      <td>5535.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7379.000000</td>\n",
       "      <td>7380.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.790000</td>\n",
       "      <td>41.100000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>1576.000000</td>\n",
       "      <td>6479.000000</td>\n",
       "      <td>1126.000000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>6.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             index        patno     Admitted          Age   heart_rate  \\\n",
       "count  7380.000000  7380.000000  7380.000000  7380.000000  7352.000000   \n",
       "mean   3689.500000  3690.500000     0.406911    48.977642    94.529788   \n",
       "std    2130.566826  2130.566826     0.491291    23.525661    23.352438   \n",
       "min       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "25%    1844.750000  1845.750000     0.000000    31.000000    78.000000   \n",
       "50%    3689.500000  3690.500000     0.000000    52.000000    92.000000   \n",
       "75%    5534.250000  5535.250000     1.000000    67.000000   107.000000   \n",
       "max    7379.000000  7380.000000     1.000000   119.000000   235.000000   \n",
       "\n",
       "               sbp          dbp     pulse_ox    resp_rate      height  ...  \\\n",
       "count  7292.000000  7292.000000  7346.000000  7312.000000  456.000000  ...   \n",
       "mean    135.998354    76.034696    97.064661    21.029130   65.971491  ...   \n",
       "std      27.256409    15.302797     3.832935     6.762566    7.635750  ...   \n",
       "min      46.000000     0.000000    25.000000     0.000000    2.000000  ...   \n",
       "25%     118.000000    65.000000    96.000000    18.000000   63.000000  ...   \n",
       "50%     133.000000    75.000000    98.000000    20.000000   67.000000  ...   \n",
       "75%     151.000000    86.000000    99.000000    22.000000   70.000000  ...   \n",
       "max     258.000000   147.000000   100.000000   111.000000   77.000000  ...   \n",
       "\n",
       "       cbc_monocyte_c  cbc_eosinophil_perc.2   cmp_sodium  cmp_potassium  \\\n",
       "count     3874.000000            3872.000000  6286.000000    5570.000000   \n",
       "mean         0.740428               1.492485   137.104677       4.043447   \n",
       "std          0.545253               2.276703     4.366669       0.603037   \n",
       "min          0.000000               0.000000   107.000000       2.000000   \n",
       "25%          0.460000               0.100000   135.000000       3.700000   \n",
       "50%          0.670000               0.800000   138.000000       4.000000   \n",
       "75%          0.940000               2.000000   140.000000       4.300000   \n",
       "max         17.790000              41.100000   182.000000       8.900000   \n",
       "\n",
       "       cmp_chloride  cmp_glucose      cmp_ast  cmp_alkaline_phosphatase  \\\n",
       "count   6286.000000  6286.000000  4767.000000               5399.000000   \n",
       "mean     102.562997   137.406141    55.627858                114.154843   \n",
       "std        5.600923    92.857337   154.142598                 89.983238   \n",
       "min       60.000000    22.000000     7.000000                 21.000000   \n",
       "25%      100.000000    94.000000    23.000000                 71.000000   \n",
       "50%      103.000000   109.000000    31.000000                 90.000000   \n",
       "75%      106.000000   140.000000    46.000000                123.000000   \n",
       "max      143.000000  1576.000000  6479.000000               1126.000000   \n",
       "\n",
       "       cmp_total_protein  cmp_albumin  \n",
       "count        5175.000000  5402.000000  \n",
       "mean            7.210473     3.846113  \n",
       "std             0.843891     0.577974  \n",
       "min             2.400000     1.000000  \n",
       "25%             6.700000     3.500000  \n",
       "50%             7.200000     3.900000  \n",
       "75%             7.700000     4.200000  \n",
       "max            11.300000     6.300000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>patno</th>\n",
       "      <th>Admitted</th>\n",
       "      <th>Age</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pulse_ox</th>\n",
       "      <th>resp_rate</th>\n",
       "      <th>height</th>\n",
       "      <th>...</th>\n",
       "      <th>cbc_monocyte_c</th>\n",
       "      <th>cbc_eosinophil_perc.2</th>\n",
       "      <th>cmp_sodium</th>\n",
       "      <th>cmp_potassium</th>\n",
       "      <th>cmp_chloride</th>\n",
       "      <th>cmp_glucose</th>\n",
       "      <th>cmp_ast</th>\n",
       "      <th>cmp_alkaline_phosphatase</th>\n",
       "      <th>cmp_total_protein</th>\n",
       "      <th>cmp_albumin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030377</td>\n",
       "      <td>-0.071132</td>\n",
       "      <td>-0.014543</td>\n",
       "      <td>-0.013479</td>\n",
       "      <td>-0.002088</td>\n",
       "      <td>0.066634</td>\n",
       "      <td>-0.031710</td>\n",
       "      <td>-0.017314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006011</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.039232</td>\n",
       "      <td>-0.005859</td>\n",
       "      <td>0.026758</td>\n",
       "      <td>-0.010492</td>\n",
       "      <td>-0.036648</td>\n",
       "      <td>-0.011070</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.045855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patno</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030377</td>\n",
       "      <td>-0.071132</td>\n",
       "      <td>-0.014543</td>\n",
       "      <td>-0.013479</td>\n",
       "      <td>-0.002088</td>\n",
       "      <td>0.066634</td>\n",
       "      <td>-0.031710</td>\n",
       "      <td>-0.017314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006011</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.039232</td>\n",
       "      <td>-0.005859</td>\n",
       "      <td>0.026758</td>\n",
       "      <td>-0.010492</td>\n",
       "      <td>-0.036648</td>\n",
       "      <td>-0.011070</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.045855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Admitted</th>\n",
       "      <td>-0.030377</td>\n",
       "      <td>-0.030377</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.071533</td>\n",
       "      <td>-0.034520</td>\n",
       "      <td>-0.083964</td>\n",
       "      <td>-0.187805</td>\n",
       "      <td>0.141345</td>\n",
       "      <td>0.006556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090950</td>\n",
       "      <td>-0.122416</td>\n",
       "      <td>-0.139857</td>\n",
       "      <td>0.123330</td>\n",
       "      <td>-0.145144</td>\n",
       "      <td>0.125331</td>\n",
       "      <td>0.098732</td>\n",
       "      <td>0.117501</td>\n",
       "      <td>-0.169298</td>\n",
       "      <td>-0.301735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.071132</td>\n",
       "      <td>-0.071132</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.343054</td>\n",
       "      <td>0.255632</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>-0.233759</td>\n",
       "      <td>-0.128765</td>\n",
       "      <td>0.237857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068070</td>\n",
       "      <td>-0.003148</td>\n",
       "      <td>-0.077553</td>\n",
       "      <td>0.129890</td>\n",
       "      <td>-0.137116</td>\n",
       "      <td>0.097948</td>\n",
       "      <td>-0.014016</td>\n",
       "      <td>-0.091849</td>\n",
       "      <td>-0.147716</td>\n",
       "      <td>-0.312481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_rate</th>\n",
       "      <td>-0.014543</td>\n",
       "      <td>-0.014543</td>\n",
       "      <td>0.071533</td>\n",
       "      <td>-0.343054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.128325</td>\n",
       "      <td>0.032385</td>\n",
       "      <td>-0.018398</td>\n",
       "      <td>0.397967</td>\n",
       "      <td>-0.277916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100502</td>\n",
       "      <td>-0.102094</td>\n",
       "      <td>-0.062122</td>\n",
       "      <td>-0.048065</td>\n",
       "      <td>-0.073826</td>\n",
       "      <td>0.074114</td>\n",
       "      <td>0.025044</td>\n",
       "      <td>0.123586</td>\n",
       "      <td>0.046071</td>\n",
       "      <td>0.021046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbp</th>\n",
       "      <td>-0.013479</td>\n",
       "      <td>-0.013479</td>\n",
       "      <td>-0.034520</td>\n",
       "      <td>0.255632</td>\n",
       "      <td>-0.128325</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700990</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>-0.054224</td>\n",
       "      <td>0.129512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037211</td>\n",
       "      <td>0.056011</td>\n",
       "      <td>0.089829</td>\n",
       "      <td>-0.016583</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.052785</td>\n",
       "      <td>-0.058817</td>\n",
       "      <td>-0.102502</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.193473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dbp</th>\n",
       "      <td>-0.002088</td>\n",
       "      <td>-0.002088</td>\n",
       "      <td>-0.083964</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.032385</td>\n",
       "      <td>0.700990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044760</td>\n",
       "      <td>-0.038692</td>\n",
       "      <td>0.178501</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019228</td>\n",
       "      <td>0.026571</td>\n",
       "      <td>0.119920</td>\n",
       "      <td>-0.055991</td>\n",
       "      <td>0.036059</td>\n",
       "      <td>0.017755</td>\n",
       "      <td>-0.010922</td>\n",
       "      <td>-0.091883</td>\n",
       "      <td>0.268447</td>\n",
       "      <td>0.288271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pulse_ox</th>\n",
       "      <td>0.066634</td>\n",
       "      <td>0.066634</td>\n",
       "      <td>-0.187805</td>\n",
       "      <td>-0.233759</td>\n",
       "      <td>-0.018398</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>0.044760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.203094</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002565</td>\n",
       "      <td>0.017027</td>\n",
       "      <td>0.012110</td>\n",
       "      <td>-0.118440</td>\n",
       "      <td>0.099202</td>\n",
       "      <td>-0.105208</td>\n",
       "      <td>-0.052456</td>\n",
       "      <td>-0.005379</td>\n",
       "      <td>0.037321</td>\n",
       "      <td>0.123265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resp_rate</th>\n",
       "      <td>-0.031710</td>\n",
       "      <td>-0.031710</td>\n",
       "      <td>0.141345</td>\n",
       "      <td>-0.128765</td>\n",
       "      <td>0.397967</td>\n",
       "      <td>-0.054224</td>\n",
       "      <td>-0.038692</td>\n",
       "      <td>-0.203094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.339655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078115</td>\n",
       "      <td>-0.037053</td>\n",
       "      <td>-0.013692</td>\n",
       "      <td>0.118477</td>\n",
       "      <td>-0.008239</td>\n",
       "      <td>0.076232</td>\n",
       "      <td>0.037055</td>\n",
       "      <td>0.099776</td>\n",
       "      <td>-0.078270</td>\n",
       "      <td>-0.083926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>-0.017314</td>\n",
       "      <td>-0.017314</td>\n",
       "      <td>0.006556</td>\n",
       "      <td>0.237857</td>\n",
       "      <td>-0.277916</td>\n",
       "      <td>0.129512</td>\n",
       "      <td>0.178501</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>-0.339655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033168</td>\n",
       "      <td>-0.156211</td>\n",
       "      <td>0.055314</td>\n",
       "      <td>-0.173582</td>\n",
       "      <td>0.030194</td>\n",
       "      <td>0.057657</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>-0.187236</td>\n",
       "      <td>0.127008</td>\n",
       "      <td>0.030490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wght</th>\n",
       "      <td>-0.057584</td>\n",
       "      <td>-0.057584</td>\n",
       "      <td>0.138873</td>\n",
       "      <td>0.432725</td>\n",
       "      <td>-0.375283</td>\n",
       "      <td>0.256390</td>\n",
       "      <td>0.191655</td>\n",
       "      <td>-0.130171</td>\n",
       "      <td>-0.299886</td>\n",
       "      <td>0.506950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046526</td>\n",
       "      <td>0.035913</td>\n",
       "      <td>0.031168</td>\n",
       "      <td>-0.001168</td>\n",
       "      <td>-0.009780</td>\n",
       "      <td>0.117112</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>-0.201825</td>\n",
       "      <td>0.089641</td>\n",
       "      <td>-0.087129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cbc_wbc</th>\n",
       "      <td>-0.005411</td>\n",
       "      <td>-0.005411</td>\n",
       "      <td>0.140818</td>\n",
       "      <td>-0.035561</td>\n",
       "      <td>0.127127</td>\n",
       "      <td>-0.044712</td>\n",
       "      <td>-0.035427</td>\n",
       "      <td>-0.053765</td>\n",
       "      <td>0.107466</td>\n",
       "      <td>-0.006946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509534</td>\n",
       "      <td>-0.116462</td>\n",
       "      <td>-0.031298</td>\n",
       "      <td>0.052575</td>\n",
       "      <td>-0.036382</td>\n",
       "      <td>0.079747</td>\n",
       "      <td>0.038337</td>\n",
       "      <td>0.038098</td>\n",
       "      <td>0.011260</td>\n",
       "      <td>-0.020093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cbc_hematocrit</th>\n",
       "      <td>0.022097</td>\n",
       "      <td>0.022097</td>\n",
       "      <td>-0.201153</td>\n",
       "      <td>-0.134952</td>\n",
       "      <td>0.003627</td>\n",
       "      <td>0.123147</td>\n",
       "      <td>0.271443</td>\n",
       "      <td>-0.049715</td>\n",
       "      <td>-0.037861</td>\n",
       "      <td>0.100637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021607</td>\n",
       "      <td>-0.009774</td>\n",
       "      <td>0.208495</td>\n",
       "      <td>-0.039061</td>\n",
       "      <td>0.058504</td>\n",
       "      <td>0.008516</td>\n",
       "      <td>0.018966</td>\n",
       "      <td>-0.155929</td>\n",
       "      <td>0.403966</td>\n",
       "      <td>0.522731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cbc_hemoglobin</th>\n",
       "      <td>0.026712</td>\n",
       "      <td>0.026712</td>\n",
       "      <td>-0.218690</td>\n",
       "      <td>-0.179703</td>\n",
       "      <td>0.011397</td>\n",
       "      <td>0.118943</td>\n",
       "      <td>0.280105</td>\n",
       "      <td>-0.006979</td>\n",
       "      <td>-0.052274</td>\n",
       "      <td>0.092058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>-0.023797</td>\n",
       "      <td>0.152671</td>\n",
       "      <td>-0.086993</td>\n",
       "      <td>0.032291</td>\n",
       "      <td>-0.009205</td>\n",
       "      <td>0.014291</td>\n",
       "      <td>-0.158250</td>\n",
       "      <td>0.389195</td>\n",
       "      <td>0.545362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cbc_platelets</th>\n",
       "      <td>0.034431</td>\n",
       "      <td>0.034431</td>\n",
       "      <td>-0.048104</td>\n",
       "      <td>-0.186491</td>\n",
       "      <td>0.156655</td>\n",
       "      <td>-0.004040</td>\n",
       "      <td>0.034225</td>\n",
       "      <td>0.040013</td>\n",
       "      <td>0.078875</td>\n",
       "      <td>-0.241994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189150</td>\n",
       "      <td>0.015036</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.012827</td>\n",
       "      <td>-0.035093</td>\n",
       "      <td>0.032876</td>\n",
       "      <td>-0.072822</td>\n",
       "      <td>0.036632</td>\n",
       "      <td>0.224736</td>\n",
       "      <td>0.124224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cbc_neutrophil_c</th>\n",
       "      <td>0.015320</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>0.207518</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.144446</td>\n",
       "      <td>-0.054473</td>\n",
       "      <td>-0.051273</td>\n",
       "      <td>-0.068710</td>\n",
       "      <td>0.101723</td>\n",
       "      <td>0.073823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442835</td>\n",
       "      <td>-0.231476</td>\n",
       "      <td>-0.055907</td>\n",
       "      <td>0.059657</td>\n",
       "      <td>-0.061286</td>\n",
       "      <td>0.117837</td>\n",
       "      <td>0.030051</td>\n",
       "      <td>0.028203</td>\n",
       "      <td>0.008387</td>\n",
       "      <td>-0.044713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cbc_eosinophil_perc</th>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>-0.122416</td>\n",
       "      <td>-0.003148</td>\n",
       "      <td>-0.102094</td>\n",
       "      <td>0.056011</td>\n",
       "      <td>0.026571</td>\n",
       "      <td>0.017027</td>\n",
       "      <td>-0.037053</td>\n",
       "      <td>-0.156211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083970</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>0.067240</td>\n",
       "      <td>-0.064207</td>\n",
       "      <td>-0.044503</td>\n",
       "      <td>0.030661</td>\n",
       "      <td>0.009270</td>\n",
       "      <td>-0.021485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cbc_lymphocyte_c</th>\n",
       "      <td>-0.019357</td>\n",
       "      <td>-0.019357</td>\n",
       "      <td>-0.094380</td>\n",
       "      <td>-0.141078</td>\n",
       "      <td>0.050274</td>\n",
       "      <td>0.009810</td>\n",
       "      <td>0.048564</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.099687</td>\n",
       "      <td>-0.328064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155681</td>\n",
       "      <td>0.082187</td>\n",
       "      <td>0.106285</td>\n",
       "      <td>0.018151</td>\n",
       "      <td>0.097709</td>\n",
       "      <td>-0.035040</td>\n",
       "      <td>-0.017489</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.028924</td>\n",
       "      <td>0.132946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cbc_lymphocyte_perc</th>\n",
       "      <td>-0.009835</td>\n",
       "      <td>-0.009835</td>\n",
       "      <td>-0.234463</td>\n",
       "      <td>-0.197247</td>\n",
       "      <td>-0.030777</td>\n",
       "      <td>-0.001484</td>\n",
       "      <td>0.058332</td>\n",
       "      <td>0.094088</td>\n",
       "      <td>0.013950</td>\n",
       "      <td>-0.297477</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.163475</td>\n",
       "      <td>0.236394</td>\n",
       "      <td>0.146085</td>\n",
       "      <td>-0.073324</td>\n",
       "      <td>0.170409</td>\n",
       "      <td>-0.129518</td>\n",
       "      <td>-0.021960</td>\n",
       "      <td>-0.004045</td>\n",
       "      <td>0.024257</td>\n",
       "      <td>0.147584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cbc_eosinophil_c</th>\n",
       "      <td>-0.010186</td>\n",
       "      <td>-0.010186</td>\n",
       "      <td>-0.056693</td>\n",
       "      <td>-0.028611</td>\n",
       "      <td>-0.031720</td>\n",
       "      <td>0.032620</td>\n",
       "      <td>0.020709</td>\n",
       "      <td>-0.011299</td>\n",
       "      <td>0.016372</td>\n",
       "      <td>-0.172728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186129</td>\n",
       "      <td>0.702266</td>\n",
       "      <td>0.057141</td>\n",
       "      <td>0.025359</td>\n",
       "      <td>0.051368</td>\n",
       "      <td>-0.030097</td>\n",
       "      <td>-0.037181</td>\n",
       "      <td>0.023790</td>\n",
       "      <td>0.024046</td>\n",
       "      <td>0.002132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cbc_eosinophil_perc.1</th>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>-0.122416</td>\n",
       "      <td>-0.003148</td>\n",
       "      <td>-0.102094</td>\n",
       "      <td>0.056011</td>\n",
       "      <td>0.026571</td>\n",
       "      <td>0.017027</td>\n",
       "      <td>-0.037053</td>\n",
       "      <td>-0.156211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083970</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>0.067240</td>\n",
       "      <td>-0.064207</td>\n",
       "      <td>-0.044503</td>\n",
       "      <td>0.030661</td>\n",
       "      <td>0.009270</td>\n",
       "      <td>-0.021485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cbc_monocyte_c</th>\n",
       "      <td>0.006011</td>\n",
       "      <td>0.006011</td>\n",
       "      <td>0.090950</td>\n",
       "      <td>-0.068070</td>\n",
       "      <td>0.100502</td>\n",
       "      <td>-0.037211</td>\n",
       "      <td>-0.019228</td>\n",
       "      <td>-0.002565</td>\n",
       "      <td>0.078115</td>\n",
       "      <td>-0.033168</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.059593</td>\n",
       "      <td>-0.022803</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>-0.042564</td>\n",
       "      <td>-0.007272</td>\n",
       "      <td>0.011405</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>0.045531</td>\n",
       "      <td>-0.001810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cbc_eosinophil_perc.2</th>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>-0.122416</td>\n",
       "      <td>-0.003148</td>\n",
       "      <td>-0.102094</td>\n",
       "      <td>0.056011</td>\n",
       "      <td>0.026571</td>\n",
       "      <td>0.017027</td>\n",
       "      <td>-0.037053</td>\n",
       "      <td>-0.156211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083970</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>0.067240</td>\n",
       "      <td>-0.064207</td>\n",
       "      <td>-0.044503</td>\n",
       "      <td>0.030661</td>\n",
       "      <td>0.009270</td>\n",
       "      <td>-0.021485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_sodium</th>\n",
       "      <td>0.039232</td>\n",
       "      <td>0.039232</td>\n",
       "      <td>-0.139857</td>\n",
       "      <td>-0.077553</td>\n",
       "      <td>-0.062122</td>\n",
       "      <td>0.089829</td>\n",
       "      <td>0.119920</td>\n",
       "      <td>0.012110</td>\n",
       "      <td>-0.013692</td>\n",
       "      <td>0.055314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022803</td>\n",
       "      <td>0.083970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.134295</td>\n",
       "      <td>0.721939</td>\n",
       "      <td>-0.235284</td>\n",
       "      <td>-0.002077</td>\n",
       "      <td>-0.139260</td>\n",
       "      <td>0.040876</td>\n",
       "      <td>0.207628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_potassium</th>\n",
       "      <td>-0.005859</td>\n",
       "      <td>-0.005859</td>\n",
       "      <td>0.123330</td>\n",
       "      <td>0.129890</td>\n",
       "      <td>-0.048065</td>\n",
       "      <td>-0.016583</td>\n",
       "      <td>-0.055991</td>\n",
       "      <td>-0.118440</td>\n",
       "      <td>0.118477</td>\n",
       "      <td>-0.173582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>-0.134295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034364</td>\n",
       "      <td>0.189133</td>\n",
       "      <td>0.052079</td>\n",
       "      <td>0.104493</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-0.057138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_chloride</th>\n",
       "      <td>0.026758</td>\n",
       "      <td>0.026758</td>\n",
       "      <td>-0.145144</td>\n",
       "      <td>-0.137116</td>\n",
       "      <td>-0.073826</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.036059</td>\n",
       "      <td>0.099202</td>\n",
       "      <td>-0.008239</td>\n",
       "      <td>0.030194</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042564</td>\n",
       "      <td>0.067240</td>\n",
       "      <td>0.721939</td>\n",
       "      <td>-0.034364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.258474</td>\n",
       "      <td>-0.014191</td>\n",
       "      <td>-0.127214</td>\n",
       "      <td>-0.148060</td>\n",
       "      <td>0.066461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_glucose</th>\n",
       "      <td>-0.010492</td>\n",
       "      <td>-0.010492</td>\n",
       "      <td>0.125331</td>\n",
       "      <td>0.097948</td>\n",
       "      <td>0.074114</td>\n",
       "      <td>0.052785</td>\n",
       "      <td>0.017755</td>\n",
       "      <td>-0.105208</td>\n",
       "      <td>0.076232</td>\n",
       "      <td>0.057657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007272</td>\n",
       "      <td>-0.064207</td>\n",
       "      <td>-0.235284</td>\n",
       "      <td>0.189133</td>\n",
       "      <td>-0.258474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002650</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>0.043708</td>\n",
       "      <td>-0.066460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_ast</th>\n",
       "      <td>-0.036648</td>\n",
       "      <td>-0.036648</td>\n",
       "      <td>0.098732</td>\n",
       "      <td>-0.014016</td>\n",
       "      <td>0.025044</td>\n",
       "      <td>-0.058817</td>\n",
       "      <td>-0.010922</td>\n",
       "      <td>-0.052456</td>\n",
       "      <td>0.037055</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011405</td>\n",
       "      <td>-0.044503</td>\n",
       "      <td>-0.002077</td>\n",
       "      <td>0.052079</td>\n",
       "      <td>-0.014191</td>\n",
       "      <td>-0.002650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.168172</td>\n",
       "      <td>-0.057133</td>\n",
       "      <td>-0.072939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_alkaline_phosphatase</th>\n",
       "      <td>-0.011070</td>\n",
       "      <td>-0.011070</td>\n",
       "      <td>0.117501</td>\n",
       "      <td>-0.091849</td>\n",
       "      <td>0.123586</td>\n",
       "      <td>-0.102502</td>\n",
       "      <td>-0.091883</td>\n",
       "      <td>-0.005379</td>\n",
       "      <td>0.099776</td>\n",
       "      <td>-0.187236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>0.030661</td>\n",
       "      <td>-0.139260</td>\n",
       "      <td>0.104493</td>\n",
       "      <td>-0.127214</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>0.168172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.050349</td>\n",
       "      <td>-0.235270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_total_protein</th>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>-0.169298</td>\n",
       "      <td>-0.147716</td>\n",
       "      <td>0.046071</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.268447</td>\n",
       "      <td>0.037321</td>\n",
       "      <td>-0.078270</td>\n",
       "      <td>0.127008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045531</td>\n",
       "      <td>0.009270</td>\n",
       "      <td>0.040876</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-0.148060</td>\n",
       "      <td>0.043708</td>\n",
       "      <td>-0.057133</td>\n",
       "      <td>-0.050349</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.614664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_albumin</th>\n",
       "      <td>0.045855</td>\n",
       "      <td>0.045855</td>\n",
       "      <td>-0.301735</td>\n",
       "      <td>-0.312481</td>\n",
       "      <td>0.021046</td>\n",
       "      <td>0.193473</td>\n",
       "      <td>0.288271</td>\n",
       "      <td>0.123265</td>\n",
       "      <td>-0.083926</td>\n",
       "      <td>0.030490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001810</td>\n",
       "      <td>-0.021485</td>\n",
       "      <td>0.207628</td>\n",
       "      <td>-0.057138</td>\n",
       "      <td>0.066461</td>\n",
       "      <td>-0.066460</td>\n",
       "      <td>-0.072939</td>\n",
       "      <td>-0.235270</td>\n",
       "      <td>0.614664</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             index     patno  Admitted       Age  heart_rate  \\\n",
       "index                     1.000000  1.000000 -0.030377 -0.071132   -0.014543   \n",
       "patno                     1.000000  1.000000 -0.030377 -0.071132   -0.014543   \n",
       "Admitted                 -0.030377 -0.030377  1.000000  0.259000    0.071533   \n",
       "Age                      -0.071132 -0.071132  0.259000  1.000000   -0.343054   \n",
       "heart_rate               -0.014543 -0.014543  0.071533 -0.343054    1.000000   \n",
       "sbp                      -0.013479 -0.013479 -0.034520  0.255632   -0.128325   \n",
       "dbp                      -0.002088 -0.002088 -0.083964  0.021500    0.032385   \n",
       "pulse_ox                  0.066634  0.066634 -0.187805 -0.233759   -0.018398   \n",
       "resp_rate                -0.031710 -0.031710  0.141345 -0.128765    0.397967   \n",
       "height                   -0.017314 -0.017314  0.006556  0.237857   -0.277916   \n",
       "wght                     -0.057584 -0.057584  0.138873  0.432725   -0.375283   \n",
       "cbc_wbc                  -0.005411 -0.005411  0.140818 -0.035561    0.127127   \n",
       "cbc_hematocrit            0.022097  0.022097 -0.201153 -0.134952    0.003627   \n",
       "cbc_hemoglobin            0.026712  0.026712 -0.218690 -0.179703    0.011397   \n",
       "cbc_platelets             0.034431  0.034431 -0.048104 -0.186491    0.156655   \n",
       "cbc_neutrophil_c          0.015320  0.015320  0.207518  0.000455    0.144446   \n",
       "cbc_eosinophil_perc       0.000322  0.000322 -0.122416 -0.003148   -0.102094   \n",
       "cbc_lymphocyte_c         -0.019357 -0.019357 -0.094380 -0.141078    0.050274   \n",
       "cbc_lymphocyte_perc      -0.009835 -0.009835 -0.234463 -0.197247   -0.030777   \n",
       "cbc_eosinophil_c         -0.010186 -0.010186 -0.056693 -0.028611   -0.031720   \n",
       "cbc_eosinophil_perc.1     0.000322  0.000322 -0.122416 -0.003148   -0.102094   \n",
       "cbc_monocyte_c            0.006011  0.006011  0.090950 -0.068070    0.100502   \n",
       "cbc_eosinophil_perc.2     0.000322  0.000322 -0.122416 -0.003148   -0.102094   \n",
       "cmp_sodium                0.039232  0.039232 -0.139857 -0.077553   -0.062122   \n",
       "cmp_potassium            -0.005859 -0.005859  0.123330  0.129890   -0.048065   \n",
       "cmp_chloride              0.026758  0.026758 -0.145144 -0.137116   -0.073826   \n",
       "cmp_glucose              -0.010492 -0.010492  0.125331  0.097948    0.074114   \n",
       "cmp_ast                  -0.036648 -0.036648  0.098732 -0.014016    0.025044   \n",
       "cmp_alkaline_phosphatase -0.011070 -0.011070  0.117501 -0.091849    0.123586   \n",
       "cmp_total_protein         0.016393  0.016393 -0.169298 -0.147716    0.046071   \n",
       "cmp_albumin               0.045855  0.045855 -0.301735 -0.312481    0.021046   \n",
       "\n",
       "                               sbp       dbp  pulse_ox  resp_rate    height  \\\n",
       "index                    -0.013479 -0.002088  0.066634  -0.031710 -0.017314   \n",
       "patno                    -0.013479 -0.002088  0.066634  -0.031710 -0.017314   \n",
       "Admitted                 -0.034520 -0.083964 -0.187805   0.141345  0.006556   \n",
       "Age                       0.255632  0.021500 -0.233759  -0.128765  0.237857   \n",
       "heart_rate               -0.128325  0.032385 -0.018398   0.397967 -0.277916   \n",
       "sbp                       1.000000  0.700990  0.012399  -0.054224  0.129512   \n",
       "dbp                       0.700990  1.000000  0.044760  -0.038692  0.178501   \n",
       "pulse_ox                  0.012399  0.044760  1.000000  -0.203094  0.003070   \n",
       "resp_rate                -0.054224 -0.038692 -0.203094   1.000000 -0.339655   \n",
       "height                    0.129512  0.178501  0.003070  -0.339655  1.000000   \n",
       "wght                      0.256390  0.191655 -0.130171  -0.299886  0.506950   \n",
       "cbc_wbc                  -0.044712 -0.035427 -0.053765   0.107466 -0.006946   \n",
       "cbc_hematocrit            0.123147  0.271443 -0.049715  -0.037861  0.100637   \n",
       "cbc_hemoglobin            0.118943  0.280105 -0.006979  -0.052274  0.092058   \n",
       "cbc_platelets            -0.004040  0.034225  0.040013   0.078875 -0.241994   \n",
       "cbc_neutrophil_c         -0.054473 -0.051273 -0.068710   0.101723  0.073823   \n",
       "cbc_eosinophil_perc       0.056011  0.026571  0.017027  -0.037053 -0.156211   \n",
       "cbc_lymphocyte_c          0.009810  0.048564  0.007033   0.099687 -0.328064   \n",
       "cbc_lymphocyte_perc      -0.001484  0.058332  0.094088   0.013950 -0.297477   \n",
       "cbc_eosinophil_c          0.032620  0.020709 -0.011299   0.016372 -0.172728   \n",
       "cbc_eosinophil_perc.1     0.056011  0.026571  0.017027  -0.037053 -0.156211   \n",
       "cbc_monocyte_c           -0.037211 -0.019228 -0.002565   0.078115 -0.033168   \n",
       "cbc_eosinophil_perc.2     0.056011  0.026571  0.017027  -0.037053 -0.156211   \n",
       "cmp_sodium                0.089829  0.119920  0.012110  -0.013692  0.055314   \n",
       "cmp_potassium            -0.016583 -0.055991 -0.118440   0.118477 -0.173582   \n",
       "cmp_chloride              0.003022  0.036059  0.099202  -0.008239  0.030194   \n",
       "cmp_glucose               0.052785  0.017755 -0.105208   0.076232  0.057657   \n",
       "cmp_ast                  -0.058817 -0.010922 -0.052456   0.037055  0.005574   \n",
       "cmp_alkaline_phosphatase -0.102502 -0.091883 -0.005379   0.099776 -0.187236   \n",
       "cmp_total_protein         0.195652  0.268447  0.037321  -0.078270  0.127008   \n",
       "cmp_albumin               0.193473  0.288271  0.123265  -0.083926  0.030490   \n",
       "\n",
       "                          ...  cbc_monocyte_c  cbc_eosinophil_perc.2  \\\n",
       "index                     ...        0.006011               0.000322   \n",
       "patno                     ...        0.006011               0.000322   \n",
       "Admitted                  ...        0.090950              -0.122416   \n",
       "Age                       ...       -0.068070              -0.003148   \n",
       "heart_rate                ...        0.100502              -0.102094   \n",
       "sbp                       ...       -0.037211               0.056011   \n",
       "dbp                       ...       -0.019228               0.026571   \n",
       "pulse_ox                  ...       -0.002565               0.017027   \n",
       "resp_rate                 ...        0.078115              -0.037053   \n",
       "height                    ...       -0.033168              -0.156211   \n",
       "wght                      ...       -0.046526               0.035913   \n",
       "cbc_wbc                   ...        0.509534              -0.116462   \n",
       "cbc_hematocrit            ...        0.021607              -0.009774   \n",
       "cbc_hemoglobin            ...        0.024400              -0.023797   \n",
       "cbc_platelets             ...        0.189150               0.015036   \n",
       "cbc_neutrophil_c          ...        0.442835              -0.231476   \n",
       "cbc_eosinophil_perc       ...       -0.059593               1.000000   \n",
       "cbc_lymphocyte_c          ...        0.155681               0.082187   \n",
       "cbc_lymphocyte_perc       ...       -0.163475               0.236394   \n",
       "cbc_eosinophil_c          ...        0.186129               0.702266   \n",
       "cbc_eosinophil_perc.1     ...       -0.059593               1.000000   \n",
       "cbc_monocyte_c            ...        1.000000              -0.059593   \n",
       "cbc_eosinophil_perc.2     ...       -0.059593               1.000000   \n",
       "cmp_sodium                ...       -0.022803               0.083970   \n",
       "cmp_potassium             ...        0.006029               0.014421   \n",
       "cmp_chloride              ...       -0.042564               0.067240   \n",
       "cmp_glucose               ...       -0.007272              -0.064207   \n",
       "cmp_ast                   ...        0.011405              -0.044503   \n",
       "cmp_alkaline_phosphatase  ...        0.009640               0.030661   \n",
       "cmp_total_protein         ...        0.045531               0.009270   \n",
       "cmp_albumin               ...       -0.001810              -0.021485   \n",
       "\n",
       "                          cmp_sodium  cmp_potassium  cmp_chloride  \\\n",
       "index                       0.039232      -0.005859      0.026758   \n",
       "patno                       0.039232      -0.005859      0.026758   \n",
       "Admitted                   -0.139857       0.123330     -0.145144   \n",
       "Age                        -0.077553       0.129890     -0.137116   \n",
       "heart_rate                 -0.062122      -0.048065     -0.073826   \n",
       "sbp                         0.089829      -0.016583      0.003022   \n",
       "dbp                         0.119920      -0.055991      0.036059   \n",
       "pulse_ox                    0.012110      -0.118440      0.099202   \n",
       "resp_rate                  -0.013692       0.118477     -0.008239   \n",
       "height                      0.055314      -0.173582      0.030194   \n",
       "wght                        0.031168      -0.001168     -0.009780   \n",
       "cbc_wbc                    -0.031298       0.052575     -0.036382   \n",
       "cbc_hematocrit              0.208495      -0.039061      0.058504   \n",
       "cbc_hemoglobin              0.152671      -0.086993      0.032291   \n",
       "cbc_platelets               0.000126       0.012827     -0.035093   \n",
       "cbc_neutrophil_c           -0.055907       0.059657     -0.061286   \n",
       "cbc_eosinophil_perc         0.083970       0.014421      0.067240   \n",
       "cbc_lymphocyte_c            0.106285       0.018151      0.097709   \n",
       "cbc_lymphocyte_perc         0.146085      -0.073324      0.170409   \n",
       "cbc_eosinophil_c            0.057141       0.025359      0.051368   \n",
       "cbc_eosinophil_perc.1       0.083970       0.014421      0.067240   \n",
       "cbc_monocyte_c             -0.022803       0.006029     -0.042564   \n",
       "cbc_eosinophil_perc.2       0.083970       0.014421      0.067240   \n",
       "cmp_sodium                  1.000000      -0.134295      0.721939   \n",
       "cmp_potassium              -0.134295       1.000000     -0.034364   \n",
       "cmp_chloride                0.721939      -0.034364      1.000000   \n",
       "cmp_glucose                -0.235284       0.189133     -0.258474   \n",
       "cmp_ast                    -0.002077       0.052079     -0.014191   \n",
       "cmp_alkaline_phosphatase   -0.139260       0.104493     -0.127214   \n",
       "cmp_total_protein           0.040876       0.000182     -0.148060   \n",
       "cmp_albumin                 0.207628      -0.057138      0.066461   \n",
       "\n",
       "                          cmp_glucose   cmp_ast  cmp_alkaline_phosphatase  \\\n",
       "index                       -0.010492 -0.036648                 -0.011070   \n",
       "patno                       -0.010492 -0.036648                 -0.011070   \n",
       "Admitted                     0.125331  0.098732                  0.117501   \n",
       "Age                          0.097948 -0.014016                 -0.091849   \n",
       "heart_rate                   0.074114  0.025044                  0.123586   \n",
       "sbp                          0.052785 -0.058817                 -0.102502   \n",
       "dbp                          0.017755 -0.010922                 -0.091883   \n",
       "pulse_ox                    -0.105208 -0.052456                 -0.005379   \n",
       "resp_rate                    0.076232  0.037055                  0.099776   \n",
       "height                       0.057657  0.005574                 -0.187236   \n",
       "wght                         0.117112  0.013699                 -0.201825   \n",
       "cbc_wbc                      0.079747  0.038337                  0.038098   \n",
       "cbc_hematocrit               0.008516  0.018966                 -0.155929   \n",
       "cbc_hemoglobin              -0.009205  0.014291                 -0.158250   \n",
       "cbc_platelets                0.032876 -0.072822                  0.036632   \n",
       "cbc_neutrophil_c             0.117837  0.030051                  0.028203   \n",
       "cbc_eosinophil_perc         -0.064207 -0.044503                  0.030661   \n",
       "cbc_lymphocyte_c            -0.035040 -0.017489                  0.002187   \n",
       "cbc_lymphocyte_perc         -0.129518 -0.021960                 -0.004045   \n",
       "cbc_eosinophil_c            -0.030097 -0.037181                  0.023790   \n",
       "cbc_eosinophil_perc.1       -0.064207 -0.044503                  0.030661   \n",
       "cbc_monocyte_c              -0.007272  0.011405                  0.009640   \n",
       "cbc_eosinophil_perc.2       -0.064207 -0.044503                  0.030661   \n",
       "cmp_sodium                  -0.235284 -0.002077                 -0.139260   \n",
       "cmp_potassium                0.189133  0.052079                  0.104493   \n",
       "cmp_chloride                -0.258474 -0.014191                 -0.127214   \n",
       "cmp_glucose                  1.000000 -0.002650                  0.051861   \n",
       "cmp_ast                     -0.002650  1.000000                  0.168172   \n",
       "cmp_alkaline_phosphatase     0.051861  0.168172                  1.000000   \n",
       "cmp_total_protein            0.043708 -0.057133                 -0.050349   \n",
       "cmp_albumin                 -0.066460 -0.072939                 -0.235270   \n",
       "\n",
       "                          cmp_total_protein  cmp_albumin  \n",
       "index                              0.016393     0.045855  \n",
       "patno                              0.016393     0.045855  \n",
       "Admitted                          -0.169298    -0.301735  \n",
       "Age                               -0.147716    -0.312481  \n",
       "heart_rate                         0.046071     0.021046  \n",
       "sbp                                0.195652     0.193473  \n",
       "dbp                                0.268447     0.288271  \n",
       "pulse_ox                           0.037321     0.123265  \n",
       "resp_rate                         -0.078270    -0.083926  \n",
       "height                             0.127008     0.030490  \n",
       "wght                               0.089641    -0.087129  \n",
       "cbc_wbc                            0.011260    -0.020093  \n",
       "cbc_hematocrit                     0.403966     0.522731  \n",
       "cbc_hemoglobin                     0.389195     0.545362  \n",
       "cbc_platelets                      0.224736     0.124224  \n",
       "cbc_neutrophil_c                   0.008387    -0.044713  \n",
       "cbc_eosinophil_perc                0.009270    -0.021485  \n",
       "cbc_lymphocyte_c                   0.028924     0.132946  \n",
       "cbc_lymphocyte_perc                0.024257     0.147584  \n",
       "cbc_eosinophil_c                   0.024046     0.002132  \n",
       "cbc_eosinophil_perc.1              0.009270    -0.021485  \n",
       "cbc_monocyte_c                     0.045531    -0.001810  \n",
       "cbc_eosinophil_perc.2              0.009270    -0.021485  \n",
       "cmp_sodium                         0.040876     0.207628  \n",
       "cmp_potassium                      0.000182    -0.057138  \n",
       "cmp_chloride                      -0.148060     0.066461  \n",
       "cmp_glucose                        0.043708    -0.066460  \n",
       "cmp_ast                           -0.057133    -0.072939  \n",
       "cmp_alkaline_phosphatase          -0.050349    -0.235270  \n",
       "cmp_total_protein                  1.000000     0.614664  \n",
       "cmp_albumin                        0.614664     1.000000  \n",
       "\n",
       "[31 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None Detected    6910\n",
      "Detected          470\n",
      "Name: COVIDResult, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[target].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Inspect Null Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of NULL Data Points: 69411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "index                          0\n",
       "patno                          0\n",
       "Admitted                       0\n",
       "AdmittingDepartment         4377\n",
       "COVIDResult                    0\n",
       "Age                            0\n",
       "FirstRace                      1\n",
       "Ethnicity                      0\n",
       "Sex                            0\n",
       "heart_rate                    28\n",
       "sbp                           88\n",
       "dbp                           88\n",
       "pulse_ox                      34\n",
       "resp_rate                     68\n",
       "height                      6924\n",
       "wght                        4132\n",
       "cbc_wbc                     1124\n",
       "cbc_hematocrit              1124\n",
       "cbc_hemoglobin              1123\n",
       "cbc_platelets               1124\n",
       "cbc_neutrophil_c            3507\n",
       "cbc_eosinophil_perc         3508\n",
       "cbc_lymphocyte_c            3506\n",
       "cbc_lymphocyte_perc         3506\n",
       "cbc_eosinophil_c            3508\n",
       "cbc_eosinophil_perc.1       3508\n",
       "cbc_monocyte_c              3506\n",
       "cbc_eosinophil_perc.2       3508\n",
       "cmp_sodium                  1094\n",
       "cmp_potassium               1810\n",
       "cmp_chloride                1094\n",
       "cmp_bicarbonate             1104\n",
       "cmp_bun                     1094\n",
       "cmp_creatinine              1094\n",
       "cmp_glucose                 1094\n",
       "cmp_alt                     1979\n",
       "cmp_ast                     2613\n",
       "cmp_alkaline_phosphatase    1981\n",
       "cmp_total_protein           2205\n",
       "cmp_albumin                 1978\n",
       "cmp_bilirubin               1979\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total Number of NULL Data Points:', df.isnull().sum().sum())\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = {\n",
    "    col: round(df[col].isnull().sum() * 100 / len(df[col]), 4)\n",
    "    for col in df\n",
    "}\n",
    "d = dict(sorted(d.items(), key=lambda item: item[1], reverse=True))\n",
    "majority_null = [k for k, v in d.items() if v > 50.0]\n",
    "\n",
    "# print(\"Null Data Points by variable\")\n",
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "msno.matrix(df)\n",
    "# msno.heatmap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admitted</th>\n",
       "      <th>COVIDResult</th>\n",
       "      <th>Age</th>\n",
       "      <th>FirstRace</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Sex</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pulse_ox</th>\n",
       "      <th>...</th>\n",
       "      <th>cmp_bicarbonate</th>\n",
       "      <th>cmp_bun</th>\n",
       "      <th>cmp_creatinine</th>\n",
       "      <th>cmp_glucose</th>\n",
       "      <th>cmp_alt</th>\n",
       "      <th>cmp_ast</th>\n",
       "      <th>cmp_alkaline_phosphatase</th>\n",
       "      <th>cmp_total_protein</th>\n",
       "      <th>cmp_albumin</th>\n",
       "      <th>cmp_bilirubin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>78</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>94.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>14</td>\n",
       "      <td>26.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>23</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>121.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>0.9</td>\n",
       "      <td>83.0</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>55</td>\n",
       "      <td>African American</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>83.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>123.0</td>\n",
       "      <td>26</td>\n",
       "      <td>29.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>50</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>88.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>1.6</td>\n",
       "      <td>297.0</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>67</td>\n",
       "      <td>African American</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>90.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Admitted    COVIDResult  Age           FirstRace     Ethnicity     Sex  \\\n",
       "0         1  None Detected   78  White or Caucasian  Non-Hispanic  Female   \n",
       "1         0  None Detected   23  White or Caucasian  Non-Hispanic  Female   \n",
       "2         0  None Detected   55    African American  Non-Hispanic    Male   \n",
       "3         1  None Detected   50  White or Caucasian  Non-Hispanic    Male   \n",
       "4         0  None Detected   67    African American  Non-Hispanic  Female   \n",
       "\n",
       "   heart_rate    sbp   dbp  pulse_ox  ...  cmp_bicarbonate  cmp_bun  \\\n",
       "0        94.0  138.0  82.0      96.0  ...               26       31   \n",
       "1       121.0  134.0  88.0      98.0  ...               19       11   \n",
       "2        83.0  152.0  76.0      98.0  ...               23        9   \n",
       "3        88.0  138.0  65.0      87.0  ...               30       45   \n",
       "4        90.0  128.0  69.0      98.0  ...               27       25   \n",
       "\n",
       "   cmp_creatinine  cmp_glucose  cmp_alt  cmp_ast  cmp_alkaline_phosphatase  \\\n",
       "0             2.5         82.0       14     26.0                      80.0   \n",
       "1             0.9         83.0       73      NaN                     100.0   \n",
       "2             1.2        123.0       26     29.0                     106.0   \n",
       "3             1.6        297.0       22      NaN                      78.0   \n",
       "4             1.0         96.0       12     18.0                     122.0   \n",
       "\n",
       "   cmp_total_protein  cmp_albumin  cmp_bilirubin  \n",
       "0                8.5          4.3            0.5  \n",
       "1                8.1          4.6            0.6  \n",
       "2                7.1          4.0            0.7  \n",
       "3                7.8          3.7            0.5  \n",
       "4                7.4          3.5            0.2  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trim_df = df.drop(columns=majority_null)\n",
    "trim_df = trim_df.drop(columns=['index', 'patno'])\n",
    "trim_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53978"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trim_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Handle Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COVIDResult', 'FirstRace', 'Ethnicity', 'Sex', 'cmp_bicarbonate',\n",
       "       'cmp_bun', 'cmp_creatinine', 'cmp_alt', 'cmp_bilirubin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trim_df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.2.1 Manual Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admitted</th>\n",
       "      <th>COVIDResult</th>\n",
       "      <th>Age</th>\n",
       "      <th>FirstRace</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Sex</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pulse_ox</th>\n",
       "      <th>...</th>\n",
       "      <th>cmp_bicarbonate</th>\n",
       "      <th>cmp_bun</th>\n",
       "      <th>cmp_creatinine</th>\n",
       "      <th>cmp_glucose</th>\n",
       "      <th>cmp_alt</th>\n",
       "      <th>cmp_ast</th>\n",
       "      <th>cmp_alkaline_phosphatase</th>\n",
       "      <th>cmp_total_protein</th>\n",
       "      <th>cmp_albumin</th>\n",
       "      <th>cmp_bilirubin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>78</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>94.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>23</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>121.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>83.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>55</td>\n",
       "      <td>African American</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>83.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>123.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>50</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>88.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>297.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>67</td>\n",
       "      <td>African American</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>90.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Admitted    COVIDResult  Age           FirstRace     Ethnicity     Sex  \\\n",
       "0         1  None Detected   78  White or Caucasian  Non-Hispanic  Female   \n",
       "1         0  None Detected   23  White or Caucasian  Non-Hispanic  Female   \n",
       "2         0  None Detected   55    African American  Non-Hispanic    Male   \n",
       "3         1  None Detected   50  White or Caucasian  Non-Hispanic    Male   \n",
       "4         0  None Detected   67    African American  Non-Hispanic  Female   \n",
       "\n",
       "   heart_rate    sbp   dbp  pulse_ox  ...  cmp_bicarbonate  cmp_bun  \\\n",
       "0        94.0  138.0  82.0      96.0  ...             26.0     31.0   \n",
       "1       121.0  134.0  88.0      98.0  ...             19.0     11.0   \n",
       "2        83.0  152.0  76.0      98.0  ...             23.0      9.0   \n",
       "3        88.0  138.0  65.0      87.0  ...             30.0     45.0   \n",
       "4        90.0  128.0  69.0      98.0  ...             27.0     25.0   \n",
       "\n",
       "   cmp_creatinine  cmp_glucose  cmp_alt  cmp_ast  cmp_alkaline_phosphatase  \\\n",
       "0             2.5         82.0     14.0     26.0                      80.0   \n",
       "1             0.9         83.0     73.0      NaN                     100.0   \n",
       "2             1.2        123.0     26.0     29.0                     106.0   \n",
       "3             1.6        297.0     22.0      NaN                      78.0   \n",
       "4             1.0         96.0     12.0     18.0                     122.0   \n",
       "\n",
       "   cmp_total_protein  cmp_albumin  cmp_bilirubin  \n",
       "0                8.5          4.3            0.5  \n",
       "1                8.1          4.6            0.6  \n",
       "2                7.1          4.0            0.7  \n",
       "3                7.8          3.7            0.5  \n",
       "4                7.4          3.5            0.2  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = [\n",
    "    'cmp_bicarbonate', 'cmp_bun', 'cmp_creatinine', 'cmp_alt', 'cmp_bilirubin'\n",
    "]\n",
    "less_than_list = [\n",
    "    '<5', '<2', '<0.2', '<6', '<0.1'\n",
    "]\n",
    "\n",
    "\n",
    "def replace_cat(val, less, num):\n",
    "    if val == less:\n",
    "        return random.uniform(0, num) if \".\" in less else random.randint(0, num)\n",
    "    else:\n",
    "        return float(val)\n",
    "\n",
    "    \n",
    "trim_df2 = trim_df.copy()\n",
    "for col, less_than in zip(cat_cols, less_than_list):\n",
    "    upper_range = float(less_than[1:])\n",
    "    trim_df2[col] = trim_df2[col].apply(lambda x: replace_cat(x, less_than, upper_range))\n",
    "\n",
    "trim_df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7380 entries, 0 to 7379\n",
      "Data columns (total 36 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Admitted                  7380 non-null   int64  \n",
      " 1   COVIDResult               7380 non-null   object \n",
      " 2   Age                       7380 non-null   int64  \n",
      " 3   FirstRace                 7379 non-null   object \n",
      " 4   Ethnicity                 7380 non-null   object \n",
      " 5   Sex                       7380 non-null   object \n",
      " 6   heart_rate                7352 non-null   float64\n",
      " 7   sbp                       7292 non-null   float64\n",
      " 8   dbp                       7292 non-null   float64\n",
      " 9   pulse_ox                  7346 non-null   float64\n",
      " 10  resp_rate                 7312 non-null   float64\n",
      " 11  cbc_wbc                   6256 non-null   float64\n",
      " 12  cbc_hematocrit            6256 non-null   float64\n",
      " 13  cbc_hemoglobin            6257 non-null   float64\n",
      " 14  cbc_platelets             6256 non-null   float64\n",
      " 15  cbc_neutrophil_c          3873 non-null   float64\n",
      " 16  cbc_eosinophil_perc       3872 non-null   float64\n",
      " 17  cbc_lymphocyte_c          3874 non-null   float64\n",
      " 18  cbc_lymphocyte_perc       3874 non-null   float64\n",
      " 19  cbc_eosinophil_c          3872 non-null   float64\n",
      " 20  cbc_eosinophil_perc.1     3872 non-null   float64\n",
      " 21  cbc_monocyte_c            3874 non-null   float64\n",
      " 22  cbc_eosinophil_perc.2     3872 non-null   float64\n",
      " 23  cmp_sodium                6286 non-null   float64\n",
      " 24  cmp_potassium             5570 non-null   float64\n",
      " 25  cmp_chloride              6286 non-null   float64\n",
      " 26  cmp_bicarbonate           6276 non-null   float64\n",
      " 27  cmp_bun                   6286 non-null   float64\n",
      " 28  cmp_creatinine            6286 non-null   float64\n",
      " 29  cmp_glucose               6286 non-null   float64\n",
      " 30  cmp_alt                   5401 non-null   float64\n",
      " 31  cmp_ast                   4767 non-null   float64\n",
      " 32  cmp_alkaline_phosphatase  5399 non-null   float64\n",
      " 33  cmp_total_protein         5175 non-null   float64\n",
      " 34  cmp_albumin               5402 non-null   float64\n",
      " 35  cmp_bilirubin             5401 non-null   float64\n",
      "dtypes: float64(30), int64(2), object(4)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "trim_df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.2.2 Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admitted</th>\n",
       "      <th>COVIDResult</th>\n",
       "      <th>Age</th>\n",
       "      <th>FirstRace</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Sex</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pulse_ox</th>\n",
       "      <th>...</th>\n",
       "      <th>cmp_alt</th>\n",
       "      <th>cmp_ast</th>\n",
       "      <th>cmp_alkaline_phosphatase</th>\n",
       "      <th>cmp_total_protein</th>\n",
       "      <th>cmp_albumin</th>\n",
       "      <th>cmp_bilirubin</th>\n",
       "      <th>COVIDResult_Encoded</th>\n",
       "      <th>FirstRace_Encoded</th>\n",
       "      <th>Ethnicity_Encoded</th>\n",
       "      <th>Sex_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>78</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>94.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>23</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>121.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>55</td>\n",
       "      <td>African American</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>83.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>50</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>88.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>None Detected</td>\n",
       "      <td>67</td>\n",
       "      <td>African American</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>90.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Admitted    COVIDResult  Age           FirstRace     Ethnicity     Sex  \\\n",
       "0         1  None Detected   78  White or Caucasian  Non-Hispanic  Female   \n",
       "1         0  None Detected   23  White or Caucasian  Non-Hispanic  Female   \n",
       "2         0  None Detected   55    African American  Non-Hispanic    Male   \n",
       "3         1  None Detected   50  White or Caucasian  Non-Hispanic    Male   \n",
       "4         0  None Detected   67    African American  Non-Hispanic  Female   \n",
       "\n",
       "   heart_rate    sbp   dbp  pulse_ox  ...  cmp_alt  cmp_ast  \\\n",
       "0        94.0  138.0  82.0      96.0  ...     14.0     26.0   \n",
       "1       121.0  134.0  88.0      98.0  ...     73.0      NaN   \n",
       "2        83.0  152.0  76.0      98.0  ...     26.0     29.0   \n",
       "3        88.0  138.0  65.0      87.0  ...     22.0      NaN   \n",
       "4        90.0  128.0  69.0      98.0  ...     12.0     18.0   \n",
       "\n",
       "   cmp_alkaline_phosphatase  cmp_total_protein  cmp_albumin  cmp_bilirubin  \\\n",
       "0                      80.0                8.5          4.3            0.5   \n",
       "1                     100.0                8.1          4.6            0.6   \n",
       "2                     106.0                7.1          4.0            0.7   \n",
       "3                      78.0                7.8          3.7            0.5   \n",
       "4                     122.0                7.4          3.5            0.2   \n",
       "\n",
       "   COVIDResult_Encoded  FirstRace_Encoded  Ethnicity_Encoded  Sex_Encoded  \n",
       "0                  1.0                9.0                2.0          0.0  \n",
       "1                  1.0                9.0                2.0          0.0  \n",
       "2                  1.0                0.0                2.0          1.0  \n",
       "3                  1.0                9.0                2.0          1.0  \n",
       "4                  1.0                0.0                2.0          0.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = [\n",
    "    'COVIDResult', 'FirstRace', 'Ethnicity', 'Sex'\n",
    "]\n",
    "\n",
    "trim_df3 = trim_df2.copy()\n",
    "for col in cat_cols:\n",
    "    trim_df3[col] = trim_df3[col].fillna(\"Unspecified\")\n",
    "    enc = OrdinalEncoder()\n",
    "    trim_df3[col + \"_Encoded\"] = enc.fit_transform(trim_df3[[col]])\n",
    "trim_df3.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.2.3 Categorical Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**COVIDResult**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Detected', 0.0)\n",
      "('None Detected', 1.0)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**FirstRace**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('African American', 0.0)\n",
      "('American Indian and Alaska Native', 1.0)\n",
      "('Asian', 2.0)\n",
      "('Hispanic', 3.0)\n",
      "('Native Hawaiian and Other Pacific Islander', 4.0)\n",
      "('Other', 5.0)\n",
      "('Patient Refused', 6.0)\n",
      "('Patient Unavailable', 7.0)\n",
      "('Unspecified', 8.0)\n",
      "('White or Caucasian', 9.0)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Ethnicity**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('*Unspecified', 0.0)\n",
      "('Hispanic', 1.0)\n",
      "('Non-Hispanic', 2.0)\n",
      "('Patient Refused', 3.0)\n",
      "('Patient Unavailable', 4.0)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Sex**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Female', 0.0)\n",
      "('Male', 1.0)\n",
      "('Unknown', 2.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in cat_cols:\n",
    "    display(Markdown(\"**{}**\".format(col)))\n",
    "    for each in trim_df3.groupby([col, col + '_Encoded']).indices:\n",
    "        print(each)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admitted</th>\n",
       "      <th>Age</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pulse_ox</th>\n",
       "      <th>resp_rate</th>\n",
       "      <th>cbc_wbc</th>\n",
       "      <th>cbc_hematocrit</th>\n",
       "      <th>cbc_hemoglobin</th>\n",
       "      <th>...</th>\n",
       "      <th>cmp_alt</th>\n",
       "      <th>cmp_ast</th>\n",
       "      <th>cmp_alkaline_phosphatase</th>\n",
       "      <th>cmp_total_protein</th>\n",
       "      <th>cmp_albumin</th>\n",
       "      <th>cmp_bilirubin</th>\n",
       "      <th>COVIDResult_Encoded</th>\n",
       "      <th>FirstRace_Encoded</th>\n",
       "      <th>Ethnicity_Encoded</th>\n",
       "      <th>Sex_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>94.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.01</td>\n",
       "      <td>34.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>121.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.04</td>\n",
       "      <td>36.2</td>\n",
       "      <td>11.9</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>83.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.13</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>88.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>32.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>90.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.56</td>\n",
       "      <td>31.7</td>\n",
       "      <td>9.8</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Admitted  Age  heart_rate    sbp   dbp  pulse_ox  resp_rate  cbc_wbc  \\\n",
       "0         1   78        94.0  138.0  82.0      96.0       29.0    14.01   \n",
       "1         0   23       121.0  134.0  88.0      98.0       18.0     5.04   \n",
       "2         0   55        83.0  152.0  76.0      98.0       21.0     7.13   \n",
       "3         1   50        88.0  138.0  65.0      87.0       18.0     5.74   \n",
       "4         0   67        90.0  128.0  69.0      98.0       18.0    10.56   \n",
       "\n",
       "   cbc_hematocrit  cbc_hemoglobin  ...  cmp_alt  cmp_ast  \\\n",
       "0            34.1            11.0  ...     14.0     26.0   \n",
       "1            36.2            11.9  ...     73.0      NaN   \n",
       "2            36.0            12.0  ...     26.0     29.0   \n",
       "3            32.9            11.6  ...     22.0      NaN   \n",
       "4            31.7             9.8  ...     12.0     18.0   \n",
       "\n",
       "   cmp_alkaline_phosphatase  cmp_total_protein  cmp_albumin  cmp_bilirubin  \\\n",
       "0                      80.0                8.5          4.3            0.5   \n",
       "1                     100.0                8.1          4.6            0.6   \n",
       "2                     106.0                7.1          4.0            0.7   \n",
       "3                      78.0                7.8          3.7            0.5   \n",
       "4                     122.0                7.4          3.5            0.2   \n",
       "\n",
       "   COVIDResult_Encoded  FirstRace_Encoded  Ethnicity_Encoded  Sex_Encoded  \n",
       "0                  1.0                9.0                2.0          0.0  \n",
       "1                  1.0                9.0                2.0          0.0  \n",
       "2                  1.0                0.0                2.0          1.0  \n",
       "3                  1.0                9.0                2.0          1.0  \n",
       "4                  1.0                0.0                2.0          0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trim_df3 = trim_df3.drop(columns=['COVIDResult', 'FirstRace', 'Ethnicity', 'Sex'])\n",
    "trim_df3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7380, 36)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trim_df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7380 entries, 0 to 7379\n",
      "Data columns (total 36 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Admitted                  7380 non-null   int64  \n",
      " 1   Age                       7380 non-null   int64  \n",
      " 2   heart_rate                7352 non-null   float64\n",
      " 3   sbp                       7292 non-null   float64\n",
      " 4   dbp                       7292 non-null   float64\n",
      " 5   pulse_ox                  7346 non-null   float64\n",
      " 6   resp_rate                 7312 non-null   float64\n",
      " 7   cbc_wbc                   6256 non-null   float64\n",
      " 8   cbc_hematocrit            6256 non-null   float64\n",
      " 9   cbc_hemoglobin            6257 non-null   float64\n",
      " 10  cbc_platelets             6256 non-null   float64\n",
      " 11  cbc_neutrophil_c          3873 non-null   float64\n",
      " 12  cbc_eosinophil_perc       3872 non-null   float64\n",
      " 13  cbc_lymphocyte_c          3874 non-null   float64\n",
      " 14  cbc_lymphocyte_perc       3874 non-null   float64\n",
      " 15  cbc_eosinophil_c          3872 non-null   float64\n",
      " 16  cbc_eosinophil_perc.1     3872 non-null   float64\n",
      " 17  cbc_monocyte_c            3874 non-null   float64\n",
      " 18  cbc_eosinophil_perc.2     3872 non-null   float64\n",
      " 19  cmp_sodium                6286 non-null   float64\n",
      " 20  cmp_potassium             5570 non-null   float64\n",
      " 21  cmp_chloride              6286 non-null   float64\n",
      " 22  cmp_bicarbonate           6276 non-null   float64\n",
      " 23  cmp_bun                   6286 non-null   float64\n",
      " 24  cmp_creatinine            6286 non-null   float64\n",
      " 25  cmp_glucose               6286 non-null   float64\n",
      " 26  cmp_alt                   5401 non-null   float64\n",
      " 27  cmp_ast                   4767 non-null   float64\n",
      " 28  cmp_alkaline_phosphatase  5399 non-null   float64\n",
      " 29  cmp_total_protein         5175 non-null   float64\n",
      " 30  cmp_albumin               5402 non-null   float64\n",
      " 31  cmp_bilirubin             5401 non-null   float64\n",
      " 32  COVIDResult_Encoded       7380 non-null   float64\n",
      " 33  FirstRace_Encoded         7380 non-null   float64\n",
      " 34  Ethnicity_Encoded         7380 non-null   float64\n",
      " 35  Sex_Encoded               7380 non-null   float64\n",
      "dtypes: float64(34), int64(2)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "trim_df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admitted</th>\n",
       "      <th>Age</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pulse_ox</th>\n",
       "      <th>resp_rate</th>\n",
       "      <th>cbc_wbc</th>\n",
       "      <th>cbc_hematocrit</th>\n",
       "      <th>cbc_hemoglobin</th>\n",
       "      <th>...</th>\n",
       "      <th>cmp_alt</th>\n",
       "      <th>cmp_ast</th>\n",
       "      <th>cmp_alkaline_phosphatase</th>\n",
       "      <th>cmp_total_protein</th>\n",
       "      <th>cmp_albumin</th>\n",
       "      <th>cmp_bilirubin</th>\n",
       "      <th>COVIDResult_Encoded</th>\n",
       "      <th>FirstRace_Encoded</th>\n",
       "      <th>Ethnicity_Encoded</th>\n",
       "      <th>Sex_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>94.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.01</td>\n",
       "      <td>34.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>121.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.04</td>\n",
       "      <td>36.2</td>\n",
       "      <td>11.9</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>55.627858</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>83.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.13</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>106.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>88.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>32.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>55.627858</td>\n",
       "      <td>78.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>90.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.56</td>\n",
       "      <td>31.7</td>\n",
       "      <td>9.8</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>122.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Admitted  Age  heart_rate    sbp   dbp  pulse_ox  resp_rate  cbc_wbc  \\\n",
       "0         1   78        94.0  138.0  82.0      96.0       29.0    14.01   \n",
       "1         0   23       121.0  134.0  88.0      98.0       18.0     5.04   \n",
       "2         0   55        83.0  152.0  76.0      98.0       21.0     7.13   \n",
       "3         1   50        88.0  138.0  65.0      87.0       18.0     5.74   \n",
       "4         0   67        90.0  128.0  69.0      98.0       18.0    10.56   \n",
       "\n",
       "   cbc_hematocrit  cbc_hemoglobin  ...  cmp_alt    cmp_ast  \\\n",
       "0            34.1            11.0  ...     14.0  26.000000   \n",
       "1            36.2            11.9  ...     73.0  55.627858   \n",
       "2            36.0            12.0  ...     26.0  29.000000   \n",
       "3            32.9            11.6  ...     22.0  55.627858   \n",
       "4            31.7             9.8  ...     12.0  18.000000   \n",
       "\n",
       "   cmp_alkaline_phosphatase  cmp_total_protein  cmp_albumin  cmp_bilirubin  \\\n",
       "0                      80.0                8.5          4.3            0.5   \n",
       "1                     100.0                8.1          4.6            0.6   \n",
       "2                     106.0                7.1          4.0            0.7   \n",
       "3                      78.0                7.8          3.7            0.5   \n",
       "4                     122.0                7.4          3.5            0.2   \n",
       "\n",
       "   COVIDResult_Encoded  FirstRace_Encoded  Ethnicity_Encoded  Sex_Encoded  \n",
       "0                  1.0                9.0                2.0          0.0  \n",
       "1                  1.0                9.0                2.0          0.0  \n",
       "2                  1.0                0.0                2.0          1.0  \n",
       "3                  1.0                9.0                2.0          1.0  \n",
       "4                  1.0                0.0                2.0          0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = [\n",
    "    'heart_rate', 'sbp', 'dbp', 'pulse_ox', 'resp_rate', 'cbc_wbc', 'cbc_hematocrit', 'cbc_hemoglobin',\n",
    "    'cbc_platelets', 'cbc_neutrophil_c', 'cbc_eosinophil_perc', 'cbc_lymphocyte_c',\n",
    "    'cbc_lymphocyte_perc', 'cbc_eosinophil_c', 'cbc_eosinophil_perc.1', 'cbc_monocyte_c',\n",
    "    'cbc_eosinophil_perc.2', 'cmp_sodium', 'cmp_potassium', 'cmp_chloride', 'cmp_bicarbonate',\n",
    "    'cmp_bun', 'cmp_creatinine', 'cmp_glucose', 'cmp_alt', 'cmp_ast', 'cmp_alkaline_phosphatase',\n",
    "    'cmp_total_protein', 'cmp_albumin', 'cmp_bilirubin'\n",
    "]\n",
    "\n",
    "trim_df4 = trim_df3.copy()\n",
    "for col in num_cols:\n",
    "    trim_df4[col] = trim_df4[col].replace(np.NaN, trim_df4[col].mean())\n",
    "    \n",
    "trim_df4.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trim_df4.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_cols = [\n",
    "    'Admitted', 'FirstRace_Encoded', 'Ethnicity_Encoded', 'Sex_Encoded', 'COVIDResult_Encoded'\n",
    "]\n",
    "\n",
    "codes_df = trim_df4[code_cols]\n",
    "trim_df5 = trim_df4.drop(columns=code_cols)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(trim_df5)\n",
    "scaled_df = pd.DataFrame(data=scaled, columns=trim_df5.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pulse_ox</th>\n",
       "      <th>resp_rate</th>\n",
       "      <th>cbc_wbc</th>\n",
       "      <th>cbc_hematocrit</th>\n",
       "      <th>cbc_hemoglobin</th>\n",
       "      <th>cbc_platelets</th>\n",
       "      <th>...</th>\n",
       "      <th>cmp_ast</th>\n",
       "      <th>cmp_alkaline_phosphatase</th>\n",
       "      <th>cmp_total_protein</th>\n",
       "      <th>cmp_albumin</th>\n",
       "      <th>cmp_bilirubin</th>\n",
       "      <th>Admitted</th>\n",
       "      <th>FirstRace_Encoded</th>\n",
       "      <th>Ethnicity_Encoded</th>\n",
       "      <th>Sex_Encoded</th>\n",
       "      <th>COVIDResult_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.233730</td>\n",
       "      <td>-0.022731</td>\n",
       "      <td>0.073884</td>\n",
       "      <td>0.392190</td>\n",
       "      <td>-0.278428</td>\n",
       "      <td>1.184224</td>\n",
       "      <td>0.520132</td>\n",
       "      <td>-0.721388</td>\n",
       "      <td>-0.741784</td>\n",
       "      <td>0.616521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.239182</td>\n",
       "      <td>-0.443815</td>\n",
       "      <td>1.824984</td>\n",
       "      <td>0.917976</td>\n",
       "      <td>-0.234216</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.104301</td>\n",
       "      <td>1.135743</td>\n",
       "      <td>-0.073763</td>\n",
       "      <td>0.786661</td>\n",
       "      <td>0.244608</td>\n",
       "      <td>-0.450035</td>\n",
       "      <td>-0.702405</td>\n",
       "      <td>-0.383468</td>\n",
       "      <td>-0.337826</td>\n",
       "      <td>0.722131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.183931</td>\n",
       "      <td>1.258890</td>\n",
       "      <td>1.524718</td>\n",
       "      <td>-0.166295</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.256008</td>\n",
       "      <td>-0.494702</td>\n",
       "      <td>0.590651</td>\n",
       "      <td>-0.002281</td>\n",
       "      <td>0.244608</td>\n",
       "      <td>-0.004328</td>\n",
       "      <td>-0.417555</td>\n",
       "      <td>-0.415651</td>\n",
       "      <td>-0.292942</td>\n",
       "      <td>-0.091067</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214963</td>\n",
       "      <td>-0.105966</td>\n",
       "      <td>-0.156346</td>\n",
       "      <td>0.311233</td>\n",
       "      <td>-0.098374</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043460</td>\n",
       "      <td>-0.280170</td>\n",
       "      <td>0.073884</td>\n",
       "      <td>-0.725478</td>\n",
       "      <td>-2.632085</td>\n",
       "      <td>-0.450035</td>\n",
       "      <td>-0.607001</td>\n",
       "      <td>-0.914485</td>\n",
       "      <td>-0.472478</td>\n",
       "      <td>-1.316144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.469804</td>\n",
       "      <td>0.834319</td>\n",
       "      <td>-0.295509</td>\n",
       "      <td>-0.234216</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.766124</td>\n",
       "      <td>-0.194357</td>\n",
       "      <td>-0.295234</td>\n",
       "      <td>-0.462497</td>\n",
       "      <td>0.244608</td>\n",
       "      <td>-0.450035</td>\n",
       "      <td>0.049926</td>\n",
       "      <td>-1.107582</td>\n",
       "      <td>-1.280394</td>\n",
       "      <td>0.605960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303765</td>\n",
       "      <td>0.101942</td>\n",
       "      <td>0.268225</td>\n",
       "      <td>-0.700004</td>\n",
       "      <td>-0.437977</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  heart_rate       sbp       dbp  pulse_ox  resp_rate   cbc_wbc  \\\n",
       "0  1.233730   -0.022731  0.073884  0.392190 -0.278428   1.184224  0.520132   \n",
       "1 -1.104301    1.135743 -0.073763  0.786661  0.244608  -0.450035 -0.702405   \n",
       "2  0.256008   -0.494702  0.590651 -0.002281  0.244608  -0.004328 -0.417555   \n",
       "3  0.043460   -0.280170  0.073884 -0.725478 -2.632085  -0.450035 -0.607001   \n",
       "4  0.766124   -0.194357 -0.295234 -0.462497  0.244608  -0.450035  0.049926   \n",
       "\n",
       "   cbc_hematocrit  cbc_hemoglobin  cbc_platelets  ...   cmp_ast  \\\n",
       "0       -0.721388       -0.741784       0.616521  ... -0.239182   \n",
       "1       -0.383468       -0.337826       0.722131  ...  0.000000   \n",
       "2       -0.415651       -0.292942      -0.091067  ... -0.214963   \n",
       "3       -0.914485       -0.472478      -1.316144  ...  0.000000   \n",
       "4       -1.107582       -1.280394       0.605960  ... -0.303765   \n",
       "\n",
       "   cmp_alkaline_phosphatase  cmp_total_protein  cmp_albumin  cmp_bilirubin  \\\n",
       "0                 -0.443815           1.824984     0.917976      -0.234216   \n",
       "1                 -0.183931           1.258890     1.524718      -0.166295   \n",
       "2                 -0.105966          -0.156346     0.311233      -0.098374   \n",
       "3                 -0.469804           0.834319    -0.295509      -0.234216   \n",
       "4                  0.101942           0.268225    -0.700004      -0.437977   \n",
       "\n",
       "   Admitted  FirstRace_Encoded  Ethnicity_Encoded  Sex_Encoded  \\\n",
       "0         1                9.0                2.0          0.0   \n",
       "1         0                9.0                2.0          0.0   \n",
       "2         0                0.0                2.0          1.0   \n",
       "3         1                9.0                2.0          1.0   \n",
       "4         0                0.0                2.0          0.0   \n",
       "\n",
       "   COVIDResult_Encoded  \n",
       "0                  1.0  \n",
       "1                  1.0  \n",
       "2                  1.0  \n",
       "3                  1.0  \n",
       "4                  1.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.concat([scaled_df, codes_df], axis=1)\n",
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(merged_df, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Final Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = merged_df.copy()\n",
    "final_train = train.copy()\n",
    "final_test = test.copy()\n",
    "target = 'COVIDResult_Encoded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7380, 36)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5904, 36)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1476, 36)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    5543\n",
      "0.0     361\n",
      "Name: COVIDResult_Encoded, dtype: int64\n",
      "1.0    1367\n",
      "0.0     109\n",
      "Name: COVIDResult_Encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(final_train[target].value_counts())\n",
    "print(final_test[target].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_data.loc[:, final_data.columns != target]\n",
    "pos_X = trim_df4.loc[:, trim_df4.columns != target]\n",
    "X_norm = MinMaxScaler().fit_transform(pos_X)\n",
    "Y = final_data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Number of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_feats = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(scores, selector):\n",
    "    plt.bar(range(len(scores)), scores, color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def correlation_selector(x, y):\n",
    "    correl_dict = {\n",
    "        col: np.corrcoef(x[col], y)[0, 1] for col in x.columns.tolist()\n",
    "    }\n",
    "    correl_dict = {\n",
    "        col: 0 if np.isnan(cor) else np.abs(cor) for col, cor in correl_dict.items()\n",
    "    }\n",
    "    plot_scores(list(correl_dict.values()), 'correlation')\n",
    "    \n",
    "    correl_dict = dict(sorted(correl_dict.items(), key=lambda item: item[1], reverse=True)[:top_n_feats])\n",
    "    top_n = np.array([\n",
    "        True if col in list(correl_dict.keys()) else False for col in x.columns.tolist()\n",
    "    ])\n",
    "    return top_n\n",
    "\n",
    "\n",
    "corr_top_n = correlation_selector(X, Y)\n",
    "corr_top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Chi-Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chi_selector(y):\n",
    "    chi_sq = SelectKBest(chi2, k=top_n_feats)\n",
    "    chi_sq.fit(X_norm, y)\n",
    "    top_n = chi_sq.get_support()\n",
    "    plot_scores(chi_sq.scores_, 'chi-squared')\n",
    "    return top_n\n",
    "\n",
    "\n",
    "chi_top_n = chi_selector(Y)\n",
    "chi_top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rfe_selector(y):\n",
    "    rfe = RFE(estimator=LogisticRegression(), n_features_to_select=top_n_feats, step=10, verbose=0)\n",
    "    rfe.fit(X_norm, y)\n",
    "    top_n = rfe.get_support()\n",
    "    return top_n\n",
    "\n",
    "\n",
    "rfe_top_n = rfe_selector(Y)\n",
    "rfe_top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Lasso: SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True, False,  True, False,\n",
       "       False,  True,  True,  True,  True, False, False,  True,  True,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False,  True,  True, False,  True, False])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lasso_selector(y):\n",
    "    lasso = SelectFromModel(LogisticRegression(penalty=\"l2\"), max_features=top_n_feats)\n",
    "    lasso.fit(X_norm, y)\n",
    "    top_n = lasso.get_support()\n",
    "    return top_n\n",
    "\n",
    "\n",
    "lasso_top_n = lasso_selector(Y)\n",
    "lasso_top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 RandomForestClassifier: SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rfc_selector(x, y):\n",
    "    rfc = SelectFromModel(RandomForestClassifier(n_estimators=100), max_features=top_n_feats)\n",
    "    rfc.fit(x, y)\n",
    "    top_n = rfc.get_support()\n",
    "    return top_n\n",
    "\n",
    "\n",
    "rfc_top_n = rfc_selector(X, Y)\n",
    "rfc_top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Cumulative Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>correlation</th>\n",
       "      <th>chi-sq</th>\n",
       "      <th>rfe</th>\n",
       "      <th>lasso</th>\n",
       "      <th>rfc</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resp_rate</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ethnicity_Encoded</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sbp</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pulse_ox</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>heart_rate</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dbp</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cmp_total_protein</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cmp_sodium</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cmp_bilirubin</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cbc_wbc</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cbc_platelets</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cbc_neutrophil_c</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cbc_monocyte_c</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cbc_lymphocyte_perc</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cbc_lymphocyte_c</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cbc_hematocrit</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cbc_eosinophil_perc.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cbc_eosinophil_perc</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Age</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cmp_potassium</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cmp_glucose</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cmp_creatinine</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cmp_chloride</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cmp_bun</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cmp_bicarbonate</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cmp_ast</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cmp_alt</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cmp_alkaline_phosphatase</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>cmp_albumin</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cbc_hemoglobin</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>cbc_eosinophil_perc.1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>cbc_eosinophil_c</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Sex_Encoded</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>FirstRace_Encoded</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature  correlation  chi-sq   rfe  lasso    rfc  total\n",
       "1                  resp_rate         True    True  True   True   True      5\n",
       "2          Ethnicity_Encoded         True    True  True   True   True      5\n",
       "3                        sbp         True    True  True  False   True      4\n",
       "4                   pulse_ox         True    True  True  False   True      4\n",
       "5                 heart_rate         True    True  True  False   True      4\n",
       "6                        dbp         True    True  True  False   True      4\n",
       "7          cmp_total_protein         True    True  True   True  False      4\n",
       "8                 cmp_sodium         True    True  True   True  False      4\n",
       "9              cmp_bilirubin         True    True  True   True  False      4\n",
       "10                   cbc_wbc         True    True  True  False   True      4\n",
       "11             cbc_platelets         True    True  True  False   True      4\n",
       "12          cbc_neutrophil_c         True    True  True   True  False      4\n",
       "13            cbc_monocyte_c         True    True  True   True  False      4\n",
       "14       cbc_lymphocyte_perc         True    True  True   True  False      4\n",
       "15          cbc_lymphocyte_c         True    True  True   True  False      4\n",
       "16            cbc_hematocrit         True    True  True   True  False      4\n",
       "17     cbc_eosinophil_perc.2         True    True  True   True  False      4\n",
       "18       cbc_eosinophil_perc         True    True  True   True  False      4\n",
       "19                       Age         True    True  True  False   True      4\n",
       "20                  Admitted         True    True  True   True  False      4\n",
       "21             cmp_potassium         True    True  True  False  False      3\n",
       "22               cmp_glucose         True    True  True  False  False      3\n",
       "23            cmp_creatinine         True    True  True  False  False      3\n",
       "24              cmp_chloride         True    True  True  False  False      3\n",
       "25                   cmp_bun         True    True  True  False  False      3\n",
       "26           cmp_bicarbonate         True    True  True  False  False      3\n",
       "27                   cmp_ast         True    True  True  False  False      3\n",
       "28                   cmp_alt         True    True  True  False  False      3\n",
       "29  cmp_alkaline_phosphatase         True    True  True  False  False      3\n",
       "30               cmp_albumin         True    True  True  False  False      3\n",
       "31            cbc_hemoglobin         True    True  True  False  False      3\n",
       "32     cbc_eosinophil_perc.1         True    True  True  False  False      3\n",
       "33          cbc_eosinophil_c         True    True  True  False  False      3\n",
       "34               Sex_Encoded         True    True  True  False  False      3\n",
       "35         FirstRace_Encoded         True    True  True  False  False      3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumm_df = pd.DataFrame({\n",
    "    'feature': X.columns.tolist(),\n",
    "    'correlation': corr_top_n,\n",
    "    'chi-sq': chi_top_n,\n",
    "    'rfe': rfe_top_n,\n",
    "    'lasso': lasso_top_n,\n",
    "    'rfc': rfc_top_n\n",
    "})\n",
    "cumm_df['total'] = np.sum(cumm_df, axis=1)\n",
    "cumm_df = cumm_df.sort_values(['total', 'feature'], ascending=False)\n",
    "cumm_df.index = range(1, len(cumm_df) + 1)\n",
    "cumm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resp_rate',\n",
       " 'Ethnicity_Encoded',\n",
       " 'sbp',\n",
       " 'pulse_ox',\n",
       " 'heart_rate',\n",
       " 'dbp',\n",
       " 'cmp_total_protein',\n",
       " 'cmp_sodium',\n",
       " 'cmp_bilirubin',\n",
       " 'cbc_wbc',\n",
       " 'cbc_platelets',\n",
       " 'cbc_neutrophil_c',\n",
       " 'cbc_monocyte_c',\n",
       " 'cbc_lymphocyte_perc',\n",
       " 'cbc_lymphocyte_c',\n",
       " 'cbc_hematocrit',\n",
       " 'cbc_eosinophil_perc.2',\n",
       " 'cbc_eosinophil_perc',\n",
       " 'Age',\n",
       " 'Admitted',\n",
       " 'cmp_potassium',\n",
       " 'cmp_glucose',\n",
       " 'cmp_creatinine',\n",
       " 'cmp_chloride',\n",
       " 'cmp_bun',\n",
       " 'cmp_bicarbonate',\n",
       " 'cmp_ast',\n",
       " 'cmp_alt',\n",
       " 'cmp_alkaline_phosphatase',\n",
       " 'cmp_albumin',\n",
       " 'cbc_hemoglobin',\n",
       " 'cbc_eosinophil_perc.1',\n",
       " 'cbc_eosinophil_c',\n",
       " 'Sex_Encoded',\n",
       " 'FirstRace_Encoded']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_features = list(cumm_df.iloc[:top_n_feats]['feature'])\n",
    "top_n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Train / Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = final_train[top_n_features]\n",
    "y_train = final_train[target]\n",
    "X_test = final_test[top_n_features]\n",
    "y_test = final_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (5904, 35)\n",
      "y_train (5904,)\n",
      "\n",
      "X_test (1476, 35)\n",
      "y_test (1476,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train', X_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print()\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.1 Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Keras Layers/Activation Documentation](https://keras.io/api/layers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Functions\n",
    "* 'binary_crossentropy'\n",
    "* 'sparse_categorical_crossentropy'\n",
    "\n",
    "Optimizers\n",
    "* 'adam'\n",
    "* 'sgd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.2 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    Dense(300, use_bias=False),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dense(100, use_bias=False),\n",
    "    Activation('relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2 = Sequential([\n",
    "    Dense(top_n_feats, activation='relu'),\n",
    "    Dense(6, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq3 = Sequential([\n",
    "    Dense(top_n_feats, kernel_initializer='he_normal'),\n",
    "    PReLU(),\n",
    "    Dense(6, kernel_initializer='he_normal'),\n",
    "    PReLU(),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model, \"seq_model1.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Model Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(hist, metric):\n",
    "    train_metrics = hist.history[metric]\n",
    "    val_metrics = hist.history['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and Validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_history(hist):\n",
    "    display(Markdown('**Training/Validation Loss and Accuracy**'))\n",
    "    pd.DataFrame(hist.history).plot(figsize=(8,5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_evaluation(y_test, y_pred):\n",
    "    display(Markdown('**Metric Scores**'))\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "    print(\"Precision: {:.2f}%\".format(precision_score(y_test, y_pred) * 100))\n",
    "    print(\"Recall: {:.2f}%\".format(recall_score(y_test, y_pred) * 100))\n",
    "    print(\"F1: {:.2f}%\".format(f1_score(y_test, y_pred) * 100))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "    display(Markdown('**Confusion Matrix**'))\n",
    "    cm_df = pd.DataFrame(\n",
    "        confusion_matrix(y_test, y_pred), columns=['Detected', 'None Detected'], index=['Detected', 'None Detected']\n",
    "    )\n",
    "    ax = sns.heatmap(\n",
    "        data=cm_df, cmap=cm.Blues, annot=True, fmt='d'\n",
    "    )\n",
    "    ax.set(xlabel='Predicted', ylabel='Actual')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Simultaneous Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lst = [\n",
    "    {'name': 'Sequential: Dense + Batch Normalization Layers, ReLU Activations',\n",
    "     'model': seq1, 'loss': 'sparse_categorical_crossentropy', 'optimizer': Adam(learning_rate=1e-4)},\n",
    "    {'name': 'Sequential: Dense Layers, ReLU Activation',\n",
    "     'model': seq2, 'loss': 'sparse_categorical_crossentropy', 'optimizer': Adam(learning_rate=1e-4)},\n",
    "    {'name': 'Sequential: Dense Layers, PReLU Activation',\n",
    "     'model': seq3, 'loss': 'sparse_categorical_crossentropy', 'optimizer': Adam(learning_rate=1e-4)}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 200\n",
    "VAL_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(models, xy, isolate=None):\n",
    "    X_train, y_train, X_test, y_test = xy\n",
    "    for i, m in enumerate(models):\n",
    "        name, model, loss, optimizer = m.values()\n",
    "        if isolate is not None and i + 1 != isolate:\n",
    "            print('Skipping Model {}...'.format(i + 1))\n",
    "            continue\n",
    "        \n",
    "        display(Markdown('### Model {} – {}'.format(i + 1, name)))\n",
    "        \n",
    "        # 1. Compile\n",
    "        model.compile(\n",
    "            loss=loss, optimizer=optimizer, metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # 2. Fit\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=VAL_SPLIT, shuffle=True, verbose=0\n",
    "        )\n",
    "        \n",
    "        # 3. Visualize Model\n",
    "        display(Markdown(\"**Summary**\"))\n",
    "        model.summary()\n",
    "        plot_history(history)\n",
    "        \n",
    "        # 4. Evaluate\n",
    "        display(Markdown(\"**Evaluation and Prediction**\"))\n",
    "        loss, accuracy = model.evaluate(x=X_test, y=y_test)\n",
    "        print(\"\\nLoss: {:.2f}%\".format(loss * 100))\n",
    "        print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "        \n",
    "        # 5. Predict\n",
    "        y_prediction_array = model.predict(X_test)\n",
    "        y_prediction = np.argmax(y_prediction_array, axis=1)\n",
    "        \n",
    "        # 6. Visualize Predictions\n",
    "        metric_evaluation(y_test, y_prediction)\n",
    "        plot_confusion_matrix(y_test, y_prediction)\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Model 1 – Sequential: Dense + Batch Normalization Layers, ReLU Activations"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Summary**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 35)                140       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               10500     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30000     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 42,442\n",
      "Trainable params: 41,572\n",
      "Non-trainable params: 870\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Training/Validation Loss and Accuracy**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Evaluation and Prediction**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3132 - accuracy: 0.9167\n",
      "\n",
      "Loss: 31.32%\n",
      "Accuracy: 91.67%\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Metric Scores**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.67%\n",
      "Precision: 94.75%\n",
      "Recall: 96.34%\n",
      "F1: 95.54%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  36   73]\n",
      " [  50 1317]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Confusion Matrix**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Model 2 – Sequential: Dense Layers, ReLU Activation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Summary**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 35)                1260      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 216       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 1,490\n",
      "Trainable params: 1,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Training/Validation Loss and Accuracy**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Evaluation and Prediction**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 979us/step - loss: 0.2673 - accuracy: 0.9228\n",
      "\n",
      "Loss: 26.73%\n",
      "Accuracy: 92.28%\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Metric Scores**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.28%\n",
      "Precision: 92.59%\n",
      "Recall: 99.63%\n",
      "F1: 95.98%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   0  109]\n",
      " [   5 1362]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Confusion Matrix**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Model 3 – Sequential: Dense Layers, PReLU Activation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Summary**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 35)                1260      \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              (None, 35)                35        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 216       \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 6)                 6         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 1,531\n",
      "Trainable params: 1,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Training/Validation Loss and Accuracy**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Evaluation and Prediction**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 999us/step - loss: 0.6589 - accuracy: 0.7893\n",
      "\n",
      "Loss: 65.89%\n",
      "Accuracy: 78.93%\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Metric Scores**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.93%\n",
      "Precision: 92.86%\n",
      "Recall: 83.69%\n",
      "F1: 88.03%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  21   88]\n",
      " [ 223 1144]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Confusion Matrix**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_models(model_lst, (X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[top_n_feats]):\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=input_shape)\n",
    "    ])\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'n_hidden': [0, 1, 2, 3],\n",
    "    'n_neurons': np.arange(1, 100),\n",
    "    'learning_rate': reciprocal(3e-4, 3e-2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg, hyperparameters, n_iter=10, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 1.6438 - val_loss: 0.6919\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.5883 - val_loss: 0.3790\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3475 - val_loss: 0.2640\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2493 - val_loss: 0.2070\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1976 - val_loss: 0.1724\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1662 - val_loss: 0.1508\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1456 - val_loss: 0.1344\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1308 - val_loss: 0.1216\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1196 - val_loss: 0.1119\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1108 - val_loss: 0.1041\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1038 - val_loss: 0.0989\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0983 - val_loss: 0.0925\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0937 - val_loss: 0.0883\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0897 - val_loss: 0.0846\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0816\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0837 - val_loss: 0.0791\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0769\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0751\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0776 - val_loss: 0.0737\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.0723\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0710\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0701\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0690\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0683\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0677\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0673\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0663\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0658\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 989us/step - loss: 0.0683 - val_loss: 0.0655\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0648\n",
      "19/19 [==============================] - 0s 857us/step - loss: 0.0628\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.3319 - val_loss: 0.8633\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.7670 - val_loss: 0.5545\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4981 - val_loss: 0.3956\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.3048\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2728 - val_loss: 0.2475\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2215 - val_loss: 0.2086\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1866 - val_loss: 0.1811\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1625 - val_loss: 0.1607\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1445 - val_loss: 0.1460\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.1335\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1197 - val_loss: 0.1224\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1107 - val_loss: 0.1148\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1033 - val_loss: 0.1081\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0973 - val_loss: 0.1021\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.0963\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.0921\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0842 - val_loss: 0.0884\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.0851\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0783 - val_loss: 0.0825\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0801\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0774\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0762\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0740\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0721\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0711\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0698\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0685\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.0678\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0668\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0658\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0569\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7279 - val_loss: 0.4706\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.3209\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2599 - val_loss: 0.2419\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2043 - val_loss: 0.1950\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1702 - val_loss: 0.1658\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1475 - val_loss: 0.1455\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1320 - val_loss: 0.1304\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1207 - val_loss: 0.1195\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1121 - val_loss: 0.1134\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1055 - val_loss: 0.1045\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0999 - val_loss: 0.0990\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0956 - val_loss: 0.0946\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0916 - val_loss: 0.0908\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0886 - val_loss: 0.0875\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0859 - val_loss: 0.0848\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0834 - val_loss: 0.0823\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0801\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0782\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0778 - val_loss: 0.0764\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0763 - val_loss: 0.0749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0748 - val_loss: 0.0738\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0723\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0712\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0700\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.0691\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0683\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.0672\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0679 - val_loss: 0.0664\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0672 - val_loss: 0.0657\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0651\n",
      "19/19 [==============================] - 0s 804us/step - loss: 0.0705\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 2.1842 - val_loss: 1.2903\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 1.0632 - val_loss: 0.6816\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.5921 - val_loss: 0.4054\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3679 - val_loss: 0.2650\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2514 - val_loss: 0.1908\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1861 - val_loss: 0.1481\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.1469 - val_loss: 0.1219\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1220 - val_loss: 0.1053\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.1059 - val_loss: 0.0940\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0943 - val_loss: 0.0857\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.0799\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0759\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0723\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.0723 - val_loss: 0.0697\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0698 - val_loss: 0.0677\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0676 - val_loss: 0.0668\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.0660 - val_loss: 0.0648\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.065 - 0s 3ms/step - loss: 0.0646 - val_loss: 0.0638\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0634 - val_loss: 0.0625\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.0624 - val_loss: 0.0617\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0615 - val_loss: 0.0610\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0609 - val_loss: 0.0605\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0600\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0597 - val_loss: 0.0595\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.0591\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0588 - val_loss: 0.0587\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.0584 - val_loss: 0.0585\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0585\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.0577 - val_loss: 0.0578\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.0575 - val_loss: 0.0576\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0601\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 1.3564 - val_loss: 0.8118\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7229 - val_loss: 0.4991\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.3250\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3175 - val_loss: 0.2377\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2388 - val_loss: 0.1872\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1910 - val_loss: 0.1546\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1594 - val_loss: 0.1334\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1377 - val_loss: 0.1170\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1219 - val_loss: 0.1056\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1104 - val_loss: 0.0972\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1015 - val_loss: 0.0901\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0949 - val_loss: 0.0848\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0896 - val_loss: 0.0808\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0780\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.0754\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0726\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0765 - val_loss: 0.0706\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0690\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0674\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0663\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0698 - val_loss: 0.0650\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0638\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0630\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0623\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0624\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0651 - val_loss: 0.0611\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0643 - val_loss: 0.0602\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0598\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0632 - val_loss: 0.0594\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0587\n",
      "19/19 [==============================] - 0s 844us/step - loss: 0.0699\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 1.1407 - val_loss: 0.8112\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.5654 - val_loss: 0.4805\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3507 - val_loss: 0.3234\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2468 - val_loss: 0.2378\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1886 - val_loss: 0.1868\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 970us/step - loss: 0.1532 - val_loss: 0.1541\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1301 - val_loss: 0.1323\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 981us/step - loss: 0.1147 - val_loss: 0.1174\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 980us/step - loss: 0.1037 - val_loss: 0.1065\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0957 - val_loss: 0.0984\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0897 - val_loss: 0.0923\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.0876\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0835\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0783 - val_loss: 0.0805\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0757 - val_loss: 0.0775\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0753\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0733\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.0717\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0703\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0691\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0668 - val_loss: 0.0684\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0658 - val_loss: 0.0672\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0650 - val_loss: 0.0661\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0642 - val_loss: 0.0653\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0646\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0630 - val_loss: 0.0639\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.0633\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0619 - val_loss: 0.0627\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.0629\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0610 - val_loss: 0.0617\n",
      "19/19 [==============================] - 0s 753us/step - loss: 0.0630\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.4148 - val_loss: 0.6294\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.5732 - val_loss: 0.3716\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.2535\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2438 - val_loss: 0.1881\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1861 - val_loss: 0.1518\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1521 - val_loss: 0.1267\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1298 - val_loss: 0.1111\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1149 - val_loss: 0.0995\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1040 - val_loss: 0.0921\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0967 - val_loss: 0.0869\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0907 - val_loss: 0.0819\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0861 - val_loss: 0.0789\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0823 - val_loss: 0.0767\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0794 - val_loss: 0.0738\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0718\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0747 - val_loss: 0.0701\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0687\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0675\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0667\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.0660\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.0649\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0641\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0634\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0651 - val_loss: 0.0628\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0644 - val_loss: 0.0624\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0621\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0632 - val_loss: 0.0614\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0612\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0607\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0603\n",
      "19/19 [==============================] - 0s 834us/step - loss: 0.0638\n",
      "Epoch 1/30\n",
      "  1/133 [..............................] - ETA: 0s - loss: 4.7349WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0053s). Check your callbacks.\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 1.4188 - val_loss: 0.8417\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7111 - val_loss: 0.4956\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.4331 - val_loss: 0.3220\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2884 - val_loss: 0.2269\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2078 - val_loss: 0.1759\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1601 - val_loss: 0.1407\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1304 - val_loss: 0.1178\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1111 - val_loss: 0.1035\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0980 - val_loss: 0.0933\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.0862\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0826 - val_loss: 0.0808\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0778 - val_loss: 0.0770\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0739\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0698\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0680 - val_loss: 0.0683\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0670\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.0660\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0648 - val_loss: 0.0651\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0640 - val_loss: 0.0644\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0637\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0629 - val_loss: 0.0635\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0624 - val_loss: 0.0627\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0626\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0617 - val_loss: 0.0619\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.0620\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0613\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0616\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0607\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.0605\n",
      "19/19 [==============================] - 0s 784us/step - loss: 0.0553\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.2004 - val_loss: 0.6352\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.4897 - val_loss: 0.3954\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 0.2857\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2473 - val_loss: 0.2243\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2027 - val_loss: 0.1868\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1736 - val_loss: 0.1627\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1532 - val_loss: 0.1434\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 0.1297\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1258 - val_loss: 0.1180\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1159 - val_loss: 0.1102\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1079 - val_loss: 0.1033\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1013 - val_loss: 0.0959\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0957 - val_loss: 0.0907\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0909 - val_loss: 0.0863\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0868 - val_loss: 0.0832\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0834 - val_loss: 0.0793\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0804 - val_loss: 0.0770\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0779 - val_loss: 0.0747\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0725\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0705\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0691\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0675\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0689 - val_loss: 0.0665\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0655\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.0646\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0638\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0652 - val_loss: 0.0632\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0623\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.0618\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0613\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0621\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.7152 - val_loss: 0.9913\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.8053 - val_loss: 0.5313\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4660 - val_loss: 0.3241\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3027 - val_loss: 0.2206\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2165 - val_loss: 0.1652\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1667 - val_loss: 0.1329\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1372 - val_loss: 0.1133\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1179 - val_loss: 0.1001\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1055 - val_loss: 0.0912\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0967 - val_loss: 0.0853\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.0810\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0854 - val_loss: 0.0779\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0816 - val_loss: 0.0758\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0730\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0762 - val_loss: 0.0712\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0698\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0686\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0678\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0697 - val_loss: 0.0667\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0656\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.0649\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0643\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.0635\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0649 - val_loss: 0.0628\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0643 - val_loss: 0.0624\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0636 - val_loss: 0.0616\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0631 - val_loss: 0.0612\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0625 - val_loss: 0.0607\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0603\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.0600\n",
      "19/19 [==============================] - 0s 781us/step - loss: 0.0741\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.3595 - val_loss: 0.8581\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.6245 - val_loss: 0.4621\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.3038\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2589 - val_loss: 0.2200\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1981 - val_loss: 0.1752\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1617 - val_loss: 0.1465\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1379 - val_loss: 0.1281\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1213 - val_loss: 0.1156\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1094 - val_loss: 0.1049\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1007 - val_loss: 0.0972\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0938 - val_loss: 0.0914\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0886 - val_loss: 0.0861\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0844 - val_loss: 0.0826\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0792\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.0770\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0758 - val_loss: 0.0744\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0721\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0703\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.0689\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.0675\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0664\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0671 - val_loss: 0.0654\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0662 - val_loss: 0.0647\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0654 - val_loss: 0.0635\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0646 - val_loss: 0.0627\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0640 - val_loss: 0.0620\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0614\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0608\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0625 - val_loss: 0.0605\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.0598\n",
      "19/19 [==============================] - 0s 762us/step - loss: 0.0577\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 2.3309 - val_loss: 1.1261\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.8160 - val_loss: 0.5978\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.4422 - val_loss: 0.3699\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2767 - val_loss: 0.2580\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1955 - val_loss: 0.1979\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1518 - val_loss: 0.1631\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1268 - val_loss: 0.1414\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1000us/step - loss: 0.1117 - val_loss: 0.1261\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1013 - val_loss: 0.1161\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0945 - val_loss: 0.1072\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.1010\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0965\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0819 - val_loss: 0.0933\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0792 - val_loss: 0.0894\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0871\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0848\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.0827\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0812\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.0789\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0694 - val_loss: 0.0775\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0683 - val_loss: 0.0757\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0673 - val_loss: 0.0750\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0665 - val_loss: 0.0734\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.0724\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0649 - val_loss: 0.0712\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.0699\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0636 - val_loss: 0.0692\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0629 - val_loss: 0.0686\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0623 - val_loss: 0.0673\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0667\n",
      "19/19 [==============================] - 0s 869us/step - loss: 0.0603\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 0.5372\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.4928 - val_loss: 0.3415\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3265 - val_loss: 0.2423\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2440 - val_loss: 0.1895\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1955 - val_loss: 0.1572\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1638 - val_loss: 0.1348\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1414 - val_loss: 0.1183\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1251 - val_loss: 0.1060\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1129 - val_loss: 0.0984\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1033 - val_loss: 0.0912\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0961 - val_loss: 0.0847\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.0804\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0780\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0739\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0779 - val_loss: 0.0720\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.0695\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0731 - val_loss: 0.0675\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.0662\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0650\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0680 - val_loss: 0.0640\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0668 - val_loss: 0.0629\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0658 - val_loss: 0.0621\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0649 - val_loss: 0.0617\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.0609\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0603\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0597\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0624 - val_loss: 0.0593\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0619 - val_loss: 0.0589\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0616 - val_loss: 0.0588\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0612 - val_loss: 0.0584\n",
      "19/19 [==============================] - 0s 770us/step - loss: 0.0577\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.4300 - val_loss: 0.7451\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.6216 - val_loss: 0.4104\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.2719\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2426 - val_loss: 0.2040\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1822 - val_loss: 0.1669\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1478 - val_loss: 0.1426\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1263 - val_loss: 0.1269\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1122 - val_loss: 0.1170\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1026 - val_loss: 0.1075\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0955 - val_loss: 0.1015\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.0956\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0858 - val_loss: 0.0910\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0825 - val_loss: 0.0879\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0797 - val_loss: 0.0855\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0775 - val_loss: 0.0827\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0754 - val_loss: 0.0804\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0738 - val_loss: 0.0787\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0767\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0754\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0698 - val_loss: 0.0742\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0728\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0719\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0670 - val_loss: 0.0706\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0662 - val_loss: 0.0696\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0655 - val_loss: 0.0684\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0649 - val_loss: 0.0679\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0643 - val_loss: 0.0668\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0636 - val_loss: 0.0662\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0631 - val_loss: 0.0655\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0626 - val_loss: 0.0649\n",
      "19/19 [==============================] - 0s 944us/step - loss: 0.0622\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.8370 - val_loss: 0.9456\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.7955 - val_loss: 0.5116\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.4591 - val_loss: 0.3263\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.2324\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2245 - val_loss: 0.1814\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1785 - val_loss: 0.1507\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1500 - val_loss: 0.1304\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1307 - val_loss: 0.1165\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1173 - val_loss: 0.1063\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1072 - val_loss: 0.0995\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0999 - val_loss: 0.0925\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0938 - val_loss: 0.0883\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0892 - val_loss: 0.0840\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0805\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0822 - val_loss: 0.0780\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0755\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0774 - val_loss: 0.0736\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0754 - val_loss: 0.0719\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0717\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0694\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.0683\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0672\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.0664\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0658\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0677 - val_loss: 0.0651\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0670 - val_loss: 0.0644\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0665 - val_loss: 0.0640\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0658 - val_loss: 0.0637\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0655 - val_loss: 0.0632\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0650 - val_loss: 0.0630\n",
      "19/19 [==============================] - 0s 838us/step - loss: 0.0752\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 1.9224 - val_loss: 1.0430\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7859 - val_loss: 0.5193\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.4290 - val_loss: 0.3083\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2724 - val_loss: 0.2056\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1921 - val_loss: 0.1520\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1480 - val_loss: 0.1221\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1220 - val_loss: 0.1034\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1060 - val_loss: 0.0923\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0954 - val_loss: 0.0852\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0884 - val_loss: 0.0805\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.0780\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0794 - val_loss: 0.0752\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0765 - val_loss: 0.0728\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0710\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0697\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0692\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0694 - val_loss: 0.0676\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0682 - val_loss: 0.0669\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0672 - val_loss: 0.0661\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0663 - val_loss: 0.0653\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0655 - val_loss: 0.0649\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0649 - val_loss: 0.0641\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0642 - val_loss: 0.0636\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0637 - val_loss: 0.0631\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0632 - val_loss: 0.0628\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0626 - val_loss: 0.0622\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0622 - val_loss: 0.0618\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0617 - val_loss: 0.0615\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.0612\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0608\n",
      "19/19 [==============================] - 0s 773us/step - loss: 0.0584\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.2163 - val_loss: 0.5314\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.4544 - val_loss: 0.3128\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2836 - val_loss: 0.2103\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1995 - val_loss: 0.1561\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1541 - val_loss: 0.1267\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1280 - val_loss: 0.1081\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1119 - val_loss: 0.0963\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1013 - val_loss: 0.0885\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0941 - val_loss: 0.0832\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0889 - val_loss: 0.0795\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0851 - val_loss: 0.0763\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0820 - val_loss: 0.0738\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.0717\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0775 - val_loss: 0.0700\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0758 - val_loss: 0.0687\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0672\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0661\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0652\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.0643\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0634\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0629\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0682 - val_loss: 0.0621\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0615\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0670 - val_loss: 0.0610\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0663 - val_loss: 0.0604\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0600\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0654 - val_loss: 0.0595\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0649 - val_loss: 0.0592\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0646 - val_loss: 0.0587\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.0584\n",
      "19/19 [==============================] - 0s 817us/step - loss: 0.0726\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 2.0513 - val_loss: 1.0501\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.8276 - val_loss: 0.5471\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.4387 - val_loss: 0.3336\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2783 - val_loss: 0.2310\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2001 - val_loss: 0.1751\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1567 - val_loss: 0.1424\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1306 - val_loss: 0.1236\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1138 - val_loss: 0.1065\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1017 - val_loss: 0.0971\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0932 - val_loss: 0.0892\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0867 - val_loss: 0.0833\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.0786\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0777 - val_loss: 0.0749\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0720\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0697\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0676\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0677 - val_loss: 0.0659\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0661 - val_loss: 0.0646\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0648 - val_loss: 0.0632\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0636 - val_loss: 0.0622\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0614\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0607\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0599\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.0592\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0590\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.0584\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0578\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0574\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0574\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0570\n",
      "19/19 [==============================] - 0s 730us/step - loss: 0.0555\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 2.4956 - val_loss: 1.2786\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.9541 - val_loss: 0.6380\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.5100 - val_loss: 0.3948\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3250 - val_loss: 0.2725\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2322 - val_loss: 0.2082\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1808 - val_loss: 0.1684\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1496 - val_loss: 0.1442\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1294 - val_loss: 0.1279\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1154 - val_loss: 0.1164\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1056 - val_loss: 0.1081\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0979 - val_loss: 0.1021\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.0963\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0876 - val_loss: 0.0923\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.0881\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0855\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0779 - val_loss: 0.0831\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0807\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0785\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0767\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.0754\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0689 - val_loss: 0.0737\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0677 - val_loss: 0.0722\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0714\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0657 - val_loss: 0.0704\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0648 - val_loss: 0.0691\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.0681\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0633 - val_loss: 0.0677\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0672\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0654\n",
      "19/19 [==============================] - 0s 793us/step - loss: 0.0584\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.5584 - val_loss: 0.9219\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.7680 - val_loss: 0.5098\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.4513 - val_loss: 0.3206\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2959 - val_loss: 0.2258\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2131 - val_loss: 0.1748\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1660 - val_loss: 0.1435\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1372 - val_loss: 0.1240\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1188 - val_loss: 0.1115\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1063 - val_loss: 0.1026\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0975 - val_loss: 0.0958\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.0908\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0860 - val_loss: 0.0867\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0821 - val_loss: 0.0838\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.0811\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0765 - val_loss: 0.0786\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0766\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0749\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0734\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0722\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0683 - val_loss: 0.0709\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0672 - val_loss: 0.0697\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0662 - val_loss: 0.0688\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0654 - val_loss: 0.0679\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0646 - val_loss: 0.0671\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.0667\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0631 - val_loss: 0.0657\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0626 - val_loss: 0.0651\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0644\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0639\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0610 - val_loss: 0.0633\n",
      "19/19 [==============================] - 0s 747us/step - loss: 0.0592\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9165 - val_loss: 0.5655\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.4679 - val_loss: 0.3587\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.2573\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2276 - val_loss: 0.2063\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1850 - val_loss: 0.1733\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1583 - val_loss: 0.1528\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1402 - val_loss: 0.1381\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1268 - val_loss: 0.1268\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1164 - val_loss: 0.1182\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1084 - val_loss: 0.1104\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1019 - val_loss: 0.1044\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0966 - val_loss: 0.1000\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.0953\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.0919\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0851 - val_loss: 0.0888\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0825 - val_loss: 0.0858\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0837\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0779 - val_loss: 0.0810\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0789\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0773\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0758\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.0743\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0703 - val_loss: 0.0730\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.0717\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0708\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.0698\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0668 - val_loss: 0.0688\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0661 - val_loss: 0.0679\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0653 - val_loss: 0.0677\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0648 - val_loss: 0.0666\n",
      "19/19 [==============================] - 0s 840us/step - loss: 0.0627\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.6890 - val_loss: 0.8690\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.6975 - val_loss: 0.4641\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3906 - val_loss: 0.3036\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2648 - val_loss: 0.2267\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2025 - val_loss: 0.1850\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1668 - val_loss: 0.1593\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1445 - val_loss: 0.1425\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1291 - val_loss: 0.1300\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1180 - val_loss: 0.1205\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1098 - val_loss: 0.1139\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1031 - val_loss: 0.1076\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0978 - val_loss: 0.1023\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0932 - val_loss: 0.0981\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0895 - val_loss: 0.0943\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0863 - val_loss: 0.0908\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0835 - val_loss: 0.0878\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0854\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0789 - val_loss: 0.0831\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.0811\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.0790\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0776\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0724 - val_loss: 0.0762\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0746\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0701 - val_loss: 0.0734\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0723\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0713\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0673 - val_loss: 0.0704\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0665 - val_loss: 0.0697\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0657 - val_loss: 0.0689\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0651 - val_loss: 0.0685\n",
      "19/19 [==============================] - 0s 825us/step - loss: 0.0646\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.1888 - val_loss: 0.7165\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.6204 - val_loss: 0.4179\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.2760\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2626 - val_loss: 0.1946\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1948 - val_loss: 0.1511\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1552 - val_loss: 0.1247\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1301 - val_loss: 0.1085\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1135 - val_loss: 0.0977\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1024 - val_loss: 0.0904\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0943 - val_loss: 0.0854\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.0812\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0840 - val_loss: 0.0786\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0758\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.0739\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0728\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0710\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0698\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.0690\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0679\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0670\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0670 - val_loss: 0.0664\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0653 - val_loss: 0.0652\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0647 - val_loss: 0.0645\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0640 - val_loss: 0.0638\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0634 - val_loss: 0.0635\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0629\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0623 - val_loss: 0.0625\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0621\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.0618\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0646\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 1.8517 - val_loss: 0.7681\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5835 - val_loss: 0.3481\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2919 - val_loss: 0.2186\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1945 - val_loss: 0.1623\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1509 - val_loss: 0.1335\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1273 - val_loss: 0.1163\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1130 - val_loss: 0.1045\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1032 - val_loss: 0.0964\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0958 - val_loss: 0.0896\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0903 - val_loss: 0.0844\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0857 - val_loss: 0.0803\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.0770\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0789 - val_loss: 0.0740\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.0719\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0694\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0682\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0660\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.0649\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0634\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0661 - val_loss: 0.0624\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.0616\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0642 - val_loss: 0.0606\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0634 - val_loss: 0.0599\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0626 - val_loss: 0.0592\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0587\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.0581\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0577\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.0572\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0599 - val_loss: 0.0568\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0565\n",
      "19/19 [==============================] - 0s 756us/step - loss: 0.0598\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.6337 - val_loss: 0.8970\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.7146 - val_loss: 0.5164\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.4510 - val_loss: 0.3421\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3088 - val_loss: 0.2466\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2243 - val_loss: 0.1854\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1719 - val_loss: 0.1479\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1391 - val_loss: 0.1237\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1175 - val_loss: 0.1079\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1030 - val_loss: 0.0979\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0932 - val_loss: 0.0902\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0862 - val_loss: 0.0840\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0807\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0774 - val_loss: 0.0767\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0748\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0725\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0709\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0692\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.0681\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0664 - val_loss: 0.0671\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0655 - val_loss: 0.0667\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0647 - val_loss: 0.0658\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.0649\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0634 - val_loss: 0.0644\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0629 - val_loss: 0.0639\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0635\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0619 - val_loss: 0.0630\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0627\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0621\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.0620\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.0615\n",
      "19/19 [==============================] - 0s 747us/step - loss: 0.0570\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.6254 - val_loss: 0.9602\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.7737 - val_loss: 0.5324\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.4405 - val_loss: 0.3337\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2850 - val_loss: 0.2321\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2050 - val_loss: 0.1753\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1605 - val_loss: 0.1420\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1338 - val_loss: 0.1205\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1165 - val_loss: 0.1063\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1048 - val_loss: 0.0962\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0964 - val_loss: 0.0887\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.0834\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0855 - val_loss: 0.0790\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0816 - val_loss: 0.0756\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0729\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0762 - val_loss: 0.0706\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0687\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0671\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.0663\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0694 - val_loss: 0.0647\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.0636\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0674 - val_loss: 0.0627\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0621\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0612\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0652 - val_loss: 0.0606\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0645 - val_loss: 0.0614\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.0596\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0636 - val_loss: 0.0591\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0631 - val_loss: 0.0587\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0583\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0624 - val_loss: 0.0579\n",
      "19/19 [==============================] - 0s 832us/step - loss: 0.0646\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.6447 - val_loss: 0.7444\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.5688 - val_loss: 0.3807\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3184 - val_loss: 0.2381\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2120 - val_loss: 0.1689\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1575 - val_loss: 0.1320\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1262 - val_loss: 0.1113\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1072 - val_loss: 0.0967\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0947 - val_loss: 0.0880\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0864 - val_loss: 0.0817\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0805 - val_loss: 0.0777\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0762 - val_loss: 0.0743\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0717\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.0696\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.0681\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0669 - val_loss: 0.0665\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.0654\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0645 - val_loss: 0.0646\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0636\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0628\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0622\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0615\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0611\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.0607\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0604\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0599\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0596\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0598\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0591\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0594\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0588\n",
      "19/19 [==============================] - 0s 731us/step - loss: 0.0598\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.7005 - val_loss: 1.0078\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.7585 - val_loss: 0.5408\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.3486\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2821 - val_loss: 0.2532\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.2100 - val_loss: 0.2013\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1704 - val_loss: 0.1715\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1460 - val_loss: 0.1510\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1302 - val_loss: 0.1369\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1190 - val_loss: 0.1269\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1105 - val_loss: 0.1186\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1041 - val_loss: 0.1123\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0991 - val_loss: 0.1072\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0947 - val_loss: 0.1027\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.0991\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0881 - val_loss: 0.0952\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0855 - val_loss: 0.0922\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.0893\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0869\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.0850\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0775 - val_loss: 0.0829\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0812\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0800\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0772\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0770\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0747\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0733\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.0721\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0710\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0701\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0669 - val_loss: 0.0702\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0678\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 1.4277 - val_loss: 0.7460\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.6054 - val_loss: 0.4090\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.2641\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2397 - val_loss: 0.1913\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1828 - val_loss: 0.1508\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1494 - val_loss: 0.1255\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1279 - val_loss: 0.1098\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1136 - val_loss: 0.0985\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1032 - val_loss: 0.0910\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0957 - val_loss: 0.0848\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.0802\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0854 - val_loss: 0.0768\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0739\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.0716\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0698\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0683\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0668\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0657\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0646\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0638\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0633\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0674 - val_loss: 0.0624\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0618\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0612\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0653 - val_loss: 0.0607\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0647 - val_loss: 0.0604\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0642 - val_loss: 0.0598\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.0596\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0634 - val_loss: 0.0594\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0630 - val_loss: 0.0590\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0637\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 1.3141 - val_loss: 0.9269\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.5917 - val_loss: 0.5142\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.3206\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2322 - val_loss: 0.2253\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1727 - val_loss: 0.1731\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1390 - val_loss: 0.1416\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1183 - val_loss: 0.1209\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1045 - val_loss: 0.1069\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0948 - val_loss: 0.0975\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0878 - val_loss: 0.0897\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0840\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.0794\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0759\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0730\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0709\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0686\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0661 - val_loss: 0.0669\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0647 - val_loss: 0.0655\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0636 - val_loss: 0.0642\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0626 - val_loss: 0.0631\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0617 - val_loss: 0.0622\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0610 - val_loss: 0.0614\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.0614\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0606\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0598\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0591\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0589\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0583\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0579\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0576\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0555\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3142 - val_loss: 0.2217\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2062 - val_loss: 0.1848\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1738 - val_loss: 0.1612\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1526 - val_loss: 0.1445\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1376 - val_loss: 0.1320\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1262 - val_loss: 0.1222\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1174 - val_loss: 0.1146\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1105 - val_loss: 0.1084\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1048 - val_loss: 0.1036\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1001 - val_loss: 0.0988\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0961 - val_loss: 0.0952\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0927 - val_loss: 0.0920\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0897 - val_loss: 0.0891\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0871 - val_loss: 0.0865\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0849 - val_loss: 0.0843\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0828 - val_loss: 0.0823\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0811 - val_loss: 0.0806\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0788\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.0773\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0761\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0749\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0738\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.0728\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0711\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0704\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0695\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0689\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0684\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0682 - val_loss: 0.0677\n",
      "19/19 [==============================] - 0s 827us/step - loss: 0.0743\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3510 - val_loss: 0.2347\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2116 - val_loss: 0.1863\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1763 - val_loss: 0.1595\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1520 - val_loss: 0.1392\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1341 - val_loss: 0.1239\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1204 - val_loss: 0.1121\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1099 - val_loss: 0.1029\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1016 - val_loss: 0.0956\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0951 - val_loss: 0.0898\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0898 - val_loss: 0.0850\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0856 - val_loss: 0.0812\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0822 - val_loss: 0.0780\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0754\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0770 - val_loss: 0.0732\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0713\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0698\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0685\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0673\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0663\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0686 - val_loss: 0.0655\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0647\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0671 - val_loss: 0.0640\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0665 - val_loss: 0.0634\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0629\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0654 - val_loss: 0.0624\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0620\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0616\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0613\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0610\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0607\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0616\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 1.1613 - val_loss: 0.7268\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5598 - val_loss: 0.4382\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3412 - val_loss: 0.2641\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2011 - val_loss: 0.1557\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1296 - val_loss: 0.1108\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1022 - val_loss: 0.0933\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0910 - val_loss: 0.0858\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0845 - val_loss: 0.0810\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0801 - val_loss: 0.0780\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0751\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.0731\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.0715\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0700\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0689\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0678\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0669\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0660\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.0654\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0662 - val_loss: 0.0646\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0641\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0635\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.0646 - val_loss: 0.0631\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.0641 - val_loss: 0.0625\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0637 - val_loss: 0.0621\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.0633 - val_loss: 0.0617\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.0630 - val_loss: 0.0613\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0611\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0608\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0607\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0604\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0585\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4849 - val_loss: 0.2085\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1629 - val_loss: 0.1301\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1349 - val_loss: 0.1199\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1247 - val_loss: 0.1129\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1168 - val_loss: 0.1071\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1107 - val_loss: 0.1028\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1056 - val_loss: 0.0988\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1011 - val_loss: 0.0956\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0974 - val_loss: 0.0924\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0940 - val_loss: 0.0899\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.0876\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0886 - val_loss: 0.0854\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0863 - val_loss: 0.0835\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0843 - val_loss: 0.0819\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0824 - val_loss: 0.0804\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0808 - val_loss: 0.0790\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0777\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0766\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0755\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0746\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0737\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0729\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0721\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0713\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.0707\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.0701\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0697 - val_loss: 0.0695\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0690\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.0684\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0680 - val_loss: 0.0680\n",
      "19/19 [==============================] - 0s 829us/step - loss: 0.0657\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.1341 - val_loss: 0.6602\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.5116 - val_loss: 0.3871\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3105 - val_loss: 0.2412\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1976 - val_loss: 0.1547\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1316 - val_loss: 0.1040\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0947 - val_loss: 0.0770\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0764 - val_loss: 0.0644\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0683 - val_loss: 0.0591\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0650 - val_loss: 0.0569\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0559\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0553\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0622 - val_loss: 0.0549\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0546\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0544\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0612 - val_loss: 0.0542\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0541\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0540\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0538\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.0538\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.0537\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0602 - val_loss: 0.0536\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0535\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0535\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0599 - val_loss: 0.0534\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0599 - val_loss: 0.0534\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0533\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0533\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0533\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0532\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0532\n",
      "19/19 [==============================] - 0s 902us/step - loss: 0.0605\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6419 - val_loss: 0.3508\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2535 - val_loss: 0.1685\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1521 - val_loss: 0.1216\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1265 - val_loss: 0.1090\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1158 - val_loss: 0.1015\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1082 - val_loss: 0.0958\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1020 - val_loss: 0.0912\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0970 - val_loss: 0.0874\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0928 - val_loss: 0.0842\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0893 - val_loss: 0.0815\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0864 - val_loss: 0.0792\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0839 - val_loss: 0.0772\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.0755\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0798 - val_loss: 0.0740\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.0727\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0716\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0752 - val_loss: 0.0706\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0697\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0689\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.0682\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.0675\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0669\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0664\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0659\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0654\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0650\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0674 - val_loss: 0.0646\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0642\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0665 - val_loss: 0.0639\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0661 - val_loss: 0.0636\n",
      "19/19 [==============================] - 0s 854us/step - loss: 0.0643\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.8016 - val_loss: 0.6185\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.5075 - val_loss: 0.4090\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3383 - val_loss: 0.2747\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2293 - val_loss: 0.1887\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1606 - val_loss: 0.1361\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1198 - val_loss: 0.1061\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0970 - val_loss: 0.0901\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.0819\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0777\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0754 - val_loss: 0.0753\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0737\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0726\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.0716\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0708\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0701\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0683 - val_loss: 0.0694\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0677 - val_loss: 0.0688\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0671 - val_loss: 0.0683\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0677\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0661 - val_loss: 0.0673\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.0668\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0652 - val_loss: 0.0664\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0648 - val_loss: 0.0660\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0644 - val_loss: 0.0656\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0640 - val_loss: 0.0653\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0637 - val_loss: 0.0650\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0634 - val_loss: 0.0647\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0631 - val_loss: 0.0645\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0629 - val_loss: 0.0642\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0626 - val_loss: 0.0640\n",
      "19/19 [==============================] - 0s 847us/step - loss: 0.0673\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5156 - val_loss: 0.3079\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2238 - val_loss: 0.1729\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1668 - val_loss: 0.1512\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1507 - val_loss: 0.1382\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1390 - val_loss: 0.1280\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1294 - val_loss: 0.1195\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1215 - val_loss: 0.1125\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1148 - val_loss: 0.1066\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1091 - val_loss: 0.1015\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1041 - val_loss: 0.0971\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0999 - val_loss: 0.0933\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0961 - val_loss: 0.0900\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0929 - val_loss: 0.0871\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.0846\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0875 - val_loss: 0.0823\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0803\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0832 - val_loss: 0.0785\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0769\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0798 - val_loss: 0.0755\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0783 - val_loss: 0.0741\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.0730\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0719\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0708\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0699\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0691\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0683\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0676\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0703 - val_loss: 0.0669\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0663\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0657\n",
      "19/19 [==============================] - 0s 825us/step - loss: 0.0681\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4221 - val_loss: 0.2475\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2183 - val_loss: 0.1846\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1808 - val_loss: 0.1613\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1589 - val_loss: 0.1452\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1432 - val_loss: 0.1332\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1314 - val_loss: 0.1242\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1224 - val_loss: 0.1169\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1150 - val_loss: 0.1109\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1088 - val_loss: 0.1057\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1035 - val_loss: 0.1014\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0991 - val_loss: 0.0977\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0953 - val_loss: 0.0944\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0920 - val_loss: 0.0916\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0892 - val_loss: 0.0892\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0868 - val_loss: 0.0871\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0845 - val_loss: 0.0851\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0824 - val_loss: 0.0834\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0819\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0805\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0776 - val_loss: 0.0792\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0763 - val_loss: 0.0781\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0752 - val_loss: 0.0770\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0761\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0752\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0743\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0735\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0728\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0721\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0715\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.0709\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0937\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4716 - val_loss: 0.3286\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2881 - val_loss: 0.2477\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2237 - val_loss: 0.2064\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1895 - val_loss: 0.1816\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1682 - val_loss: 0.1642\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1530 - val_loss: 0.1513\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1416 - val_loss: 0.1412\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1327 - val_loss: 0.1331\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1254 - val_loss: 0.1263\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1194 - val_loss: 0.1205\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1143 - val_loss: 0.1155\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1099 - val_loss: 0.1111\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1060 - val_loss: 0.1073\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1026 - val_loss: 0.1039\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0996 - val_loss: 0.1008\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0969 - val_loss: 0.0980\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0944 - val_loss: 0.0955\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.0933\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.0912\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.0894\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0868 - val_loss: 0.0877\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0861\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0839 - val_loss: 0.0847\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0834\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.0821\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0810\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0799\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0789\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0780\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.0771\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0724\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4867 - val_loss: 0.2752\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2375 - val_loss: 0.2073\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1876 - val_loss: 0.1707\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1594 - val_loss: 0.1480\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1413 - val_loss: 0.1326\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1290 - val_loss: 0.1218\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1201 - val_loss: 0.1137\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1135 - val_loss: 0.1075\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1082 - val_loss: 0.1025\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1038 - val_loss: 0.0985\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1001 - val_loss: 0.0949\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0969 - val_loss: 0.0919\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0941 - val_loss: 0.0893\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0916 - val_loss: 0.0870\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0894 - val_loss: 0.0849\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0874 - val_loss: 0.0830\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0856 - val_loss: 0.0813\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0840 - val_loss: 0.0797\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0782\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0768\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.0756\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.0744\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.0734\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.0724\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0716\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.0707\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0700\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0693\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0686\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0679\n",
      "19/19 [==============================] - 0s 847us/step - loss: 0.0691\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7293 - val_loss: 0.4882\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3512 - val_loss: 0.2451\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1848 - val_loss: 0.1399\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1156 - val_loss: 0.0982\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.0828\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0766\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0734\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0713\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0698\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0685\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0675\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0666\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0657 - val_loss: 0.0659\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0651 - val_loss: 0.0652\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0645 - val_loss: 0.0647\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0640 - val_loss: 0.0641\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0637\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0631 - val_loss: 0.0632\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0629\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0625\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0622\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0619 - val_loss: 0.0619\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0617\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0614\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0612\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0610\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0608\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.0607\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0605\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.0604\n",
      "19/19 [==============================] - 0s 866us/step - loss: 0.0603\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4885 - val_loss: 0.3165\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2899 - val_loss: 0.2404\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2291 - val_loss: 0.1961\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1911 - val_loss: 0.1669\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1659 - val_loss: 0.1474\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1482 - val_loss: 0.1332\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1353 - val_loss: 0.1231\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1255 - val_loss: 0.1149\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1177 - val_loss: 0.1087\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1115 - val_loss: 0.1037\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1064 - val_loss: 0.0993\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1022 - val_loss: 0.0958\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0985 - val_loss: 0.0928\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0953 - val_loss: 0.0901\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0926 - val_loss: 0.0878\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.0857\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0880 - val_loss: 0.0839\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0860 - val_loss: 0.0822\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0843 - val_loss: 0.0807\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0827 - val_loss: 0.0794\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0813 - val_loss: 0.0781\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0769\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0759\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0777 - val_loss: 0.0749\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0740\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.0731\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0747 - val_loss: 0.0723\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0715\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0731 - val_loss: 0.0708\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0702\n",
      "19/19 [==============================] - 0s 852us/step - loss: 0.0742\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4139 - val_loss: 0.2661\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2611 - val_loss: 0.2112\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2102 - val_loss: 0.1813\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.1820 - val_loss: 0.1611\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1633 - val_loss: 0.1460\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1492 - val_loss: 0.1343\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1380 - val_loss: 0.1249\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1290 - val_loss: 0.1173\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1215 - val_loss: 0.1109\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.111 - 0s 3ms/step - loss: 0.1152 - val_loss: 0.1055\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1099 - val_loss: 0.1009\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1053 - val_loss: 0.0969\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1013 - val_loss: 0.0933\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0977 - val_loss: 0.0903\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0946 - val_loss: 0.0875\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0919 - val_loss: 0.0851\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.0830\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0872 - val_loss: 0.0810\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0852 - val_loss: 0.0792\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0834 - val_loss: 0.0776\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0817 - val_loss: 0.0762\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0749\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0737\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.0725\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0715\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0706\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.0697\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0689\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.0682\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0675\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0741\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.8751 - val_loss: 0.4449\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2648 - val_loss: 0.1673\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1500 - val_loss: 0.1354\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1344 - val_loss: 0.1258\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1260 - val_loss: 0.1184\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1190 - val_loss: 0.1120\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1130 - val_loss: 0.1067\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1079 - val_loss: 0.1020\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1034 - val_loss: 0.0978\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0995 - val_loss: 0.0942\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0961 - val_loss: 0.0910\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.0882\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0903 - val_loss: 0.0857\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0879 - val_loss: 0.0835\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0858 - val_loss: 0.0815\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.0797\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0821 - val_loss: 0.0781\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0805 - val_loss: 0.0767\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0791 - val_loss: 0.0754\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0778 - val_loss: 0.0742\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0731\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0721\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0711\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0703\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0695\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0688\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.0682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0676\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0701 - val_loss: 0.0670\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0665\n",
      "19/19 [==============================] - 0s 844us/step - loss: 0.0676\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7614 - val_loss: 0.5129\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3727 - val_loss: 0.2673\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2024 - val_loss: 0.1571\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1363 - val_loss: 0.1216\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1170 - val_loss: 0.1110\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1096 - val_loss: 0.1052\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1046 - val_loss: 0.1008\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1004 - val_loss: 0.0970\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0967 - val_loss: 0.0936\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.0906\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.0879\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.0854\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0856 - val_loss: 0.0832\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0836 - val_loss: 0.0812\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.0794\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0778\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0763\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0750\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0758 - val_loss: 0.0738\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0726\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0716\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0706\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0715 - val_loss: 0.0697\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0689\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0682\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0675\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.0668\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0679 - val_loss: 0.0663\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0673 - val_loss: 0.0657\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0668 - val_loss: 0.0652\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0697\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4068 - val_loss: 0.2587\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2176 - val_loss: 0.2158\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1851 - val_loss: 0.1896\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1631 - val_loss: 0.1706\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1472 - val_loss: 0.1563\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1352 - val_loss: 0.1449\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1255 - val_loss: 0.1357\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.1277\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1112 - val_loss: 0.1211\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1057 - val_loss: 0.1155\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1012 - val_loss: 0.1105\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0973 - val_loss: 0.1063\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.1026\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0910 - val_loss: 0.0991\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0884 - val_loss: 0.0960\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0861 - val_loss: 0.0935\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0841 - val_loss: 0.0910\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0890\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0807 - val_loss: 0.0870\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0851\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0834\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0819\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0805\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0747 - val_loss: 0.0794\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0738 - val_loss: 0.0782\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0771\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0758\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.0750\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0706 - val_loss: 0.0741\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0731\n",
      "19/19 [==============================] - 0s 847us/step - loss: 0.0667\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9014 - val_loss: 0.5769\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3957 - val_loss: 0.2493\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1750 - val_loss: 0.1232\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1123 - val_loss: 0.0993\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1010 - val_loss: 0.0935\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0964 - val_loss: 0.0898\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0928 - val_loss: 0.0867\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0896 - val_loss: 0.0841\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.0818\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0845 - val_loss: 0.0797\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0823 - val_loss: 0.0779\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0804 - val_loss: 0.0763\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0749\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0736\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0724\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0714\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0705\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0696\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0689\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.0682\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0697 - val_loss: 0.0675\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0670\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0664\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0659\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0672 - val_loss: 0.0654\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0650\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0663 - val_loss: 0.0646\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0658 - val_loss: 0.0642\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0639\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0651 - val_loss: 0.0636\n",
      "19/19 [==============================] - 0s 803us/step - loss: 0.0635\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0806 - val_loss: 0.2741\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2632 - val_loss: 0.2196\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2127 - val_loss: 0.1910\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1836 - val_loss: 0.1719\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1641 - val_loss: 0.1574\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1496 - val_loss: 0.1459\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1383 - val_loss: 0.1368\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1293 - val_loss: 0.1293\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1219 - val_loss: 0.1231\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1158 - val_loss: 0.1179\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1107 - val_loss: 0.1134\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1064 - val_loss: 0.1095\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1026 - val_loss: 0.1061\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0993 - val_loss: 0.1030\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0963 - val_loss: 0.1003\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0936 - val_loss: 0.0979\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0912 - val_loss: 0.0956\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0891 - val_loss: 0.0936\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0872 - val_loss: 0.0918\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0854 - val_loss: 0.0901\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.0886\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0871\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0858\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0797 - val_loss: 0.0846\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0834\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0775 - val_loss: 0.0823\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0764 - val_loss: 0.0813\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0804\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0747 - val_loss: 0.0795\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0738 - val_loss: 0.0786\n",
      "19/19 [==============================] - 0s 950us/step - loss: 0.0829\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7243 - val_loss: 0.2779\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2270 - val_loss: 0.2017\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1903 - val_loss: 0.1789\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1686 - val_loss: 0.1612\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1515 - val_loss: 0.1473\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1380 - val_loss: 0.1359\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1269 - val_loss: 0.1265\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1178 - val_loss: 0.1187\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1102 - val_loss: 0.1118\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1038 - val_loss: 0.1062\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0985 - val_loss: 0.1014\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0940 - val_loss: 0.0973\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.0937\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0870 - val_loss: 0.0905\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0842 - val_loss: 0.0879\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0855\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0797 - val_loss: 0.0835\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0779 - val_loss: 0.0817\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0763 - val_loss: 0.0801\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0786\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0738 - val_loss: 0.0774\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0763\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0752\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0743\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0735\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0727\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0689 - val_loss: 0.0720\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0683 - val_loss: 0.0714\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0708\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0673 - val_loss: 0.0702\n",
      "19/19 [==============================] - 0s 879us/step - loss: 0.0698\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4136 - val_loss: 0.2898\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2774 - val_loss: 0.2274\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2277 - val_loss: 0.1947\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1972 - val_loss: 0.1719\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1751 - val_loss: 0.1544\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1575 - val_loss: 0.1400\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1432 - val_loss: 0.1280\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1316 - val_loss: 0.1184\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1223 - val_loss: 0.1111\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1056\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1093 - val_loss: 0.1009\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1045 - val_loss: 0.0969\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1004 - val_loss: 0.0935\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0968 - val_loss: 0.0904\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0937 - val_loss: 0.0877\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0909 - val_loss: 0.0853\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0883 - val_loss: 0.0831\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0860 - val_loss: 0.0811\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0840 - val_loss: 0.0793\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0822 - val_loss: 0.0776\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0805 - val_loss: 0.0760\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0789 - val_loss: 0.0747\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0775 - val_loss: 0.0734\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0763 - val_loss: 0.0723\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0752 - val_loss: 0.0712\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0741 - val_loss: 0.0702\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0693\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0685\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0677\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0670\n",
      "19/19 [==============================] - 0s 854us/step - loss: 0.0711\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2695 - val_loss: 0.2008\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1854 - val_loss: 0.1677\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1561 - val_loss: 0.1463\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1382 - val_loss: 0.1337\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1273 - val_loss: 0.1252\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1196 - val_loss: 0.1188\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1134 - val_loss: 0.1134\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1084 - val_loss: 0.1088\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1038 - val_loss: 0.1049\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0998 - val_loss: 0.1013\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0963 - val_loss: 0.0981\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0932 - val_loss: 0.0953\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0905 - val_loss: 0.0927\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0880 - val_loss: 0.0905\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0858 - val_loss: 0.0884\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0839 - val_loss: 0.0865\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0821 - val_loss: 0.0847\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0805 - val_loss: 0.0832\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0791 - val_loss: 0.0817\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0777 - val_loss: 0.0804\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0765 - val_loss: 0.0791\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0780\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0769\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0760\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0750\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0742\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0734\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.0727\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0719\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.0713\n",
      "19/19 [==============================] - 0s 879us/step - loss: 0.0651\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.7309 - val_loss: 0.5909\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.2390\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1851 - val_loss: 0.1422\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1319 - val_loss: 0.1194\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1169 - val_loss: 0.1101\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1085 - val_loss: 0.1035\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1020 - val_loss: 0.0980\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0966 - val_loss: 0.0935\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.0898\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0883 - val_loss: 0.0866\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0852 - val_loss: 0.0839\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0824 - val_loss: 0.0815\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0801 - val_loss: 0.0795\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0777\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0762 - val_loss: 0.0760\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0746\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0733\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0722\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.0712\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0698 - val_loss: 0.0702\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0689 - val_loss: 0.0694\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0680 - val_loss: 0.0686\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0673 - val_loss: 0.0679\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0672\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0661 - val_loss: 0.0666\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0655 - val_loss: 0.0661\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0650 - val_loss: 0.0656\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0646 - val_loss: 0.0651\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0642 - val_loss: 0.0647\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0643\n",
      "19/19 [==============================] - 0s 913us/step - loss: 0.0655\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2952 - val_loss: 0.1891\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1972 - val_loss: 0.1718\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1780 - val_loss: 0.1588\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1634 - val_loss: 0.1475\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1513 - val_loss: 0.1386\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1412 - val_loss: 0.1302\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1325 - val_loss: 0.1234\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1250 - val_loss: 0.1173\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1184 - val_loss: 0.1120\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1128 - val_loss: 0.1067\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1078 - val_loss: 0.1023\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1035 - val_loss: 0.0985\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0996 - val_loss: 0.0955\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0963 - val_loss: 0.0921\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0933 - val_loss: 0.0895\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0907 - val_loss: 0.0870\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0884 - val_loss: 0.0851\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0863 - val_loss: 0.0829\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0844 - val_loss: 0.0811\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0828 - val_loss: 0.0796\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0813 - val_loss: 0.0784\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0770\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0759\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0777 - val_loss: 0.0748\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0737\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0728\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0720\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0712\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.0706\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0699\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0746\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2887 - val_loss: 0.1840\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1713 - val_loss: 0.1599\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1531 - val_loss: 0.1455\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1401 - val_loss: 0.1347\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1302 - val_loss: 0.1260\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1223 - val_loss: 0.1191\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1158 - val_loss: 0.1131\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1104 - val_loss: 0.1082\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1059 - val_loss: 0.1039\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1021 - val_loss: 0.1005\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0988 - val_loss: 0.0974\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0958 - val_loss: 0.0946\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0933 - val_loss: 0.0922\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0910 - val_loss: 0.0901\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.0881\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0871 - val_loss: 0.0863\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0854 - val_loss: 0.0847\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0839 - val_loss: 0.0833\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0825 - val_loss: 0.0819\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0811 - val_loss: 0.0806\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0794\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0784\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0777 - val_loss: 0.0773\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0764\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0758 - val_loss: 0.0755\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0749 - val_loss: 0.0747\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0741 - val_loss: 0.0740\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0733\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.0727\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "19/19 [==============================] - 0s 861us/step - loss: 0.0743\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5378 - val_loss: 0.3249\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2781 - val_loss: 0.2545\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2370 - val_loss: 0.2251\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2110 - val_loss: 0.2009\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1896 - val_loss: 0.1807\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1715 - val_loss: 0.1637\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1563 - val_loss: 0.1494\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1434 - val_loss: 0.1370\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1324 - val_loss: 0.1264\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1229 - val_loss: 0.1173\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1148 - val_loss: 0.1094\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1078 - val_loss: 0.1026\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1018 - val_loss: 0.0966\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0966 - val_loss: 0.0914\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0920 - val_loss: 0.0869\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0881 - val_loss: 0.0830\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0847 - val_loss: 0.0795\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0765\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0738\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0715\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0695\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0677\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.0661\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0648\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0636\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.0625\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0615\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0671 - val_loss: 0.0607\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0664 - val_loss: 0.0599\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0593\n",
      "19/19 [==============================] - 0s 986us/step - loss: 0.0654\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.2267\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2038 - val_loss: 0.2013\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1837 - val_loss: 0.1844\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1687 - val_loss: 0.1708\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1566 - val_loss: 0.1593\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1463 - val_loss: 0.1495\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1375 - val_loss: 0.1411\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1299 - val_loss: 0.1337\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1233 - val_loss: 0.1272\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.1213\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.1162\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1076 - val_loss: 0.1116\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1034 - val_loss: 0.1073\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0996 - val_loss: 0.1036\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 0.1001\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0932 - val_loss: 0.0969\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0904 - val_loss: 0.0941\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0878 - val_loss: 0.0914\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0855 - val_loss: 0.0890\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0833 - val_loss: 0.0868\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0814 - val_loss: 0.0848\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0796 - val_loss: 0.0830\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.0813\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0797\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0782\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0769\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0726 - val_loss: 0.0756\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0745\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0734\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0724\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0671\n",
      "Epoch 1/30\n",
      "  1/133 [..............................] - ETA: 0s - loss: 0.7388WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0247s). Check your callbacks.\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.5370 - val_loss: 0.2977\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2372 - val_loss: 0.1824\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1824 - val_loss: 0.1626\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.1603 - val_loss: 0.1489\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1456 - val_loss: 0.1384\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1341 - val_loss: 0.1293\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1242 - val_loss: 0.1216\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1164 - val_loss: 0.1151\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1099 - val_loss: 0.1093\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1046 - val_loss: 0.1043\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0998 - val_loss: 0.0999\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0958 - val_loss: 0.0960\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0923 - val_loss: 0.0926\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.0897\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0870\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0842 - val_loss: 0.0848\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0821 - val_loss: 0.0828\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0810\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0794\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0772 - val_loss: 0.0780\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0767\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0747 - val_loss: 0.0755\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0745\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0735\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0726\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.0719\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.0712\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0698 - val_loss: 0.0705\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.0699\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.0694\n",
      "19/19 [==============================] - 0s 856us/step - loss: 0.0724\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.2717 - val_loss: 0.3172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2568 - val_loss: 0.2017\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2119 - val_loss: 0.1784\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1895 - val_loss: 0.1613\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1718 - val_loss: 0.1476\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1573 - val_loss: 0.1360\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1454 - val_loss: 0.1264\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1354 - val_loss: 0.1184\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1269 - val_loss: 0.1116\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1196 - val_loss: 0.1058\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1133 - val_loss: 0.1007\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1078 - val_loss: 0.0961\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1030 - val_loss: 0.0921\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0988 - val_loss: 0.0887\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0950 - val_loss: 0.0857\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.0828\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0889 - val_loss: 0.0803\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0862 - val_loss: 0.0782\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0839 - val_loss: 0.0761\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0744\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0727\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0782 - val_loss: 0.0713\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0699\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.0687\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0677\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0667\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0658\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.0649\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0641\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0634\n",
      "19/19 [==============================] - 0s 904us/step - loss: 0.0707\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3901 - val_loss: 0.2221\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1623 - val_loss: 0.1345\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1234 - val_loss: 0.1219\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1144 - val_loss: 0.1148\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1081 - val_loss: 0.1088\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1028 - val_loss: 0.1037\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0985 - val_loss: 0.0994\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0948 - val_loss: 0.0958\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0916 - val_loss: 0.0926\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.0899\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0867 - val_loss: 0.0876\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0847 - val_loss: 0.0855\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0829 - val_loss: 0.0837\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0821\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0807\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0794\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.0783\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.0772\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0762\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0748 - val_loss: 0.0754\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0745\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0738\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0731\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0724\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0718\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.0713\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0707\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0702\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.0697\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0693\n",
      "19/19 [==============================] - 0s 862us/step - loss: 0.0902\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2787 - val_loss: 0.1266\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1177 - val_loss: 0.1000\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0956 - val_loss: 0.0894\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0862 - val_loss: 0.0845\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0804\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0764 - val_loss: 0.0787\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0757\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0715 - val_loss: 0.0740\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0726\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0716\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0670 - val_loss: 0.0707\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0695\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0650 - val_loss: 0.0688\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.0687\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0678\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0669\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0623 - val_loss: 0.0669\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0616 - val_loss: 0.0660\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0610 - val_loss: 0.0656\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.0651\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0602 - val_loss: 0.0648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0599 - val_loss: 0.0645\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0640\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0637\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0648\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0635\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0629\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0627\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0624\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0621\n",
      "19/19 [==============================] - 0s 832us/step - loss: 0.0640\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2187 - val_loss: 0.1232\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1076 - val_loss: 0.1033\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0917 - val_loss: 0.0911\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0829 - val_loss: 0.0833\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0778 - val_loss: 0.0797\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0744 - val_loss: 0.0762\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0715 - val_loss: 0.0736\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0720\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0680 - val_loss: 0.0706\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0702\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.0684\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0645 - val_loss: 0.0669\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0636 - val_loss: 0.0670\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0629 - val_loss: 0.0662\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0652\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0646\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0634\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.0632\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0599 - val_loss: 0.0629\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0627\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0619\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0633\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0616\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0609\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0605\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0603\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.0607\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.0597\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0599\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.0593\n",
      "19/19 [==============================] - 0s 909us/step - loss: 0.0569\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2110 - val_loss: 0.1303\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1236 - val_loss: 0.1008\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1020 - val_loss: 0.0891\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0913 - val_loss: 0.0821\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0840 - val_loss: 0.0784\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0751\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0717\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0716\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0680\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0663\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.0650\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0639\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0648 - val_loss: 0.0629\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0639 - val_loss: 0.0624\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0612\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0607\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0599\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.0597\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.0591\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0586\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0592 - val_loss: 0.0582\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0582\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0575\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0573\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0569\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0569\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.0572\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0562\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.0559\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.0559\n",
      "19/19 [==============================] - 0s 859us/step - loss: 0.0627\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2655 - val_loss: 0.1596\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1311 - val_loss: 0.1142\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0958 - val_loss: 0.0953\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0847 - val_loss: 0.0862\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0810\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0754 - val_loss: 0.0772\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0755\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0730\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.0716\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0680 - val_loss: 0.0697\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0684\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0678\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0650 - val_loss: 0.0668\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0642 - val_loss: 0.0657\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0653\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0649\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0623 - val_loss: 0.0641\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0639\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.0627\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.0623\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.0619\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0616\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0612\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0610\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0609\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0604\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0601\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0604\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0600\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0594\n",
      "19/19 [==============================] - 0s 855us/step - loss: 0.0612\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.1383\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1264 - val_loss: 0.1070\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1032 - val_loss: 0.0944\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0918 - val_loss: 0.0868\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0849 - val_loss: 0.0818\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.0782\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0753\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0733\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0716\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0698\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0680 - val_loss: 0.0684\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0674\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.0663\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0654\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.0646\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0630 - val_loss: 0.0639\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0623 - val_loss: 0.0633\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0627\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0612 - val_loss: 0.0622\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0618\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0602 - val_loss: 0.0614\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0608\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0603\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0600\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0605\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0593\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0589\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0592\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0585\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.0583\n",
      "19/19 [==============================] - 0s 922us/step - loss: 0.0644\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2115 - val_loss: 0.1391\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1252 - val_loss: 0.1072\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1013 - val_loss: 0.0935\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.0838\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0833 - val_loss: 0.0808\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0786 - val_loss: 0.0755\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0749 - val_loss: 0.0727\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.0716\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0706 - val_loss: 0.0689\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0675\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0665\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0663 - val_loss: 0.0655\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0653 - val_loss: 0.0648\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0643 - val_loss: 0.0641\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0634 - val_loss: 0.0634\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0629\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.0625\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0619\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0622\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.0610\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0607\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0604\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0601\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0598\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0598\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0596\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0591\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0590\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.0593\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 933us/step - loss: 0.0609\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.2940 - val_loss: 0.1251\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1165 - val_loss: 0.0957\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.0854\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0863 - val_loss: 0.0796\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0808 - val_loss: 0.0750\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0770 - val_loss: 0.0725\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0702\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.0689\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0700 - val_loss: 0.0681\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0671\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0673 - val_loss: 0.0661\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0662 - val_loss: 0.0657\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0653 - val_loss: 0.0649\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0642 - val_loss: 0.0645\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.0641\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0629 - val_loss: 0.0635\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0623 - val_loss: 0.0635\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0631\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.0627\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.0625\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.0624\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0599 - val_loss: 0.0621\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0619\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0592 - val_loss: 0.0618\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0613\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0613\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0619\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0607\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0610\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0604\n",
      "19/19 [==============================] - 0s 953us/step - loss: 0.0597\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2031 - val_loss: 0.1472\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.1047\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0951 - val_loss: 0.0949\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0859 - val_loss: 0.0872\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0801 - val_loss: 0.0831\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0782\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0765\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0746\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0686 - val_loss: 0.0723\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0672 - val_loss: 0.0712\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.0704\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0649 - val_loss: 0.0687\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0640 - val_loss: 0.0681\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0630 - val_loss: 0.0677\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0622 - val_loss: 0.0670\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0661\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0653\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0647\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0602 - val_loss: 0.0644\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0639\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.0640\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0658\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0631\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0639\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0626\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0623\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0620\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0617\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.0616\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0568 - val_loss: 0.0612\n",
      "19/19 [==============================] - 0s 939us/step - loss: 0.0579\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3163 - val_loss: 0.1177\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1117 - val_loss: 0.0943\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0913 - val_loss: 0.0789\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0819 - val_loss: 0.0740\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.0710\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0692\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.0673\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0661\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0657\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0642\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0651 - val_loss: 0.0635\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0632\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0633 - val_loss: 0.0624\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0613\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0614\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0606\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0610 - val_loss: 0.0604\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.0605\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0594\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.0587\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0592 - val_loss: 0.0586\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0581\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0580\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0576\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0575\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0574\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0569\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0569\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.0565\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.0564\n",
      "19/19 [==============================] - 0s 936us/step - loss: 0.0683\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2391 - val_loss: 0.1382\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1288 - val_loss: 0.1088\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1039 - val_loss: 0.0917\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.0842\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0781\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0742\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0762 - val_loss: 0.0716\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0691\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.0673\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0661\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0655\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0663 - val_loss: 0.0635\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0650 - val_loss: 0.0641\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.0619\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0632 - val_loss: 0.0614\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0624 - val_loss: 0.0605\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0616 - val_loss: 0.0602\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0600\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0591\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0587\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.0584\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0581\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0581\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0575\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0572\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0572\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0569\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.0567\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0568 - val_loss: 0.0566\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.0565\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0634\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2103 - val_loss: 0.1457\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1210 - val_loss: 0.1172\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1012 - val_loss: 0.0987\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0912 - val_loss: 0.0919\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0854 - val_loss: 0.0851\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0811 - val_loss: 0.0804\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0778 - val_loss: 0.0769\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0753\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0731 - val_loss: 0.0720\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0708\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0698 - val_loss: 0.0687\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0686 - val_loss: 0.0675\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0668\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0664 - val_loss: 0.0656\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0655 - val_loss: 0.0651\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0647 - val_loss: 0.0643\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0640 - val_loss: 0.0627\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0634 - val_loss: 0.0620\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0616\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0623 - val_loss: 0.0610\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0605\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0601\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.0597\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.0600\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0589\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0588\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0583\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0581\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0589\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0576\n",
      "19/19 [==============================] - 0s 862us/step - loss: 0.0605\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1546 - val_loss: 0.1036\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1009 - val_loss: 0.0895\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0891 - val_loss: 0.0814\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0828 - val_loss: 0.0770\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0749\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.0731\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0738 - val_loss: 0.0713\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.0701\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0696\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.0684\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0675\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0669 - val_loss: 0.0681\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.0661\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0651 - val_loss: 0.0653\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0646 - val_loss: 0.0656\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0637 - val_loss: 0.0646\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0633 - val_loss: 0.0641\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0646\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0622 - val_loss: 0.0632\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0616 - val_loss: 0.0628\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.0626\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0636\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.0637\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0625\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0616\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0592 - val_loss: 0.0612\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0618\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0623\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0606\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0604\n",
      "19/19 [==============================] - 0s 874us/step - loss: 0.0659\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2563 - val_loss: 0.1387\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1285 - val_loss: 0.1061\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1014 - val_loss: 0.0932\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0886 - val_loss: 0.0830\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0813 - val_loss: 0.0785\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.0751\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0728\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0708\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0694 - val_loss: 0.0693\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0683\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0663 - val_loss: 0.0671\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0652 - val_loss: 0.0664\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0642 - val_loss: 0.0659\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0652\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0640\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0619 - val_loss: 0.0634\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.0628\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0632\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0602 - val_loss: 0.0618\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0618\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.0612\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0609\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0608\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0602\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0599\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0596\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0593\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.0592\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.0593\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0586\n",
      "19/19 [==============================] - 0s 947us/step - loss: 0.0585\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2428 - val_loss: 0.1433\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1226 - val_loss: 0.1062\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0981 - val_loss: 0.0914\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0872 - val_loss: 0.0832\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0782\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0760\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0724\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0739\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.0688\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0669 - val_loss: 0.0668\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0655 - val_loss: 0.0656\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0647\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0636\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0629\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0619 - val_loss: 0.0622\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0612 - val_loss: 0.0618\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.0611\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0605\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.0601\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0598\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.060 - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0593\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0592\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0589\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0588\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0582\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.0580\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.0577\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.0576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0562 - val_loss: 0.0574\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0560 - val_loss: 0.0574\n",
      "19/19 [==============================] - 0s 927us/step - loss: 0.0658\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2920 - val_loss: 0.1811\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1305 - val_loss: 0.1072\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1030 - val_loss: 0.0959\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0927 - val_loss: 0.0908\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0859 - val_loss: 0.0836\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0795\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0773\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0743\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0725\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0724\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.0695\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0681\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0657 - val_loss: 0.0670\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.0669\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0636 - val_loss: 0.0652\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0643\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0617 - val_loss: 0.0642\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0610 - val_loss: 0.0628\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.0629\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0619\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.0612\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0606\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0603\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0597\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0600\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.0594\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0568 - val_loss: 0.0589\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.0621\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0562 - val_loss: 0.0584\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0584\n",
      "19/19 [==============================] - 0s 933us/step - loss: 0.0662\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2285 - val_loss: 0.1415\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1255 - val_loss: 0.1032\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1024 - val_loss: 0.0911\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.0842\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0799\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0786 - val_loss: 0.0772\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.0748\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0729\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0716\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0704\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.0694\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0663 - val_loss: 0.0686\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0652 - val_loss: 0.0684\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0643 - val_loss: 0.0671\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0671\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0659\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.0654\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0645\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0640\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.0636\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0632\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0630\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0625\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0620\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0619\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0614\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0624\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0611\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.0608\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0606\n",
      "19/19 [==============================] - 0s 994us/step - loss: 0.0585\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3249 - val_loss: 0.1478\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1254 - val_loss: 0.1022\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0972 - val_loss: 0.0860\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0776\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0729\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0748 - val_loss: 0.0709\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0682\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0698 - val_loss: 0.0658\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0683 - val_loss: 0.0643\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0669 - val_loss: 0.0636\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0624\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0650 - val_loss: 0.0616\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0608\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0633 - val_loss: 0.0602\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0599\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0592\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0586\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0585\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.0578\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0581\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0572\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.0574\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0569\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0564\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0567\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0566\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0558\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0557\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0554\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0553\n",
      "19/19 [==============================] - 0s 917us/step - loss: 0.0695\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2362 - val_loss: 0.1447\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1156 - val_loss: 0.1159\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0959 - val_loss: 0.0972\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0868 - val_loss: 0.0897\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0813 - val_loss: 0.0851\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0774 - val_loss: 0.0813\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0785\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0759\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0744\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.0725\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0672 - val_loss: 0.0706\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.0692\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0650 - val_loss: 0.0682\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0640 - val_loss: 0.0674\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0631 - val_loss: 0.0664\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0624 - val_loss: 0.0663\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0617 - val_loss: 0.0651\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0648\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0638\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0632\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0628\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0622\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0619\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0616\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0611\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0612\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0606\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.0604\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0608\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0564 - val_loss: 0.0598\n",
      "19/19 [==============================] - 0s 877us/step - loss: 0.0586\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3004 - val_loss: 0.1232\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1051 - val_loss: 0.0962\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0896 - val_loss: 0.0860\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0824 - val_loss: 0.0805\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0777 - val_loss: 0.0768\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0739\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0717\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0706\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0686\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0664 - val_loss: 0.0679\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0652 - val_loss: 0.0677\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0642 - val_loss: 0.0662\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0633 - val_loss: 0.0651\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0645\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0638\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0633\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.0628\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0625\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0622\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0592 - val_loss: 0.0616\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0612\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0609\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0609\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0610\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0600\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0603\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.0598\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0602\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.0600\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.0591\n",
      "19/19 [==============================] - 0s 818us/step - loss: 0.0590\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2845 - val_loss: 0.1527\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1320 - val_loss: 0.1202\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1066 - val_loss: 0.1053\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0931 - val_loss: 0.0959\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.0909\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0817 - val_loss: 0.0861\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0835\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0808\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0783\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0706 - val_loss: 0.0767\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0749\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0673 - val_loss: 0.0732\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.0723\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0649 - val_loss: 0.0713\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0640 - val_loss: 0.0699\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0632 - val_loss: 0.0697\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0624 - val_loss: 0.0682\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0686\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0612 - val_loss: 0.0670\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.0662\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0664\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0654\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0647\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0644\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0647\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0634\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0638\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.0635\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0631\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.0622\n",
      "19/19 [==============================] - 0s 959us/step - loss: 0.0592\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2754 - val_loss: 0.1662\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1283 - val_loss: 0.1185\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0995 - val_loss: 0.0983\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0882 - val_loss: 0.0890\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0837\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0804\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0738 - val_loss: 0.0771\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.0744\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0725\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0719\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0708\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0689\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0648 - val_loss: 0.0680\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.0669\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0633 - val_loss: 0.0663\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.062 - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0654\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.0649\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0644\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0612 - val_loss: 0.0640\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0643\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.0630\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0599 - val_loss: 0.0625\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0625\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0592 - val_loss: 0.0621\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0620\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0614\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0616\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0608\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0619\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0604\n",
      "19/19 [==============================] - 0s 846us/step - loss: 0.0596\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2590 - val_loss: 0.1213\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1227 - val_loss: 0.0995\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1009 - val_loss: 0.0897\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.0843\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0849 - val_loss: 0.0802\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0807 - val_loss: 0.0773\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0756\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0748 - val_loss: 0.0733\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.0710\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0691\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0679\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0675\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.0668\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0648 - val_loss: 0.0666\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0640 - val_loss: 0.0649\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0632 - val_loss: 0.0647\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0626 - val_loss: 0.0641\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.0634\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0632\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0610 - val_loss: 0.0625\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0622\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0618\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0617\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0615\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0611\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0604\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0603\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0606\n",
      "19/19 [==============================] - 0s 882us/step - loss: 0.0613\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2625 - val_loss: 0.1286\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1156 - val_loss: 0.0974\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0944 - val_loss: 0.0857\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0847 - val_loss: 0.0797\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0760\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0745\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0716\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.0702\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.0690\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0672 - val_loss: 0.0680\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0684\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0649 - val_loss: 0.0671\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0639 - val_loss: 0.0657\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0632 - val_loss: 0.0650\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0622 - val_loss: 0.0647\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0640\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0635\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.0631\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0626\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.0623\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0622\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0620\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0613\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0612\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0608\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0607\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.0604\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0562 - val_loss: 0.0601\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0560 - val_loss: 0.0599\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0557 - val_loss: 0.0601\n",
      "19/19 [==============================] - 0s 954us/step - loss: 0.0644\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2130 - val_loss: 0.1330\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1099 - val_loss: 0.1034\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.0916\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0845 - val_loss: 0.0844\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0799\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0769\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0740\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0718\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0700\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0685\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0663 - val_loss: 0.0670\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.0660\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0648\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.0638\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0623 - val_loss: 0.0630\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0616 - val_loss: 0.0625\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0610 - val_loss: 0.0616\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0613\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0605\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.0600\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0595\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0591\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0587\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0585\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0580\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.0578\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0568 - val_loss: 0.0576\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0573\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.0571\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0561 - val_loss: 0.0569\n",
      "19/19 [==============================] - 0s 840us/step - loss: 0.0612\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1845 - val_loss: 0.1325\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1133 - val_loss: 0.1080\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0947 - val_loss: 0.1029\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0859 - val_loss: 0.0902\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0877\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0764 - val_loss: 0.0820\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0798\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0774\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0698 - val_loss: 0.0760\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0752\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0672 - val_loss: 0.0734\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.0725\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0721\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0643 - val_loss: 0.0710\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0714\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0694\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0623 - val_loss: 0.0691\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0617 - val_loss: 0.0686\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0612 - val_loss: 0.0684\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0677\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0677\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0668\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0660\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0659\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0654\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0655\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0652\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0643\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0648\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0641\n",
      "19/19 [==============================] - 0s 916us/step - loss: 0.0624\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1869 - val_loss: 0.1329\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1090 - val_loss: 0.0915\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0931 - val_loss: 0.0841\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0864 - val_loss: 0.0796\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0813 - val_loss: 0.0762\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0766\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.0714\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0693\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0697\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0667\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0658\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0648\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0662 - val_loss: 0.0644\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0629\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0648 - val_loss: 0.0630\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0639 - val_loss: 0.0616\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0611\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0606\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0618\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0619 - val_loss: 0.0601\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0594\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0591\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0586\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0582\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0584\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0577\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0576\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0571\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0569\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0567\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0634\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2865 - val_loss: 0.1231\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1107 - val_loss: 0.0983\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0926 - val_loss: 0.0893\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0846 - val_loss: 0.0828\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.0793\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0763\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0741\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.0727\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0712\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0680 - val_loss: 0.0700\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0668 - val_loss: 0.0689\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0657 - val_loss: 0.0679\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0647 - val_loss: 0.0675\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0639 - val_loss: 0.0664\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0633 - val_loss: 0.0659\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0626 - val_loss: 0.0653\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0648\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.0643\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0638\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.0635\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0630\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0627\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0626\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.0621\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0620\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0615\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0617\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0610\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0611\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0612\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0599\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2214 - val_loss: 0.1280\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1218 - val_loss: 0.1015\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1003 - val_loss: 0.0947\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0888 - val_loss: 0.0883\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0823 - val_loss: 0.0816\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0775 - val_loss: 0.0797\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0748 - val_loss: 0.0760\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0741\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0701 - val_loss: 0.0730\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.0705\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0670 - val_loss: 0.0696\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0689\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0648 - val_loss: 0.0673\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0639 - val_loss: 0.0679\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0632 - val_loss: 0.0686\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0657\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0649\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0610 - val_loss: 0.0644\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.0641\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0654\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0634\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0635\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0621\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0634\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0618\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0614\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0611\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0607\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.0605\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.0625\n",
      "19/19 [==============================] - 0s 934us/step - loss: 0.0676\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3240 - val_loss: 0.1362\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1012 - val_loss: 0.0988\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0854 - val_loss: 0.0895\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0826\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0779\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.0748\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.0728\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0674 - val_loss: 0.0704\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.0694\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0647 - val_loss: 0.0680\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0639 - val_loss: 0.0668\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0658\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.0652\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0616 - val_loss: 0.0645\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0610 - val_loss: 0.0639\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.0638\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0626\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0624\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0618\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0614\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0610\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0607\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0604\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0601\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.0598\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.0595\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0593\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.0593\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0562 - val_loss: 0.0589\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0586\n",
      "19/19 [==============================] - 0s 860us/step - loss: 0.0652\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1969 - val_loss: 0.1232\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1108 - val_loss: 0.0994\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0932 - val_loss: 0.0899\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.0827\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0797 - val_loss: 0.0783\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0757\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0730\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0706 - val_loss: 0.0711\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0686 - val_loss: 0.0707\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0671 - val_loss: 0.0694\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0657 - val_loss: 0.0671\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0645 - val_loss: 0.0661\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0656\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0651\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0619 - val_loss: 0.0642\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.0633\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0629\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0623\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0626\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0615\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0610\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0605\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0606\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.0619\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0600\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.0596\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0562 - val_loss: 0.0608\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0560 - val_loss: 0.0593\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0557 - val_loss: 0.0595\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0589\n",
      "19/19 [==============================] - 0s 904us/step - loss: 0.0616\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7086 - val_loss: 0.3528\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2940 - val_loss: 0.2346\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2103 - val_loss: 0.1845\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1710 - val_loss: 0.1557\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1478 - val_loss: 0.1383\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1324 - val_loss: 0.1258\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1211 - val_loss: 0.1173\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1131 - val_loss: 0.1087\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1065 - val_loss: 0.1028\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1012 - val_loss: 0.0980\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0966 - val_loss: 0.0940\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.0908\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0897 - val_loss: 0.0879\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.0854\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0845 - val_loss: 0.0831\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0822 - val_loss: 0.0809\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0791\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.0774\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.0761\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0747\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0734\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0731 - val_loss: 0.0724\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0712\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0706\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0700 - val_loss: 0.0696\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.0693\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0683 - val_loss: 0.0678\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0673\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0669 - val_loss: 0.0667\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0662 - val_loss: 0.0659\n",
      "19/19 [==============================] - 0s 849us/step - loss: 0.0674\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0101 - val_loss: 0.4291\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3106 - val_loss: 0.2283\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1955 - val_loss: 0.1718\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1558 - val_loss: 0.1466\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1359 - val_loss: 0.1320\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1239 - val_loss: 0.1221\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1150 - val_loss: 0.1146\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1085 - val_loss: 0.1087\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1033 - val_loss: 0.1040\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0989 - val_loss: 0.1005\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0952 - val_loss: 0.0967\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.0937\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0895 - val_loss: 0.0914\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0871 - val_loss: 0.0892\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.0868\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0832 - val_loss: 0.0851\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0816 - val_loss: 0.0833\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0819\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0804\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0774 - val_loss: 0.0793\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0763 - val_loss: 0.0779\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0752 - val_loss: 0.0776\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0760\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.0753\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0742\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0734\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.0728\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0703 - val_loss: 0.0718\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0697 - val_loss: 0.0714\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.0706\n",
      "19/19 [==============================] - 0s 892us/step - loss: 0.0648\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.1559 - val_loss: 0.3553\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3130 - val_loss: 0.2023\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2055 - val_loss: 0.1574\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1641 - val_loss: 0.1342\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1420 - val_loss: 0.1209\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1275 - val_loss: 0.1109\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1173 - val_loss: 0.1030\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1093 - val_loss: 0.0979\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1030 - val_loss: 0.0922\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0980 - val_loss: 0.0882\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0939 - val_loss: 0.0848\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0904 - val_loss: 0.0822\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0875 - val_loss: 0.0797\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.0778\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0828 - val_loss: 0.0756\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0743\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0792 - val_loss: 0.0729\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0776 - val_loss: 0.0713\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0764 - val_loss: 0.0702\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0690\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0681\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0730 - val_loss: 0.0672\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.0667\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0657\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0703 - val_loss: 0.0649\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0647\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0689 - val_loss: 0.0636\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0682 - val_loss: 0.0631\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0625\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0670 - val_loss: 0.0620\n",
      "19/19 [==============================] - 0s 821us/step - loss: 0.0628\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.8176 - val_loss: 0.4282\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3250 - val_loss: 0.2456\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2054 - val_loss: 0.1799\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1586 - val_loss: 0.1497\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1357 - val_loss: 0.1329\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1217 - val_loss: 0.1218\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1124 - val_loss: 0.1143\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1056 - val_loss: 0.1082\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1003 - val_loss: 0.1037\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0958 - val_loss: 0.0997\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.0960\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.0936\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0863 - val_loss: 0.0908\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0839 - val_loss: 0.0888\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0870\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0851\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0783 - val_loss: 0.0830\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0820\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.0802\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0790\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0780\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0768\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0758\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0700 - val_loss: 0.0749\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.0741\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.0733\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0726\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0671 - val_loss: 0.0721\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0665 - val_loss: 0.0713\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0710\n",
      "19/19 [==============================] - 0s 840us/step - loss: 0.0662\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3221 - val_loss: 0.2405\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2104 - val_loss: 0.1939\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1762 - val_loss: 0.1666\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1549 - val_loss: 0.1483\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1402 - val_loss: 0.1349\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1291 - val_loss: 0.1248\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1203 - val_loss: 0.1175\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1134 - val_loss: 0.1098\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1073 - val_loss: 0.1044\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1025 - val_loss: 0.1002\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0983 - val_loss: 0.0961\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0950 - val_loss: 0.0928\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0919 - val_loss: 0.0897\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0892 - val_loss: 0.0871\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.0851\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0832\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0812\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0796\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0779\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.0766\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0772 - val_loss: 0.0753\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.0741\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0730\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0720\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0730 - val_loss: 0.0735\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0703\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0695\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0706 - val_loss: 0.0694\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0701 - val_loss: 0.0682\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0673\n",
      "19/19 [==============================] - 0s 824us/step - loss: 0.1359\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3439 - val_loss: 0.2278\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2007 - val_loss: 0.1691\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1556 - val_loss: 0.1398\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1309 - val_loss: 0.1224\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1153 - val_loss: 0.1106\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1048 - val_loss: 0.1022\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0972 - val_loss: 0.0960\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0915 - val_loss: 0.0912\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0870 - val_loss: 0.0873\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0835 - val_loss: 0.0842\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0816\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0782 - val_loss: 0.0794\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0762 - val_loss: 0.0775\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0757\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0742\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.0730\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.0718\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.0707\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0698\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0674 - val_loss: 0.0688\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0681\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.0673\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0653 - val_loss: 0.0666\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0647 - val_loss: 0.0660\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0642 - val_loss: 0.0654\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0636 - val_loss: 0.0648\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0632 - val_loss: 0.0644\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0639\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.0640\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0619 - val_loss: 0.0630\n",
      "19/19 [==============================] - 0s 863us/step - loss: 0.0659\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6377 - val_loss: 0.2902\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2368 - val_loss: 0.2218\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1835 - val_loss: 0.1833\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1568 - val_loss: 0.1612\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1405 - val_loss: 0.1469\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1288 - val_loss: 0.1352\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1198 - val_loss: 0.1260\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1128 - val_loss: 0.1190\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1070 - val_loss: 0.1129\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1025 - val_loss: 0.1085\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0984 - val_loss: 0.1041\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0950 - val_loss: 0.1005\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0920 - val_loss: 0.0970\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0893 - val_loss: 0.0946\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.0921\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0896\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0827 - val_loss: 0.0882\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0861\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0794 - val_loss: 0.0843\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0779 - val_loss: 0.0828\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0815\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0752 - val_loss: 0.0801\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0790\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0780\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0769\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0759\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.0751\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0741\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0734\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0726\n",
      "19/19 [==============================] - 0s 844us/step - loss: 0.0753\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9601 - val_loss: 0.3941\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3027 - val_loss: 0.2355\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2032 - val_loss: 0.1820\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1611 - val_loss: 0.1548\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1383 - val_loss: 0.1371\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1239 - val_loss: 0.1253\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1140 - val_loss: 0.1170\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1067 - val_loss: 0.1109\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1010 - val_loss: 0.1055\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0964 - val_loss: 0.1017\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0929 - val_loss: 0.0976\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0897 - val_loss: 0.0943\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0871 - val_loss: 0.0918\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0894\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0828 - val_loss: 0.0875\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0854\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0835\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0820\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0805\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0791\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0780\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0769\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0759\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0747\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0739\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0732\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0722\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0689 - val_loss: 0.0715\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0708\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0702\n",
      "19/19 [==============================] - 0s 816us/step - loss: 0.0669\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5322 - val_loss: 0.2880\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2417 - val_loss: 0.1923\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1807 - val_loss: 0.1530\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1514 - val_loss: 0.1334\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1336 - val_loss: 0.1209\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1215 - val_loss: 0.1119\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1126 - val_loss: 0.1056\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1058 - val_loss: 0.1003\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1003 - val_loss: 0.0960\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0958 - val_loss: 0.0926\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.0900\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0889 - val_loss: 0.0872\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0863 - val_loss: 0.0851\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0840 - val_loss: 0.0831\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0820 - val_loss: 0.0813\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0801 - val_loss: 0.0799\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0783\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.0773\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0758\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0747\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.0737\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0724 - val_loss: 0.0728\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0711\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0698 - val_loss: 0.0703\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.0697\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0692\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0679 - val_loss: 0.0685\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0673 - val_loss: 0.0678\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0673\n",
      "19/19 [==============================] - 0s 930us/step - loss: 0.1009\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9441 - val_loss: 0.3339\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2573 - val_loss: 0.1990\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1863 - val_loss: 0.1619\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1575 - val_loss: 0.1414\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1397 - val_loss: 0.1276\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1271 - val_loss: 0.1172\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1176 - val_loss: 0.1095\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1098 - val_loss: 0.1034\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1039 - val_loss: 0.0982\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0991 - val_loss: 0.0936\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0948 - val_loss: 0.0900\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.0870\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0880 - val_loss: 0.0848\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0852 - val_loss: 0.0822\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0829 - val_loss: 0.0800\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0782\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.0766\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.0752\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0758 - val_loss: 0.0738\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0726\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0715\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0705\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0698\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0701 - val_loss: 0.0688\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.0680\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.0674\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0668\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0672 - val_loss: 0.0661\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0665 - val_loss: 0.0655\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0650\n",
      "19/19 [==============================] - 0s 890us/step - loss: 0.0692\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.8189 - val_loss: 0.3721\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2953 - val_loss: 0.2150\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1951 - val_loss: 0.1574\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1526 - val_loss: 0.1304\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1304 - val_loss: 0.1146\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1168 - val_loss: 0.1048\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1075 - val_loss: 0.0977\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1014 - val_loss: 0.0927\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0964 - val_loss: 0.0893\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0926 - val_loss: 0.0858\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0895 - val_loss: 0.0832\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.0811\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0847 - val_loss: 0.0791\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0828 - val_loss: 0.0775\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0811 - val_loss: 0.0759\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.0749\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0783 - val_loss: 0.0737\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0723\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0714\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0704\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0695\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0688\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0724 - val_loss: 0.0679\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.0674\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0666\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0703 - val_loss: 0.0662\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0697 - val_loss: 0.0655\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0649\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0686 - val_loss: 0.0644\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0639\n",
      "19/19 [==============================] - 0s 822us/step - loss: 0.0701\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7488 - val_loss: 0.3236\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2991 - val_loss: 0.2237\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2174 - val_loss: 0.1852\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1800 - val_loss: 0.1592\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1574 - val_loss: 0.1505\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1425 - val_loss: 0.1320\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1308 - val_loss: 0.1225\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1229 - val_loss: 0.1161\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1160 - val_loss: 0.1107\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1102 - val_loss: 0.1059\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1057 - val_loss: 0.1013\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1015 - val_loss: 0.0976\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0978 - val_loss: 0.0956\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0951 - val_loss: 0.0920\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0925 - val_loss: 0.0900\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.0878\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0881 - val_loss: 0.0862\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0864 - val_loss: 0.0847\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0845 - val_loss: 0.0825\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0810\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.0800\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0802 - val_loss: 0.0797\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0780\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0779 - val_loss: 0.0763\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0757\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0744\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0749 - val_loss: 0.0737\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0741 - val_loss: 0.0731\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0722\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.0715\n",
      "19/19 [==============================] - 0s 876us/step - loss: 0.1122\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.2752\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2285 - val_loss: 0.1987\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1739 - val_loss: 0.1648\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1478 - val_loss: 0.1435\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1320 - val_loss: 0.1309\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1217 - val_loss: 0.1213\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1137 - val_loss: 0.1139\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1077 - val_loss: 0.1089\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1030 - val_loss: 0.1036\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0987 - val_loss: 0.0999\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0951 - val_loss: 0.0965\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.0941\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0895 - val_loss: 0.0912\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0873 - val_loss: 0.0885\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0852 - val_loss: 0.0864\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0833 - val_loss: 0.0844\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.0827\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0801 - val_loss: 0.0811\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0798\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0774 - val_loss: 0.0786\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.0771\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0760\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0750\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0731 - val_loss: 0.0741\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0730\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0722\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0706 - val_loss: 0.0713\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0698 - val_loss: 0.0706\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0699\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.0692\n",
      "19/19 [==============================] - 0s 944us/step - loss: 0.0690\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7629 - val_loss: 0.3565\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3062 - val_loss: 0.2472\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2299 - val_loss: 0.1990\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1917 - val_loss: 0.1725\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1674 - val_loss: 0.1545\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1503 - val_loss: 0.1426\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1377 - val_loss: 0.1307\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1277 - val_loss: 0.1248\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1199 - val_loss: 0.1161\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1134 - val_loss: 0.1110\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1081 - val_loss: 0.1058\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1034 - val_loss: 0.1019\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0995 - val_loss: 0.0976\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0961 - val_loss: 0.0949\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.0917\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0904 - val_loss: 0.0895\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0880 - val_loss: 0.0875\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0859 - val_loss: 0.0854\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0839 - val_loss: 0.0831\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0822 - val_loss: 0.0817\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0802\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0792 - val_loss: 0.0785\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0778 - val_loss: 0.0772\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0765 - val_loss: 0.0762\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0754 - val_loss: 0.0751\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0742\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0730\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0723\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0712\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0705\n",
      "19/19 [==============================] - 0s 914us/step - loss: 0.0730\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6549 - val_loss: 0.2893\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2526 - val_loss: 0.1770\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1709 - val_loss: 0.1379\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1380 - val_loss: 0.1196\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1204 - val_loss: 0.1076\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1093 - val_loss: 0.1000\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1017 - val_loss: 0.0941\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0960 - val_loss: 0.0897\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.0864\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0884 - val_loss: 0.0834\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0854 - val_loss: 0.0812\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.0793\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0773\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0791 - val_loss: 0.0756\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0774 - val_loss: 0.0746\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0730\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0747 - val_loss: 0.0717\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.0708\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0703\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0715 - val_loss: 0.0691\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0706 - val_loss: 0.0682\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0697 - val_loss: 0.0675\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0669\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0683 - val_loss: 0.0663\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0657\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0669 - val_loss: 0.0653\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0664 - val_loss: 0.0648\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0658 - val_loss: 0.0647\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0654 - val_loss: 0.0638\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0649 - val_loss: 0.0636\n",
      "19/19 [==============================] - 0s 835us/step - loss: 0.0740\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5111 - val_loss: 0.2623\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2228 - val_loss: 0.1827\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1673 - val_loss: 0.1487\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1411 - val_loss: 0.1295\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1254 - val_loss: 0.1167\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1144 - val_loss: 0.1074\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1063 - val_loss: 0.1002\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1001 - val_loss: 0.0947\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0951 - val_loss: 0.0902\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.0865\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0876 - val_loss: 0.0835\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0808\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0824 - val_loss: 0.0784\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0802 - val_loss: 0.0766\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0783 - val_loss: 0.0750\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0733\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.0718\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0707\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0696\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0685\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0676\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0698 - val_loss: 0.0667\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0663\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0683 - val_loss: 0.0653\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0647\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0670 - val_loss: 0.0641\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0664 - val_loss: 0.0636\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0629\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0653 - val_loss: 0.0625\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0649 - val_loss: 0.0620\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0612\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5648 - val_loss: 0.3394\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2437 - val_loss: 0.2082\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1745 - val_loss: 0.1680\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1470 - val_loss: 0.1475\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1316 - val_loss: 0.1358\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1216 - val_loss: 0.1261\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1140 - val_loss: 0.1193\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1080 - val_loss: 0.1136\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1031 - val_loss: 0.1085\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0990 - val_loss: 0.1051\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0956 - val_loss: 0.1023\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0924 - val_loss: 0.0987\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0898 - val_loss: 0.0956\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0873 - val_loss: 0.0929\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0852 - val_loss: 0.0907\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0832 - val_loss: 0.0885\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0868\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0849\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.0834\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0819\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0804\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0795\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0780\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0768\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0758\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0748\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0700 - val_loss: 0.0742\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0694 - val_loss: 0.0731\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0723\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0682 - val_loss: 0.0716\n",
      "19/19 [==============================] - 0s 907us/step - loss: 0.0696\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5106 - val_loss: 0.2961\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2692 - val_loss: 0.2090\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1933 - val_loss: 0.1693\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1571 - val_loss: 0.1471\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1364 - val_loss: 0.1330\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1230 - val_loss: 0.1233\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1133 - val_loss: 0.1154\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1061 - val_loss: 0.1094\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1004 - val_loss: 0.1042\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0959 - val_loss: 0.1002\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.0966\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0890 - val_loss: 0.0936\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0864 - val_loss: 0.0910\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0841 - val_loss: 0.0887\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0820 - val_loss: 0.0867\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0848\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0831\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0816\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0802\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0790\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0779\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0768\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0758\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0749\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0740\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0694 - val_loss: 0.0732\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.0725\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0719\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.0711\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0669 - val_loss: 0.0704\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0663\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5560 - val_loss: 0.3137\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2643 - val_loss: 0.2046\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1895 - val_loss: 0.1597\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1539 - val_loss: 0.1362\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1333 - val_loss: 0.1220\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1202 - val_loss: 0.1126\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1108 - val_loss: 0.1063\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1039 - val_loss: 0.1005\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0983 - val_loss: 0.0966\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0939 - val_loss: 0.0930\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.0901\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0872 - val_loss: 0.0875\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0846 - val_loss: 0.0852\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0822 - val_loss: 0.0833\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0801 - val_loss: 0.0817\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.0802\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0788\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.0774\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0741 - val_loss: 0.0764\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0753\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0742\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.0734\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0727\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0721\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0683 - val_loss: 0.0711\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0707\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0699\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0663 - val_loss: 0.0699\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0657 - val_loss: 0.0690\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0652 - val_loss: 0.0686\n",
      "19/19 [==============================] - 0s 855us/step - loss: 0.0744\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5892 - val_loss: 0.2955\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2693 - val_loss: 0.2196\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2103 - val_loss: 0.1855\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1796 - val_loss: 0.1650\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1599 - val_loss: 0.1494\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1455 - val_loss: 0.1382\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1343 - val_loss: 0.1291\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1258 - val_loss: 0.1218\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1187 - val_loss: 0.1164\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1129 - val_loss: 0.1113\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1079 - val_loss: 0.1067\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1037 - val_loss: 0.1034\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0999 - val_loss: 0.0999\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0967 - val_loss: 0.0974\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0939 - val_loss: 0.0947\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0914 - val_loss: 0.0926\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0891 - val_loss: 0.0905\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0870 - val_loss: 0.0885\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0852 - val_loss: 0.0870\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0835 - val_loss: 0.0855\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0820 - val_loss: 0.0843\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0829\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0816\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.0805\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0770 - val_loss: 0.0796\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0785\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0775\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0741 - val_loss: 0.0766\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0759\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0751\n",
      "19/19 [==============================] - 0s 803us/step - loss: 0.0748\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4529 - val_loss: 0.2540\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2199 - val_loss: 0.1900\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1675 - val_loss: 0.1598\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1428 - val_loss: 0.1423\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1273 - val_loss: 0.1297\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1168 - val_loss: 0.1210\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1088 - val_loss: 0.1148\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1030 - val_loss: 0.1086\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0981 - val_loss: 0.1042\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0941 - val_loss: 0.1008\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0908 - val_loss: 0.0977\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0879 - val_loss: 0.0952\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0854 - val_loss: 0.0927\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0834 - val_loss: 0.0908\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0815 - val_loss: 0.0888\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0871\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.0859\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0842\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0830\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0748 - val_loss: 0.0819\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0809\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0799\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.0792\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0783\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.0775\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0698 - val_loss: 0.0771\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0761\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.0755\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0679 - val_loss: 0.0750\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0674 - val_loss: 0.0746\n",
      "19/19 [==============================] - 0s 852us/step - loss: 0.0666\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6561 - val_loss: 0.3773\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2658 - val_loss: 0.2534\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1967 - val_loss: 0.2038\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1664 - val_loss: 0.1768\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1491 - val_loss: 0.1587\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1370 - val_loss: 0.1456\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1278 - val_loss: 0.1357\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1204 - val_loss: 0.1275\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1142 - val_loss: 0.1211\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1089 - val_loss: 0.1157\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1044 - val_loss: 0.1104\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1006 - val_loss: 0.1062\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0971 - val_loss: 0.1029\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0942 - val_loss: 0.0996\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0914 - val_loss: 0.0966\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0892 - val_loss: 0.0939\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0870 - val_loss: 0.0916\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0852 - val_loss: 0.0897\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0834 - val_loss: 0.0880\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0862\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0846\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.0833\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0777 - val_loss: 0.0821\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0806\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0796\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0785\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0775\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0769\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0758\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0749\n",
      "19/19 [==============================] - 0s 842us/step - loss: 0.0703\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7369 - val_loss: 0.4394\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3196 - val_loss: 0.2714\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2226 - val_loss: 0.2041\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1776 - val_loss: 0.1698\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1518 - val_loss: 0.1478\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1345 - val_loss: 0.1327\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1224 - val_loss: 0.1216\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1134 - val_loss: 0.1132\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1063 - val_loss: 0.1062\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1006 - val_loss: 0.1008\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0960 - val_loss: 0.0965\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0923 - val_loss: 0.0928\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0891 - val_loss: 0.0892\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0863 - val_loss: 0.0866\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0837 - val_loss: 0.0851\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0819 - val_loss: 0.0818\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0804\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0782 - val_loss: 0.0785\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0767\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0754 - val_loss: 0.0755\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0741 - val_loss: 0.0746\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0730 - val_loss: 0.0736\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0724\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.0715\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0704\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0698\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.0691\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0680 - val_loss: 0.0685\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0674 - val_loss: 0.0678\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0668 - val_loss: 0.0679\n",
      "19/19 [==============================] - 0s 870us/step - loss: 0.0723\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.8773 - val_loss: 0.3147\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2684 - val_loss: 0.1993\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1903 - val_loss: 0.1622\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1573 - val_loss: 0.1430\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1382 - val_loss: 0.1391\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1264 - val_loss: 0.1230\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.1161\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1100 - val_loss: 0.1111\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1048 - val_loss: 0.1064\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1001 - val_loss: 0.1021\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0963 - val_loss: 0.0989\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0928 - val_loss: 0.0958\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.0929\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0873 - val_loss: 0.0906\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0886\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0832 - val_loss: 0.0871\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0847\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0797 - val_loss: 0.0834\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0782 - val_loss: 0.0818\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.0802\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0754 - val_loss: 0.0797\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0779\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0769\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0757\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.0745\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0737\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0700 - val_loss: 0.0731\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.0731\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0712\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0705\n",
      "19/19 [==============================] - 0s 796us/step - loss: 0.0765\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.1992 - val_loss: 0.4269\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.2354\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2415 - val_loss: 0.1779\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1846 - val_loss: 0.1390\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1553 - val_loss: 0.1238\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1372 - val_loss: 0.1134\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1249 - val_loss: 0.1051\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1160 - val_loss: 0.0998\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1090 - val_loss: 0.0954\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1037 - val_loss: 0.0915\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0992 - val_loss: 0.0891\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0953 - val_loss: 0.0861\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.0835\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0893 - val_loss: 0.0816\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0868 - val_loss: 0.0797\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0847 - val_loss: 0.0784\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0827 - val_loss: 0.0772\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0811 - val_loss: 0.0754\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.0744\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0736\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0726\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0720\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0704\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0697\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0724 - val_loss: 0.0690\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.0685\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.0678\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0701 - val_loss: 0.0672\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.0669\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.0661\n",
      "19/19 [==============================] - 0s 881us/step - loss: 0.0737\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4110 - val_loss: 0.1810\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1701 - val_loss: 0.1444\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1407 - val_loss: 0.1270\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1255 - val_loss: 0.1183\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1155 - val_loss: 0.1107\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1081 - val_loss: 0.1048\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1026 - val_loss: 0.1007\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0980 - val_loss: 0.0962\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0946 - val_loss: 0.0938\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0915 - val_loss: 0.0905\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0889 - val_loss: 0.0881\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0867 - val_loss: 0.0855\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0846 - val_loss: 0.0837\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0819\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0813 - val_loss: 0.0804\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0797 - val_loss: 0.0790\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0776\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.0762\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.0758\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0743\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0732\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0727\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0724 - val_loss: 0.0714\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0706\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0708\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0694\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0687\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0678\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0671\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0679 - val_loss: 0.0665\n",
      "19/19 [==============================] - 0s 857us/step - loss: 0.0654\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.2903\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2370 - val_loss: 0.1913\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1714 - val_loss: 0.1551\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1442 - val_loss: 0.1362\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1286 - val_loss: 0.1259\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1185 - val_loss: 0.1139\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1105 - val_loss: 0.1068\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1046 - val_loss: 0.1021\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0998 - val_loss: 0.0980\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0957 - val_loss: 0.0939\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0923 - val_loss: 0.0906\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0892 - val_loss: 0.0883\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0865 - val_loss: 0.0859\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0843 - val_loss: 0.0832\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0813\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0805 - val_loss: 0.0795\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0781\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.0767\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0761\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0748 - val_loss: 0.0745\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0733\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.0723\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.0716\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0707\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0704\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0692\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0687\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0677 - val_loss: 0.0679\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0671 - val_loss: 0.0675\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0673\n",
      "19/19 [==============================] - 0s 820us/step - loss: 0.0657\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 0.2902\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2529 - val_loss: 0.2027\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1978 - val_loss: 0.1760\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1689 - val_loss: 0.1543\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1505 - val_loss: 0.1414\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1378 - val_loss: 0.1319\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1281 - val_loss: 0.1234\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1205 - val_loss: 0.1171\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1144 - val_loss: 0.1119\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1092 - val_loss: 0.1074\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1046 - val_loss: 0.1032\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1007 - val_loss: 0.0997\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0975 - val_loss: 0.0966\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0945 - val_loss: 0.0938\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.0913\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0894 - val_loss: 0.0892\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0875 - val_loss: 0.0871\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0855 - val_loss: 0.0851\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0837 - val_loss: 0.0837\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0821 - val_loss: 0.0823\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0807 - val_loss: 0.0807\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0792 - val_loss: 0.0796\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0784\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.0774\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0761\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0750\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0741 - val_loss: 0.0742\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0733\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0725\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "19/19 [==============================] - 0s 839us/step - loss: 0.0776\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5014 - val_loss: 0.3571\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3168 - val_loss: 0.2641\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2425 - val_loss: 0.2140\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2005 - val_loss: 0.1826\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1741 - val_loss: 0.1609\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1551 - val_loss: 0.1448\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1415 - val_loss: 0.1344\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1310 - val_loss: 0.1242\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1225 - val_loss: 0.1162\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1157 - val_loss: 0.1098\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1102 - val_loss: 0.1047\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1055 - val_loss: 0.1003\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1011 - val_loss: 0.0965\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0978 - val_loss: 0.0931\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0946 - val_loss: 0.0902\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.0877\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.0849\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0874 - val_loss: 0.0831\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0810\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0836 - val_loss: 0.0796\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0820 - val_loss: 0.0779\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0805 - val_loss: 0.0763\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0791 - val_loss: 0.0749\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0779 - val_loss: 0.0738\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0728\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0720\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0708\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0699\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0691\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0683\n",
      "19/19 [==============================] - 0s 917us/step - loss: 0.0787\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5403 - val_loss: 0.3155\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2725 - val_loss: 0.2245\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2090 - val_loss: 0.1818\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1732 - val_loss: 0.1554\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1500 - val_loss: 0.1375\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1333 - val_loss: 0.1245\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1214 - val_loss: 0.1149\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1120 - val_loss: 0.1071\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1049 - val_loss: 0.1009\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0990 - val_loss: 0.0963\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0942 - val_loss: 0.0918\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.0885\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0868 - val_loss: 0.0855\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0840 - val_loss: 0.0831\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0805\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0786\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0774 - val_loss: 0.0768\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0752\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0741\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0729\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0716\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0706 - val_loss: 0.0706\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0703\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0690\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0679 - val_loss: 0.0684\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0672 - val_loss: 0.0677\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0665 - val_loss: 0.0673\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0663\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0653 - val_loss: 0.0658\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0648 - val_loss: 0.0653\n",
      "19/19 [==============================] - 0s 801us/step - loss: 0.0808\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.1494\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1375 - val_loss: 0.1179\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.1009\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0979 - val_loss: 0.0907\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0889 - val_loss: 0.0840\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0828 - val_loss: 0.0796\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0768\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0738\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0719\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0704\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0692\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0680\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0671\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0666\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0657\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0653\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0648\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0642\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0638\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.0635\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0631\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0629\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0625\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0623\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0606 - val_loss: 0.0621\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0621\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0615\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0613\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0612\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0609\n",
      "19/19 [==============================] - 0s 911us/step - loss: 0.0622\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3032 - val_loss: 0.1963\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1558 - val_loss: 0.1471\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1245 - val_loss: 0.1237\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1069 - val_loss: 0.1090\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0958 - val_loss: 0.1006\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0892 - val_loss: 0.0939\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0845 - val_loss: 0.0894\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0857\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.0831\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0812\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0793\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.0776\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0760\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0755\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0743\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0728\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0720\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0711\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.0710\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0703\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0692\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.0697\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0634 - val_loss: 0.0684\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0675\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.0671\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0668\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0657\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.0660\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0653\n",
      "19/19 [==============================] - 0s 887us/step - loss: 0.0642\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2708 - val_loss: 0.1437\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1324 - val_loss: 0.1105\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1086 - val_loss: 0.0951\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.0866\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0889 - val_loss: 0.0814\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0837 - val_loss: 0.0771\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0742\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.0718\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0699\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0683\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0672\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0706 - val_loss: 0.0659\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0694 - val_loss: 0.0650\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0641\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.0632\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0668 - val_loss: 0.0626\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0620\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0614\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.0609\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0643 - val_loss: 0.0604\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0600\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0633 - val_loss: 0.0599\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0595\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0589\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0588\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0584\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0581\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0580\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.0577\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0575\n",
      "19/19 [==============================] - 0s 955us/step - loss: 0.0634\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3139 - val_loss: 0.1582\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1460 - val_loss: 0.1219\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1143 - val_loss: 0.1014\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0973 - val_loss: 0.0903\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0872 - val_loss: 0.0822\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0775\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.0741\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0738 - val_loss: 0.0720\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.0701\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0690\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0679\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0667\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0658\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0655\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0651 - val_loss: 0.0647\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0642\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.0636\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0632\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0629 - val_loss: 0.0629\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.0625\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0621\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0619\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0616\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0612\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0610\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.0609\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0606\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0604\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0604\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0600\n",
      "19/19 [==============================] - 0s 984us/step - loss: 0.0614\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2118 - val_loss: 0.1528\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1439 - val_loss: 0.1165\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1160 - val_loss: 0.0981\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0997 - val_loss: 0.0866\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0899 - val_loss: 0.0799\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0831 - val_loss: 0.0747\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.0712\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0691\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0666\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0650\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.0637\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0631\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0617\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0653 - val_loss: 0.0609\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0602\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.0596\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0593\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0587\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0582\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0582\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.0575\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0573\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0569\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0567\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.0573\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0564\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.0560\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0559\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0557\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.0559\n",
      "19/19 [==============================] - 0s 889us/step - loss: 0.0780\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1979 - val_loss: 0.1353\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1193 - val_loss: 0.1115\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1018 - val_loss: 0.1006\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0928 - val_loss: 0.0936\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0896\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.0854\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.0825\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 0.0802\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.0783\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0767\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0753\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0740\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0729\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0719\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0711\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0704\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0696\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0689\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0683\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0678\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0672\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0668\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0664\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0660\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.0657\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0652\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0649\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0646\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0649\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0641\n",
      "19/19 [==============================] - 0s 960us/step - loss: 0.0642\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2030 - val_loss: 0.1603\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1477 - val_loss: 0.1281\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1238 - val_loss: 0.1115\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1099 - val_loss: 0.1011\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0943\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.0893\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.0855\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.0825\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0819 - val_loss: 0.0800\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0781\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0772 - val_loss: 0.0763\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0748\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0735\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0728\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0715\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0698 - val_loss: 0.0705\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0689 - val_loss: 0.0698\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0691\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0683\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0665 - val_loss: 0.0683\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0673\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0669\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.0664\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0642 - val_loss: 0.0660\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0656\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0654\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0650\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0624 - val_loss: 0.0647\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0643\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0640\n",
      "19/19 [==============================] - 0s 956us/step - loss: 0.0689\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2168 - val_loss: 0.1577\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1500 - val_loss: 0.1292\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1257 - val_loss: 0.1118\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1100 - val_loss: 0.1004\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0996 - val_loss: 0.0926\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.0869\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0829\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0828 - val_loss: 0.0794\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0767\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0770 - val_loss: 0.0745\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0727\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0714\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0700\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0691\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.0679\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0671\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.0664\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0656\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0651\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0645\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0648 - val_loss: 0.0640\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0643 - val_loss: 0.0637\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0632\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0628\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0624\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0621\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0623 - val_loss: 0.0617\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0615\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0612\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0609\n",
      "19/19 [==============================] - 0s 940us/step - loss: 0.0587\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2408 - val_loss: 0.1599\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1432 - val_loss: 0.1229\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1149 - val_loss: 0.1071\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1008 - val_loss: 0.0956\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0923 - val_loss: 0.0892\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0867 - val_loss: 0.0839\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0827 - val_loss: 0.0806\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.0775\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.0763\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0737\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0716\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0707\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0693\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0681\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0675\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0666\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0669 - val_loss: 0.0660\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0662 - val_loss: 0.0654\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0655 - val_loss: 0.0647\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0644\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0643 - val_loss: 0.0636\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0632\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0628\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0625\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0622\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0623 - val_loss: 0.0622\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0617\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0616 - val_loss: 0.0612\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0612 - val_loss: 0.0611\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0607\n",
      "19/19 [==============================] - 0s 953us/step - loss: 0.0624\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.2946 - val_loss: 0.1413\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.1127\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1035 - val_loss: 0.0982\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0931 - val_loss: 0.0901\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0849\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0822 - val_loss: 0.0813\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0786\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0765\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0748\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.0733\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0723\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0712\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0704\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0695\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0687\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0680\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0674\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0669\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0664\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0647 - val_loss: 0.0658\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0642 - val_loss: 0.0654\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0651\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0647\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0643\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0640\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0637\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0634\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0631\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0628\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0626\n",
      "19/19 [==============================] - 0s 964us/step - loss: 0.0652\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.3178 - val_loss: 0.1638\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1453 - val_loss: 0.1193\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1172 - val_loss: 0.1021\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1024 - val_loss: 0.0920\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0936 - val_loss: 0.0850\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0874 - val_loss: 0.0806\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0832 - val_loss: 0.0772\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0746\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 0.0728\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0754 - val_loss: 0.0717\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0696\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0724 - val_loss: 0.0685\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0673\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0666\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0658\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0650\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0646\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0639\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0664 - val_loss: 0.0635\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0630\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0625\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0623\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0619\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0643 - val_loss: 0.0615\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0611\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0609\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0606\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0603\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0602\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0598\n",
      "19/19 [==============================] - 0s 936us/step - loss: 0.0671\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2663 - val_loss: 0.1584\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1423 - val_loss: 0.1255\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1169 - val_loss: 0.1080\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1017 - val_loss: 0.0975\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.0905\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0856 - val_loss: 0.0859\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.0821\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0794\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.0772\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0752\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0738\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0727\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0713\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0703\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0694\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0685\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0678\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0643 - val_loss: 0.0673\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0666\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0660\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0655\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0650\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0646\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0642\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0638\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0635\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.0631\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0630\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0624\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.0622\n",
      "19/19 [==============================] - 0s 957us/step - loss: 0.0669\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2014 - val_loss: 0.1478\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1373 - val_loss: 0.1191\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1146 - val_loss: 0.1051\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1022 - val_loss: 0.0958\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0943 - val_loss: 0.0916\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0890 - val_loss: 0.0865\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.0830\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.0807\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0784\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0764\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0743\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0732\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0728\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0712 - val_loss: 0.0706\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0701\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0691\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0682\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0677\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0670\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0668\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0660\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0655 - val_loss: 0.0657\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0651 - val_loss: 0.0656\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.0646\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0643 - val_loss: 0.0644\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.0639\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0636\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0632\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0628\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0629\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0657\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2455 - val_loss: 0.1420\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1430 - val_loss: 0.1173\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1189 - val_loss: 0.1012\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1040 - val_loss: 0.0914\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0937 - val_loss: 0.0847\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 0.0796\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0762\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0749\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0716\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0703\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0687\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0676\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0667\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0659\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0654\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0646\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.0640\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0632 - val_loss: 0.0635\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0630\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0622 - val_loss: 0.0627\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0623\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0620\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0616\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0613\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0610\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0608\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0605\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0603\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0600\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0599\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0651\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2602 - val_loss: 0.1395\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1110\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1117 - val_loss: 0.0969\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0990 - val_loss: 0.0886\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0909 - val_loss: 0.0827\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0785\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0754\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0730\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0757 - val_loss: 0.0712\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0696\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0683\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0673\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0663\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0654\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0650\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0640\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0634\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0630\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0628\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0621\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0617\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.0613\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0610\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0607\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0604\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0604\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0599\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0597\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0606 - val_loss: 0.0595\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0594\n",
      "19/19 [==============================] - 0s 936us/step - loss: 0.0656\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2368 - val_loss: 0.1542\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1627 - val_loss: 0.1227\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1318 - val_loss: 0.1056\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1132 - val_loss: 0.0940\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1011 - val_loss: 0.0865\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0927 - val_loss: 0.0808\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0767\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0823 - val_loss: 0.0736\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0711\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0693\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0679\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0664\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0654\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0645\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0638\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0631\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0626\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0621\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0616\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0612\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.0609\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0606\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0603\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0601\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0598\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0596\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0595\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0592\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0591\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0590\n",
      "19/19 [==============================] - 0s 960us/step - loss: 0.0631\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1993 - val_loss: 0.1719\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1514 - val_loss: 0.1430\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1277 - val_loss: 0.1254\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1125 - val_loss: 0.1130\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1019 - val_loss: 0.1042\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0943 - val_loss: 0.0975\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.0923\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0842 - val_loss: 0.0880\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0845\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0816\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0791\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0770\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0751\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0735\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0721\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0710\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0677 - val_loss: 0.0698\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0690\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0662 - val_loss: 0.0679\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0670\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0662\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0655\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0649\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0643\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.0638\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0634\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0630\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0625\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0620\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0616\n",
      "19/19 [==============================] - 0s 895us/step - loss: 0.0699\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2785 - val_loss: 0.1527\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1384 - val_loss: 0.1178\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1129 - val_loss: 0.0994\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0988 - val_loss: 0.0900\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0902 - val_loss: 0.0844\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.0804\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0776\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0753\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0735\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.0720\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0708\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0697 - val_loss: 0.0697\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0688\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0680\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0672\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0665\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0659\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0653\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0648\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0644\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0642\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0636\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0622 - val_loss: 0.0632\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0629\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0626\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.0624\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0620\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0617\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.0615\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0613\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0613\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2314 - val_loss: 0.1467\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1279 - val_loss: 0.1118\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1050 - val_loss: 0.0974\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0940 - val_loss: 0.0894\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0873 - val_loss: 0.0844\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0809\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.0783\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0765 - val_loss: 0.0763\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0746\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0733\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0722\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0714\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0704\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0698\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0690\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0684\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0679\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0644 - val_loss: 0.0673\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0668\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0664\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0659\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0657\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0652\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0649\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.0646\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0643\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0640\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0640\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.0637\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0635\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0621\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1869 - val_loss: 0.1353\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1316 - val_loss: 0.1135\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1129 - val_loss: 0.1031\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1019 - val_loss: 0.0961\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0949 - val_loss: 0.0916\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.0868\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0858 - val_loss: 0.0838\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0851\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0800 - val_loss: 0.0799\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.0784\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0773\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0744 - val_loss: 0.0752\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.0743\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0732\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0728\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0714\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0707\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0706\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0689\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0686\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.0679\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.0674\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0669\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0667\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0663\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.0659\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0655\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0657\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0650\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0647\n",
      "19/19 [==============================] - 0s 973us/step - loss: 0.0649\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2148 - val_loss: 0.1429\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1339 - val_loss: 0.1183\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.1052\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1035 - val_loss: 0.0971\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 0.0926\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0907 - val_loss: 0.0882\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0866 - val_loss: 0.0855\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0831 - val_loss: 0.0821\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0800\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.0784\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0762\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0755\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.0740\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0726\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0719\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0712\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0699\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0692\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0687\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0688\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0655 - val_loss: 0.0681\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0667\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0664\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.0659\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0634 - val_loss: 0.0657\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0651\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0647\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0644\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0648\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0637\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0625\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2164 - val_loss: 0.1425\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1273 - val_loss: 0.1135\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1060 - val_loss: 0.0999\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0949 - val_loss: 0.0921\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0881 - val_loss: 0.0871\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 0.0836\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0818\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0775 - val_loss: 0.0794\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.0774\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0760\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0748\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0737\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0729\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0722\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0717\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0670 - val_loss: 0.0708\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0706\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.0700\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0691\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0686\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0682\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0678\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0674\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0625 - val_loss: 0.0671\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0668\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0616 - val_loss: 0.0665\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.0662\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.0659\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0658\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0655\n",
      "19/19 [==============================] - 0s 981us/step - loss: 0.0606\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2920 - val_loss: 0.1659\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1477 - val_loss: 0.1257\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1206 - val_loss: 0.1076\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1053 - val_loss: 0.0974\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0960 - val_loss: 0.0910\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.0878\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0849 - val_loss: 0.0827\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0792\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0770\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0750\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.0732\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0724\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0705\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0698 - val_loss: 0.0696\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0690\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0682\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0672\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0666\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0660\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.0654\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0651\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0645\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0641\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0637\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0634\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0631\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0628\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0626\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.0623\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0620\n",
      "19/19 [==============================] - 0s 948us/step - loss: 0.0676\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2287 - val_loss: 0.1457\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1453 - val_loss: 0.1159\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1161 - val_loss: 0.1009\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1010 - val_loss: 0.0902\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.0846\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.0796\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.0765\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0789 - val_loss: 0.0740\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0721\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0705\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0693\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0682\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0673\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0698 - val_loss: 0.0664\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0689 - val_loss: 0.0657\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0651\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0644\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0645\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0661 - val_loss: 0.0634\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0655 - val_loss: 0.0630\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0627\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0645 - val_loss: 0.0622\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0640 - val_loss: 0.0619\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0615\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0612\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0629 - val_loss: 0.0609\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0607\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0604\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0619 - val_loss: 0.0601\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0616 - val_loss: 0.0599\n",
      "19/19 [==============================] - 0s 924us/step - loss: 0.0637\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1735 - val_loss: 0.1346\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1232 - val_loss: 0.1078\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1046 - val_loss: 0.1052\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0954 - val_loss: 0.0928\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.0886\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0849 - val_loss: 0.0856\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0817 - val_loss: 0.0827\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0805\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0787\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0772\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0759\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0745\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0735\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0725\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0717\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0709\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0702\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0696\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0689\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.0685\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0680\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0673\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0667\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.0663\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0659\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0656\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0652\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0648\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0645\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.0641\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0595\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2114 - val_loss: 0.1425\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1323 - val_loss: 0.1113\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1115 - val_loss: 0.0967\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1011 - val_loss: 0.0891\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0944 - val_loss: 0.0840\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0895 - val_loss: 0.0800\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.0768\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0743\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0723\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0782 - val_loss: 0.0706\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0690\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.0678\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.0667\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0658\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0712 - val_loss: 0.0649\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0641\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0635\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0630\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0625\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0672 - val_loss: 0.0620\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0615\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.0611\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0655 - val_loss: 0.0607\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0649 - val_loss: 0.0603\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0644 - val_loss: 0.0609\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0597\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0595\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0633 - val_loss: 0.0592\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0590\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0587\n",
      "19/19 [==============================] - 0s 930us/step - loss: 0.0692\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2438 - val_loss: 0.1739\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1476 - val_loss: 0.1392\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1216 - val_loss: 0.1202\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1071 - val_loss: 0.1086\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0977 - val_loss: 0.1001\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0909 - val_loss: 0.0940\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.0892\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0817 - val_loss: 0.0854\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 0.0825\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0798\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0778\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0760\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0746\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0733\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0720\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0714\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0702\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.0692\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0644 - val_loss: 0.0684\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0680\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0672\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0666\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0658\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0653\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0650\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0647\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.0641\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0641\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0636\n",
      "19/19 [==============================] - 0s 928us/step - loss: 0.0645\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1755 - val_loss: 0.1380\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1314 - val_loss: 0.1138\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1105 - val_loss: 0.0996\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0973 - val_loss: 0.0901\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0890 - val_loss: 0.0840\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.0798\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0766\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.0743\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0726\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0710\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0698\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0686\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0677\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.0669\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0662\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0657\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0652\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0655 - val_loss: 0.0645\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0641\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0637\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0633\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0630\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0626\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0624\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0619\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0616\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0613\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0611\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0608\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 895us/step - loss: 0.0629\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2174 - val_loss: 0.1651\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1417 - val_loss: 0.1302\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.1121\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1030 - val_loss: 0.1006\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0943 - val_loss: 0.0933\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0885 - val_loss: 0.0882\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0844 - val_loss: 0.0844\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0809\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.0785\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0766\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0746\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.0731\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0707\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0696\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.0687\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0679\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0671\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0664\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0657\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0654\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0654 - val_loss: 0.0646\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0641\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0637\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0632\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0636 - val_loss: 0.0628\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0624\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0620\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0625 - val_loss: 0.0617\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.0613\n",
      "19/19 [==============================] - 0s 892us/step - loss: 0.0675\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2372 - val_loss: 0.1534\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1353 - val_loss: 0.1200\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1123 - val_loss: 0.1046\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1002 - val_loss: 0.0959\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0927 - val_loss: 0.0902\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0873 - val_loss: 0.0861\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.0830\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.0803\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 0.0782\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0770\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.0748\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0734\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0723\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0713\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0684 - val_loss: 0.0704\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0694\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0686\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.0680\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0653 - val_loss: 0.0673\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0667\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0661\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0656\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0654\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0647\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0645\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0640\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0637\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.0633\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0606 - val_loss: 0.0630\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0627\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0722\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1575 - val_loss: 0.0850\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0704\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0658\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0662\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0619\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0646\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0618\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0596\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0585\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0567\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0569\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0567\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0558\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0564\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0555\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0551\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0563\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0549\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0552\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0546\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0542\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0542\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0541\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0553\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0542\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0553\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0543\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0538\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0537\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0538\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0617\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1512 - val_loss: 0.0878\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0793\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0833 - val_loss: 0.0886\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0860 - val_loss: 0.0845\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0884 - val_loss: 0.0664\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0590\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0568 - val_loss: 0.0568\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0563\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0573\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0558\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0559\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0546\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0547\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0558\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0542\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0542\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0545\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0539\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0539\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0538\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0535\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0551\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0539\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0536\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0531\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0544\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0570\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0528\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0530\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0528\n",
      "19/19 [==============================] - 0s 843us/step - loss: 0.0518\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1615 - val_loss: 0.0782\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0752 - val_loss: 0.0737\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0649\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0672\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0690\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0580\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0571 - val_loss: 0.0558\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0589\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0566\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0548\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0547\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0529 - val_loss: 0.0553\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0535\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0552\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.0531\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0535\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0530\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0530\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0527\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0524\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0528\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0526\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0524\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0533\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0522\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0522\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0520\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0519\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0519\n",
      "19/19 [==============================] - 0s 811us/step - loss: 0.0550\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2714 - val_loss: 0.0855\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0789\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.0646\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0619\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0599\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0587\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0580\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0576\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.0569\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0563\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0558\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0564\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0556\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0552\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0558\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0563\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0545\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0547\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0541\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0539\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0512 - val_loss: 0.0539\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0537\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0535\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0535\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0537\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0533\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0531\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0536\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0534\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0529\n",
      "19/19 [==============================] - 0s 913us/step - loss: 0.0540\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1398 - val_loss: 0.0844\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0752 - val_loss: 0.0670\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0697 - val_loss: 0.0610\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0585\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0576\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0548\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0561 - val_loss: 0.0560\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0528\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0541\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.0521\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0522\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0526\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0520\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0507\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0506\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0511\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0503\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0509\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0509 - val_loss: 0.0501\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0509\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0530\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0499\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0515\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0499 - val_loss: 0.0498\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0578\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0494\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0500\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0502\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0521\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0489 - val_loss: 0.0492\n",
      "19/19 [==============================] - 0s 840us/step - loss: 0.0615\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1842 - val_loss: 0.0837\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0724\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0626\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0623 - val_loss: 0.0620\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0606 - val_loss: 0.0594\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0570\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0565\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0561\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0554\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0550\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0550\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0549\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0545\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0543\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0541\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0540\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0540\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0540\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0539\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0535\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0537\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0537\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0534\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0533\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0535\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0534\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0535\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0535\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0540\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0533\n",
      "19/19 [==============================] - 0s 888us/step - loss: 0.0558\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1356 - val_loss: 0.0746\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0665\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0858 - val_loss: 0.0635\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0837 - val_loss: 0.0608\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0720\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0563\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0557\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.0554\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0564\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0549\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0550\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0545\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0542\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0538\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0541\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0536\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0541\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0541\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0510 - val_loss: 0.0533\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0510 - val_loss: 0.0534\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0532\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0533\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0536\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0534\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0535\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0534\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0570\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0528\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0490 - val_loss: 0.0529\n",
      "19/19 [==============================] - 0s 800us/step - loss: 0.0531\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1972 - val_loss: 0.0886\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0697\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0633\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0608\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0599\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.0585\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0578\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0569\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0562\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0555\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0553\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0550\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0562\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0549\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0547\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0545\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0542\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0509 - val_loss: 0.0537\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0536\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0535\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0548\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0566\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0535\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0546\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0534\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0540\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0534\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0490 - val_loss: 0.0536\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0489 - val_loss: 0.0536\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0487 - val_loss: 0.0531\n",
      "19/19 [==============================] - 0s 864us/step - loss: 0.0540\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1617 - val_loss: 0.0774\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0762 - val_loss: 0.0703\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.0633\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0643 - val_loss: 0.0616\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0641\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.0630\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0563\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0558\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0560 - val_loss: 0.0550\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0544\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0552\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0545\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0540\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0530\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0540\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0544\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0531\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0583\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0509 - val_loss: 0.0532\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0523\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0522\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0523\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0521\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0527\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0490 - val_loss: 0.0523\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0489 - val_loss: 0.0532\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0485 - val_loss: 0.0521\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0521\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0480 - val_loss: 0.0518\n",
      "19/19 [==============================] - 0s 884us/step - loss: 0.0585\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1395 - val_loss: 0.0953\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0909 - val_loss: 0.0689\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.0639\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0596\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.0606\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.0556\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0551\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0537\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0537\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.0537\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0531\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0538\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0532\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0534\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0541\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0521\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0521\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0532\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0518\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0515\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0516\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0531\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0516\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0510 - val_loss: 0.0512\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0516\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0507\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0510\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0508\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0515\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0499 - val_loss: 0.0508\n",
      "19/19 [==============================] - 0s 871us/step - loss: 0.0575\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2331 - val_loss: 0.1257\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1369 - val_loss: 0.1263\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1188 - val_loss: 0.0775\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0584\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0555\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.0549\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0560 - val_loss: 0.0545\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0546\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0541\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0540\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.053 - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0534\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0533\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0532\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0531\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0531\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0529\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0526\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0526\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0526\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0524\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0523\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0524\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0525\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0510 - val_loss: 0.0530\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0522\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0525\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0523\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0526\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0522\n",
      "19/19 [==============================] - 0s 851us/step - loss: 0.0562\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.0880\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0787\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0778 - val_loss: 0.0687\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0639\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0602\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.0593\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0593\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0587\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0572\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0599\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0566\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0568\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0566\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0562\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0576\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0553\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0551\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0569\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0561\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0545\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0560\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0499 - val_loss: 0.0563\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0557\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0541\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0537\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0490 - val_loss: 0.0538\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0558\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0490 - val_loss: 0.0557\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0489 - val_loss: 0.0537\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0539\n",
      "19/19 [==============================] - 0s 826us/step - loss: 0.0557\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1755 - val_loss: 0.0712\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0937 - val_loss: 0.0637\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.0603\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0571\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0569\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0558\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.0552\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0546\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0541\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0540\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0540\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0537\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0542\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0545\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0533\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0532\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0529\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0539\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0510 - val_loss: 0.0529\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0534\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0528\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0529\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0532\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0528\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0489 - val_loss: 0.0524\n",
      "19/19 [==============================] - 0s 862us/step - loss: 0.0550\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2258 - val_loss: 0.0734\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0703\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0591\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.0576\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0563\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0558\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0560\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0564\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0541\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0540\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0534\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0533\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0528\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0529\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0526\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0529\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0526\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0521\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0521\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0518\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0518\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0520\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0520\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0518\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0499 - val_loss: 0.0517\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0521\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0517\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0520\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0515\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0489 - val_loss: 0.0517\n",
      "19/19 [==============================] - 0s 874us/step - loss: 0.0585\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1806 - val_loss: 0.1901\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2085 - val_loss: 0.0822\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1144 - val_loss: 0.0613\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.0571\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0558\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.0550\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0547\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0538\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0542\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0542\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0537\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0525\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0528\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0523\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0526\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0519\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0509 - val_loss: 0.0518\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0520\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0523\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0520\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0516\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0499 - val_loss: 0.0514\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0516\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0510\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0513\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0516\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0509\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0488 - val_loss: 0.0520\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0488 - val_loss: 0.0510\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0486 - val_loss: 0.0512\n",
      "19/19 [==============================] - 0s 928us/step - loss: 0.0606\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1730 - val_loss: 0.1229\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1551 - val_loss: 0.0776\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0859 - val_loss: 0.0645\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0637 - val_loss: 0.0598\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0596\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0585\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0566\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0562 - val_loss: 0.0564\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.0554\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0554\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0551\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0550\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0553\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0543\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0544\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0540\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0545\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.0539\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0532\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0512 - val_loss: 0.0531\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0533\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0509 - val_loss: 0.0537\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0531\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0529\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0530\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0526\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0499 - val_loss: 0.0546\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0528\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0527\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0526\n",
      "19/19 [==============================] - 0s 955us/step - loss: 0.0550\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1913 - val_loss: 0.0825\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0698\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.0647\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0625 - val_loss: 0.0611\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0595\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0582\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0575\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0569\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0557\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0559\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0551\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0547\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0544\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0540\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0539\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0538\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0542\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0535\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0532\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0546\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0530\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0529\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0530\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0527\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0529\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0531\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0533\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0526\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0526\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0523\n",
      "19/19 [==============================] - 0s 916us/step - loss: 0.0551\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1376 - val_loss: 0.0961\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0676\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0673 - val_loss: 0.1187\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0625 - val_loss: 0.0637\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0592 - val_loss: 0.0635\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0584\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0564 - val_loss: 0.0581\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0577\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0566\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0561\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0557\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0558\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0556\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0562\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0549\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0548\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0552\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0550\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0542\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0510 - val_loss: 0.0554\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0541\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0552\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0544\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0544\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0541\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0554\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0535\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0543\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0549\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0488 - val_loss: 0.0540\n",
      "19/19 [==============================] - 0s 867us/step - loss: 0.0551\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1537 - val_loss: 0.0813\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.0754\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.0670\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0639 - val_loss: 0.0673\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0659\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.0637\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0626\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0612\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.0601\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0614\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0614\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0603\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0597\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0598\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0590\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0599\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0586\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0587\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0584\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0583\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0582\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0581\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0512 - val_loss: 0.0579\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0512 - val_loss: 0.0581\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0510 - val_loss: 0.0576\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0509 - val_loss: 0.0581\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0574\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0581\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0578\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0587\n",
      "19/19 [==============================] - 0s 845us/step - loss: 0.0543\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1858 - val_loss: 0.0737\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0731 - val_loss: 0.0675\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0658 - val_loss: 0.0609\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0632 - val_loss: 0.0606\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0585\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0572\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.0559\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0564\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0552\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0550\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0544\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0549\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0549\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0542\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0539\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0543\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0509 - val_loss: 0.0536\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0541\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0539\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0534\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0535\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0543\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0534\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0536\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0534\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0488 - val_loss: 0.0530\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0489 - val_loss: 0.0533\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0485 - val_loss: 0.0539\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0484 - val_loss: 0.0535\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0483 - val_loss: 0.0527\n",
      "19/19 [==============================] - 0s 934us/step - loss: 0.0531\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1802 - val_loss: 0.0883\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0748 - val_loss: 0.0796\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0760\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0670 - val_loss: 0.0723\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0657 - val_loss: 0.0653\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0651 - val_loss: 0.0625\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0605\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0588\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0584\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0584\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0583\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0571\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0565\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0558\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0568\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0562\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0550\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0552\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0550\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0550\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0558\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0545\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0553\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0556\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0542\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0543\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0541\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0539\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0488 - val_loss: 0.0557\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0487 - val_loss: 0.0537\n",
      "19/19 [==============================] - 0s 848us/step - loss: 0.0537\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1862 - val_loss: 0.0825\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0691\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0682 - val_loss: 0.0655\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0630\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0620\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0619\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0601\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0594\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0591\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0633\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0587\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0576\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0578\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0580\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0574\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0566\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0579\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0510 - val_loss: 0.0569\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0563\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0570\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0559\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0572\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0556\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0556\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0557\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0555\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0556\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0552\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0558\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0565\n",
      "19/19 [==============================] - 0s 847us/step - loss: 0.0567\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1895 - val_loss: 0.1159\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1416 - val_loss: 0.0823\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0908 - val_loss: 0.0655\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.0604\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0587\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0562 - val_loss: 0.0580\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0566\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0561\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0557\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0569\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0551\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0560\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0546\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0546\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0544\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0542\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0538\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0510 - val_loss: 0.0538\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0535\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0535\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0534\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0542\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0534\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0536\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0533\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0533\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0531\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0531\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0529\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0530\n",
      "19/19 [==============================] - 0s 931us/step - loss: 0.0555\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1368 - val_loss: 0.0786\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0717\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0711\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0661 - val_loss: 0.0643\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0637 - val_loss: 0.0702\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0619\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0629 - val_loss: 0.1514\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0567\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0558\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0540\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0532\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0540\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0529\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0525\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0529\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0539\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0520\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0521\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0544\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0518\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0519\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0523\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0512\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0516\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0513\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0499 - val_loss: 0.0513\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0513\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0530\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0509\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0513\n",
      "19/19 [==============================] - 0s 903us/step - loss: 0.0542\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1506 - val_loss: 0.0923\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.0717\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0682 - val_loss: 0.5939\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0960 - val_loss: 0.0815\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0675\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0631 - val_loss: 0.0640\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.0593\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0584\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0574\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0575\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0564\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0561\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0560\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0560\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0557\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0557\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0554\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0575\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0562\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.052 - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0561\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0557\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0550\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0548\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0550\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0557\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0556\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0510 - val_loss: 0.0548\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0546\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0551\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0552\n",
      "19/19 [==============================] - 0s 860us/step - loss: 0.0522\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1750 - val_loss: 0.1927\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0951\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0991 - val_loss: 0.0695\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0590\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0625 - val_loss: 0.0543\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0527\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0562 - val_loss: 0.0524\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0514\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0544\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0505\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0507\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0500\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0508\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0497\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0498\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0494\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0494\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0498\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.052 - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0503\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0495\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0512 - val_loss: 0.0491\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0510 - val_loss: 0.0494\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0487\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0487\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0484\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0485\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0487\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0487\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0499 - val_loss: 0.0488\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0488\n",
      "19/19 [==============================] - 0s 842us/step - loss: 0.0543\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1907 - val_loss: 0.0929\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0820 - val_loss: 0.0709\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0668 - val_loss: 0.0609\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0602 - val_loss: 0.0591\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0582\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.0573\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0565\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0561\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0551\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0549\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0547\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0544\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0544\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0545\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0547\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0537\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0536\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0536\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0499 - val_loss: 0.0535\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0538\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0534\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0534\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0490 - val_loss: 0.0533\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0489 - val_loss: 0.0530\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0532\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.048 - 0s 1ms/step - loss: 0.0485 - val_loss: 0.0531\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0484 - val_loss: 0.0536\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0483 - val_loss: 0.0529\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0481 - val_loss: 0.0529\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0540\n",
      "19/19 [==============================] - 0s 897us/step - loss: 0.0566\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.1041\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0872 - val_loss: 0.0706\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.2261\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0664 - val_loss: 0.0610\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0606\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0610\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0587\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.0560\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0625\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.0552\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0549\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0546\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0560\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0543\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0572\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0538\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0540\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0537\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0533\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0597\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0555\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0512 - val_loss: 0.0547\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0512 - val_loss: 0.0530\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0546\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0542\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0527\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0528\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0525\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0550\n",
      "19/19 [==============================] - 0s 912us/step - loss: 0.0589\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1392 - val_loss: 0.0886\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0739\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0717\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0733\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0644\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0573\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0556\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0557 - val_loss: 0.0539\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0542\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0535\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0527\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0526\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0526\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0525\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0519\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0515\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0511\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0534\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0513\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0509\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0511\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0514\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0503\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0505\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0509\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0503\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0508\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0499 - val_loss: 0.0503\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0501\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0505\n",
      "19/19 [==============================] - 0s 889us/step - loss: 0.0573\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1831 - val_loss: 0.0827\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0697\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0636 - val_loss: 0.0648\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0661\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0611\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0568 - val_loss: 0.0604\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0595\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0588\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.0592\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0588\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0576\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0576\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0569\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.0567\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0573\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0568\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0565\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0560\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0560\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0569\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0559\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0555\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0566\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0576\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0488 - val_loss: 0.0560\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0490 - val_loss: 0.0552\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0489 - val_loss: 0.0579\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0487 - val_loss: 0.0554\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0552\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0484 - val_loss: 0.0549\n",
      "19/19 [==============================] - 0s 826us/step - loss: 0.0604\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3503 - val_loss: 0.0884\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0883 - val_loss: 0.0748\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0682 - val_loss: 0.0639\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0632 - val_loss: 0.0619\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0593\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0584\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0568\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0566\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0561 - val_loss: 0.0555\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0560 - val_loss: 0.0549\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0549\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0540\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0538\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0546\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0535\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0533\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0535\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0535\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0537\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0526\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0528\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0525\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0522\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0532\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0541\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0533\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0521\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0525\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0523\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0518\n",
      "19/19 [==============================] - 0s 744us/step - loss: 0.0579\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2433 - val_loss: 0.1981\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1404 - val_loss: 0.0918\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0845 - val_loss: 0.0736\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0664 - val_loss: 0.0661\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0633\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0600\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0596\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0577\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0601\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0568 - val_loss: 0.0576\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.0570\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0556\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.0556\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0568\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0551\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0550\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0550\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0543\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0549\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0543\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0540\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0545\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0537\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0549\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0534\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0549\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0573\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0533\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0532\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0533\n",
      "19/19 [==============================] - 0s 851us/step - loss: 0.0526\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2392 - val_loss: 0.1079\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.0806\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0720\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0700\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0736\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0826 - val_loss: 0.0656\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0764 - val_loss: 0.0739\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.0652\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0709\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0574\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0568\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0567\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0554\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0572\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0550\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0552\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0546\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0550\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0546\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0541\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0539\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0541\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0539\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0549\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0534\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0535\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0545\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0532\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0531\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0532\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0546\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2407 - val_loss: 0.1036\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1000 - val_loss: 0.0904\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1049 - val_loss: 0.1012\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0982 - val_loss: 0.0791\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.0774\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0741 - val_loss: 0.0647\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0637 - val_loss: 0.0652\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.0622\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0619\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0608\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0599\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0606\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0568 - val_loss: 0.0592\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0562 - val_loss: 0.0589\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0595\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.0591\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0580\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0580\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0571\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0574\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0567\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0567\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0564\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0560\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0574\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0558\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0559\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0563\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0565\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0556\n",
      "19/19 [==============================] - 0s 818us/step - loss: 0.0560\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3939 - val_loss: 0.0889\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0904 - val_loss: 0.0869\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1092 - val_loss: 0.0751\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1310 - val_loss: 0.0745\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0937 - val_loss: 0.0646\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0626 - val_loss: 0.0549\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.0547\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0526\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0520\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.0515\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0562 - val_loss: 0.0512\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0527\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0508\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0501\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0503\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0502\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0499\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0496\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0494\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0495\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0500\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0491\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0501\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0490\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0529\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0488\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0490\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0497\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0496\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 866us/step - loss: 0.0575\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2269 - val_loss: 0.1391\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0967 - val_loss: 0.0950\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0761\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.0798\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.0675\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0661 - val_loss: 0.0641\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.0629\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0602 - val_loss: 0.0619\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0592\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0590\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.0585\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0569\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.0572\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0583\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0564\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0555\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0553\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0550\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0572\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0547\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0547\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0545\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0541\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0539\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0540\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0543\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0541\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0540\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0544\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0534\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0541\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2628 - val_loss: 0.0994\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0899 - val_loss: 0.0777\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0700\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0641\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0632 - val_loss: 0.0625\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0595\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0583\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0574\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.0566\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.0568\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0553\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0566\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0545\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0544\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0544\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0534\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0536\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0535\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0528\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0532\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0528\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0529\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0529\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0530\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0527\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0524\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0548\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0526\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0523\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0520\n",
      "19/19 [==============================] - 0s 793us/step - loss: 0.0532\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2990 - val_loss: 0.2498\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1635 - val_loss: 0.1320\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1443 - val_loss: 0.1489\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0927 - val_loss: 0.0921\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0641\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.0603\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0593\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0581\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.0575\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.0567\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0562 - val_loss: 0.0565\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.0559\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0565\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0556\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0554\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0545\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0545\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0539\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0535\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0534\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0542\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0562\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0533\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0545\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0534\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0533\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0532\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0535\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0523\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0522\n",
      "19/19 [==============================] - 0s 855us/step - loss: 0.0534\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2050 - val_loss: 0.1013\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0937 - val_loss: 0.0829\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0786 - val_loss: 0.0729\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.0660\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0663 - val_loss: 0.0638\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0637 - val_loss: 0.0610\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.0605\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0582\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0574\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0560\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.0552\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0564 - val_loss: 0.0552\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0545\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0557 - val_loss: 0.0538\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.0557\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0540\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0536\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0542\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0532\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0522\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0522\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0521\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0528\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0523\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0521\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0522\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0517\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0519\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0514\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0514\n",
      "19/19 [==============================] - 0s 837us/step - loss: 0.0531\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2126 - val_loss: 0.2319\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2080 - val_loss: 0.1697\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1777 - val_loss: 0.0936\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0895 - val_loss: 0.0654\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0633\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.0602\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0579\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.0567\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0557 - val_loss: 0.0561\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0567\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0560\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0551\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0544\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0550\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0551\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0536\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0551\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0551\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0528\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0527\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0522\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0537\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0528\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0523\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0536\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0522\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0522\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0520\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0527\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0521\n",
      "19/19 [==============================] - 0s 780us/step - loss: 0.0553\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2654 - val_loss: 0.1618\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2002 - val_loss: 0.1040\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1005 - val_loss: 0.0588\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0645 - val_loss: 0.0560\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.0538\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0532\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0537\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0531\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0512\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.0513\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.0507\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0508\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0507\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.0504\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0507\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0519\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0499\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0494\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0500\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0494\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0501\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0490\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0496\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0505\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0487\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0498\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0489\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0492\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0493\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0487\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0516\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2614 - val_loss: 0.1390\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1048 - val_loss: 0.0899\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0861 - val_loss: 0.0812\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0724 - val_loss: 0.0685\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0683\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0639 - val_loss: 0.0627\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0617 - val_loss: 0.0618\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0610\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0595\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0605\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.0569\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.0585\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0561 - val_loss: 0.0581\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.0562\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0563\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0556\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0550\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0557\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0549\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0544\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0552\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0557\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0551\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0538\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0542\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0538\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0555\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0553\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0533\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0536\n",
      "19/19 [==============================] - 0s 801us/step - loss: 0.0542\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6984 - val_loss: 0.0818\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0680\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0623\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0634 - val_loss: 0.0591\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0610 - val_loss: 0.0569\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0556\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0548\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.0535\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0564 - val_loss: 0.0533\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0560 - val_loss: 0.0528\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0526\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0527\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0524\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0523\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0521\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0517\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0522\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0519\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0520\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0514\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0517\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0515\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0512\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0511\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0514\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0512\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0512\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0511\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0510\n",
      "19/19 [==============================] - 0s 823us/step - loss: 0.0538\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2607 - val_loss: 0.1119\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0994 - val_loss: 0.0901\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.0748\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0696\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0679 - val_loss: 0.0657\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.0621\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0631\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0672\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0572\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0571\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0558\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0562 - val_loss: 0.0556\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0545\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0541\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0545\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0538\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0536\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0528\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0525\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0529\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0522\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0522\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0528\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0521\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0517\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0520\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0515\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0525\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0515\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0516\n",
      "19/19 [==============================] - 0s 901us/step - loss: 0.0597\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2317 - val_loss: 0.1105\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1066 - val_loss: 0.0858\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.0739\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0815 - val_loss: 0.0724\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0667\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0645 - val_loss: 0.0859\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0626 - val_loss: 0.0621\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0600\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0578\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0599\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.0576\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.0564\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0561 - val_loss: 0.0580\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.0551\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0549\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0549\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0540\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0547\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0567\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0537\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0534\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0536\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0537\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0532\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0538\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0533\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0527\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0577\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0532\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0525\n",
      "19/19 [==============================] - 0s 850us/step - loss: 0.0599\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2287 - val_loss: 0.1157\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1238 - val_loss: 0.0831\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.0759\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0748 - val_loss: 0.0655\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0672 - val_loss: 0.0642\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0633 - val_loss: 0.0602\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0617 - val_loss: 0.0590\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.0579\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0579\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0568\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0554\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.0615\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0568 - val_loss: 0.0595\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.0550\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0540\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.0555\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0548\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0538\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0532\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0539\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0530\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0540\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0528\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0524\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0529\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0523\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0556\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0526\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0522\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0523\n",
      "19/19 [==============================] - 0s 798us/step - loss: 0.0562\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3248 - val_loss: 0.0937\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0865 - val_loss: 0.0757\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0730 - val_loss: 0.0659\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0673 - val_loss: 0.0613\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.0596\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.0569\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0561\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0548\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0535\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0538\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.0533\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.0524\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0524\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0557 - val_loss: 0.0516\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.0521\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0517\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0516\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0512\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0512\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.0526\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0515\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0505\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0507\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0505\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0507\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0506\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0517\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0505\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0502\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0501\n",
      "19/19 [==============================] - 0s 841us/step - loss: 0.0600\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2972 - val_loss: 0.2944\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1860 - val_loss: 0.0891\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0824 - val_loss: 0.6541\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0637\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0605\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0589\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0577\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.0568\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0561 - val_loss: 0.0564\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0554\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.0549\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0545\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0545\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0547\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0539\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0542\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0534\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0537\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0535\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0535\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0529\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0540\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0533\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0537\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0526\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0542\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0532\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0528\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0531\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0529\n",
      "19/19 [==============================] - 0s 808us/step - loss: 0.0542\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3531 - val_loss: 0.1200\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0964 - val_loss: 0.1076\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1162 - val_loss: 0.0802\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0656\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.0633\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0616\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0605\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.0597\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0560 - val_loss: 0.0583\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.0599\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0595\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0586\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0567\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0569\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0567\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0579\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0561\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0559\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0565\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0557\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0558\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0560\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0557\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0556\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0557\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0568\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0550\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0563\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0553\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0554\n",
      "19/19 [==============================] - 0s 808us/step - loss: 0.0540\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.1026\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1237 - val_loss: 0.0866\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.0658\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0639 - val_loss: 0.0632\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0616 - val_loss: 0.0613\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0602 - val_loss: 0.0598\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0590\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0589\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0575\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0568 - val_loss: 0.0566\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0561 - val_loss: 0.0567\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0559\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.0555\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0556\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0552\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0552\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0549\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0552\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0552\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0545\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0548\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0547\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0542\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0540\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0545\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0540\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0543\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0548\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0545\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0538\n",
      "19/19 [==============================] - 0s 856us/step - loss: 0.0546\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3559 - val_loss: 0.1257\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1038 - val_loss: 0.1541\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0934 - val_loss: 0.0823\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0772 - val_loss: 0.0742\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0646 - val_loss: 0.0661\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0628\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.0611\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0597\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0594\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.0611\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0564 - val_loss: 0.0586\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0575\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0569\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0566\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0567\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0564\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0554\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0554\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0557\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0552\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0559\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0542\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0557\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0546\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0558\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0544\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0550\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0538\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0557\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0539\n",
      "19/19 [==============================] - 0s 867us/step - loss: 0.0521\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2702 - val_loss: 0.1127\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0952 - val_loss: 0.0839\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0775 - val_loss: 0.0757\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0706 - val_loss: 0.0696\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0661 - val_loss: 0.0663\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0631 - val_loss: 0.0643\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.0617\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0612\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0598\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0622\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.0582\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0575\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.0582\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0581\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0580\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0562\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0574\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0558\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0560\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0560\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0551\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0556\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0549\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0549\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0548\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0549\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0547\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0543\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0549\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0561\n",
      "19/19 [==============================] - 0s 854us/step - loss: 0.0536\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3334 - val_loss: 0.1055\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1075 - val_loss: 0.0938\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1100 - val_loss: 0.0964\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.0692\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0646 - val_loss: 0.0616\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0620\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0594\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.0581\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0583\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0580\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0566\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0570\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0556\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0561\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0565\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0558\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0551\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0545\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0544\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0544\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0545\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0546\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0537\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0542\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0538\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0538\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0534\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0534\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0534\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0534\n",
      "19/19 [==============================] - 0s 924us/step - loss: 0.0588\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5416 - val_loss: 0.0865\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.0736\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0698 - val_loss: 0.0653\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0654 - val_loss: 0.0620\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0624 - val_loss: 0.0597\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0584\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.0581\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0565\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0558\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.0559\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.0548\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0552\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0545\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0537\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0536\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0544\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0530\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0537\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0550\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0527\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0526\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0535\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0522\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0523\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0519\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0521\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0520\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0537\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0518\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0517\n",
      "19/19 [==============================] - 0s 812us/step - loss: 0.0530\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2730 - val_loss: 0.1590\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1790 - val_loss: 0.1064\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.3717\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0779 - val_loss: 0.0658\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.0643\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0612 - val_loss: 0.0611\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.0593\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0593\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0575\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0579\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0561 - val_loss: 0.0576\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0560\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0555\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0550\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0547\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0547\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0543\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0567\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0546\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0540\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0544\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0537\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0533\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0535\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0536\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0538\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0530\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0530\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0537\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0532\n",
      "19/19 [==============================] - 0s 869us/step - loss: 0.0542\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2283 - val_loss: 0.1191\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0975 - val_loss: 0.0943\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0861 - val_loss: 0.0703\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0758 - val_loss: 0.0733\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0682 - val_loss: 0.0603\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0643 - val_loss: 0.0625\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.0573\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.0550\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0557\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0531\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0526\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0562 - val_loss: 0.0527\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0515\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0508\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0507\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0502\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0501\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0500\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0534\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0496\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0493\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0496\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0504\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0489\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0489\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0488\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0500\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0484\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0486\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0482\n",
      "19/19 [==============================] - 0s 861us/step - loss: 0.0569\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3085 - val_loss: 0.1352\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.0782\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0812 - val_loss: 0.0965\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0870\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.0667\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0604\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0596\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.0572\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.0573\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.0560\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0558\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0551\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0549\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0552\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0550\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0546\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0540\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0540\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0549\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0539\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0541\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0540\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.0548\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0532\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0542\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0533\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0534\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0540\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0530\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0551\n",
      "19/19 [==============================] - 0s 864us/step - loss: 0.0562\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2878 - val_loss: 0.1972\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1370 - val_loss: 0.0968\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.3427\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0642\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0655 - val_loss: 0.0613\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0626 - val_loss: 0.0597\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0585\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0571\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0592\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0560\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0552\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.0553\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.0546\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0564 - val_loss: 0.0545\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0560 - val_loss: 0.0555\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0557 - val_loss: 0.0540\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0538\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.0534\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.0535\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0558\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0530\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0532\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0527\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0550\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0527\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0525\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0523\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0524\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0522\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0539\n",
      "19/19 [==============================] - 0s 793us/step - loss: 0.0572\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2586 - val_loss: 0.3525\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1822 - val_loss: 0.1558\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1911 - val_loss: 0.1225\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0905 - val_loss: 0.0645\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0636 - val_loss: 0.0611\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0610 - val_loss: 0.0593\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0580\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0563\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0561\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.0551\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0564 - val_loss: 0.0541\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0542\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0544\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0541\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0530\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0528\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0521\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0533\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0523\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0516\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0516\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0517\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0510\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0511\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0515\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0507\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0509\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0511\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.0510\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0508\n",
      "19/19 [==============================] - 0s 848us/step - loss: 0.0558\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1762 - val_loss: 0.0869\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0844 - val_loss: 0.0719\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0681\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0677 - val_loss: 0.0638\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0639 - val_loss: 0.0613\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.0597\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0578\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0568\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.0584\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0564 - val_loss: 0.0569\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0554\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0546\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0543\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0542\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0548\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0538\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0550\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0546\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0540\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0535\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0532\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0529\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0548\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0588\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0527\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0525\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0541\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0525\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0526\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0522\n",
      "19/19 [==============================] - 0s 779us/step - loss: 0.0578\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.2604\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2341 - val_loss: 0.1983\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1854 - val_loss: 0.1631\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1564 - val_loss: 0.1419\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1372 - val_loss: 0.1277\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1240 - val_loss: 0.1177\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1144 - val_loss: 0.1102\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1070 - val_loss: 0.1052\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1015 - val_loss: 0.1002\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0970 - val_loss: 0.0967\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0934 - val_loss: 0.0939\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0904 - val_loss: 0.0913\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0879 - val_loss: 0.0893\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0856 - val_loss: 0.0874\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.0859\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0822 - val_loss: 0.0843\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0807 - val_loss: 0.0831\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0794 - val_loss: 0.0818\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0782 - val_loss: 0.0807\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0799\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.0788\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0752 - val_loss: 0.0780\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0773\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0766\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0758\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.0754\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0746\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.0741\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0736\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0730\n",
      "19/19 [==============================] - 0s 802us/step - loss: 0.0834\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3934 - val_loss: 0.3124\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2608 - val_loss: 0.2381\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2044 - val_loss: 0.1952\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1722 - val_loss: 0.1699\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1510 - val_loss: 0.1528\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1365 - val_loss: 0.1406\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1257 - val_loss: 0.1317\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1177 - val_loss: 0.1241\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1112 - val_loss: 0.1183\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1059 - val_loss: 0.1134\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1016 - val_loss: 0.1093\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0980 - val_loss: 0.1059\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0948 - val_loss: 0.1029\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.1003\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0897 - val_loss: 0.0979\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0877 - val_loss: 0.0957\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0858 - val_loss: 0.0938\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0842 - val_loss: 0.0921\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0826 - val_loss: 0.0906\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0812 - val_loss: 0.0892\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0879\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0868\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0777 - val_loss: 0.0857\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0848\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0839\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0831\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0823\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0816\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0808\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0801\n",
      "19/19 [==============================] - 0s 880us/step - loss: 0.0701\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4295 - val_loss: 0.2384\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2290 - val_loss: 0.1872\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1841 - val_loss: 0.1597\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1584 - val_loss: 0.1430\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1421 - val_loss: 0.1322\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1304 - val_loss: 0.1239\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1222 - val_loss: 0.1177\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1161 - val_loss: 0.1129\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1111 - val_loss: 0.1090\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1071 - val_loss: 0.1056\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1038 - val_loss: 0.1028\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1008 - val_loss: 0.1003\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0983 - val_loss: 0.0980\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0961 - val_loss: 0.0960\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0941 - val_loss: 0.0941\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.0924\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0905 - val_loss: 0.0910\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.0895\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0876 - val_loss: 0.0883\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0863 - val_loss: 0.0871\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0851 - val_loss: 0.0861\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0840 - val_loss: 0.0852\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0844\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0821 - val_loss: 0.0831\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0811 - val_loss: 0.0824\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0816\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0808\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0801\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0794\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0774 - val_loss: 0.0788\n",
      "19/19 [==============================] - 0s 857us/step - loss: 0.0774\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5792 - val_loss: 0.3352\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2672 - val_loss: 0.2284\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1939 - val_loss: 0.1783\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1569 - val_loss: 0.1507\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1353 - val_loss: 0.1332\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1217 - val_loss: 0.1216\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1124 - val_loss: 0.1126\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1056 - val_loss: 0.1062\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1003 - val_loss: 0.1011\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0961 - val_loss: 0.0972\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0928 - val_loss: 0.0938\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0899 - val_loss: 0.0909\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0876 - val_loss: 0.0886\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0855 - val_loss: 0.0865\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0837 - val_loss: 0.0850\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0821 - val_loss: 0.0835\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0821\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.0809\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0799\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0775 - val_loss: 0.0790\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0781\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0774\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0766\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0760\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0754\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0731 - val_loss: 0.0748\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0744\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.0739\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0715 - val_loss: 0.0734\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.0730\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0756\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3182 - val_loss: 0.2267\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2129 - val_loss: 0.1834\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1751 - val_loss: 0.1577\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1524 - val_loss: 0.1409\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1373 - val_loss: 0.1294\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1267 - val_loss: 0.1208\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1189 - val_loss: 0.1141\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1130 - val_loss: 0.1090\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1081 - val_loss: 0.1047\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1042 - val_loss: 0.1011\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1009 - val_loss: 0.0985\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0982 - val_loss: 0.0956\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0957 - val_loss: 0.0933\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0936 - val_loss: 0.0912\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0917 - val_loss: 0.0894\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.0880\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0884 - val_loss: 0.0864\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0871 - val_loss: 0.0851\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0858 - val_loss: 0.0841\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0847 - val_loss: 0.0828\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0836 - val_loss: 0.0821\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0827 - val_loss: 0.0812\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0800\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0792\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0801 - val_loss: 0.0787\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0794 - val_loss: 0.0778\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0786 - val_loss: 0.0770\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0766\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0756\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0750\n",
      "19/19 [==============================] - 0s 871us/step - loss: 0.1140\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3210 - val_loss: 0.2251\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1912 - val_loss: 0.1705\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1541 - val_loss: 0.1452\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1350 - val_loss: 0.1295\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1227 - val_loss: 0.1204\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1142 - val_loss: 0.1119\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1079 - val_loss: 0.1064\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1027 - val_loss: 0.1030\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0989 - val_loss: 0.0988\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0956 - val_loss: 0.0956\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0928 - val_loss: 0.0932\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0905 - val_loss: 0.0910\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.0891\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0866 - val_loss: 0.0873\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.0860\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0836 - val_loss: 0.0847\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0834\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0811 - val_loss: 0.0824\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0816\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.0805\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.0796\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0789\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0764 - val_loss: 0.0780\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0774\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0749 - val_loss: 0.0767\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0761\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0755\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0750\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0748\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.0740\n",
      "19/19 [==============================] - 0s 861us/step - loss: 0.0732\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4709 - val_loss: 0.1996\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2063 - val_loss: 0.1706\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1736 - val_loss: 0.1533\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1539 - val_loss: 0.1391\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1402 - val_loss: 0.1301\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1300 - val_loss: 0.1216\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1221 - val_loss: 0.1154\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1157 - val_loss: 0.1102\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1104 - val_loss: 0.1058\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1059 - val_loss: 0.1017\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1022 - val_loss: 0.0987\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0989 - val_loss: 0.0956\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0961 - val_loss: 0.0932\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0935 - val_loss: 0.0910\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0914 - val_loss: 0.0888\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0893 - val_loss: 0.0873\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0874 - val_loss: 0.0859\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0858 - val_loss: 0.0841\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0843 - val_loss: 0.0829\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0817\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.0807\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0796\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.0788\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0786 - val_loss: 0.0779\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0776 - val_loss: 0.0771\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0762\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0757\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0748\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0742\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0737\n",
      "19/19 [==============================] - 0s 883us/step - loss: 0.0781\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4225 - val_loss: 0.2702\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2345 - val_loss: 0.2128\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1890 - val_loss: 0.1814\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1626 - val_loss: 0.1614\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1458 - val_loss: 0.1482\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1337 - val_loss: 0.1383\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1248 - val_loss: 0.1293\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1179 - val_loss: 0.1237\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1123 - val_loss: 0.1177\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1076 - val_loss: 0.1127\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1038 - val_loss: 0.1091\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1002 - val_loss: 0.1078\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0976 - val_loss: 0.1030\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0951 - val_loss: 0.1003\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.0984\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.0962\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0893 - val_loss: 0.0950\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0877 - val_loss: 0.0928\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0864 - val_loss: 0.0914\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.0899\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.0887\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0828 - val_loss: 0.0875\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.0865\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0807 - val_loss: 0.0854\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0849\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.0836\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0783 - val_loss: 0.0830\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0775 - val_loss: 0.0821\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0813\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0762 - val_loss: 0.0806\n",
      "19/19 [==============================] - 0s 906us/step - loss: 0.0800\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3756 - val_loss: 0.2272\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1980 - val_loss: 0.1719\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1584 - val_loss: 0.1459\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1381 - val_loss: 0.1302\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1257 - val_loss: 0.1199\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1169 - val_loss: 0.1124\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1106 - val_loss: 0.1068\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1055 - val_loss: 0.1025\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1014 - val_loss: 0.0988\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0979 - val_loss: 0.0958\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0951 - val_loss: 0.0932\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0926 - val_loss: 0.0911\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0903 - val_loss: 0.0899\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0886 - val_loss: 0.0876\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0868 - val_loss: 0.0859\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0848\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0839 - val_loss: 0.0833\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0826 - val_loss: 0.0822\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0811\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0801\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0794\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0784\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0776 - val_loss: 0.0777\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0770\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0763\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0754 - val_loss: 0.0757\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0747 - val_loss: 0.0751\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0741 - val_loss: 0.0745\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.0740\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0735\n",
      "19/19 [==============================] - 0s 847us/step - loss: 0.0717\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3939 - val_loss: 0.2837\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2328 - val_loss: 0.2193\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1906 - val_loss: 0.1851\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1654 - val_loss: 0.1627\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1484 - val_loss: 0.1479\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1360 - val_loss: 0.1361\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1268 - val_loss: 0.1278\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1196 - val_loss: 0.1206\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1137 - val_loss: 0.1151\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1091 - val_loss: 0.1102\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1049 - val_loss: 0.1063\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1014 - val_loss: 0.1026\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0983 - val_loss: 0.0995\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0955 - val_loss: 0.0968\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0932 - val_loss: 0.0943\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0910 - val_loss: 0.0919\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.0899\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0872 - val_loss: 0.0881\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0855 - val_loss: 0.0864\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0841 - val_loss: 0.0848\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0827 - val_loss: 0.0834\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0821\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0801 - val_loss: 0.0810\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0791 - val_loss: 0.0799\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0790\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0779\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0762 - val_loss: 0.0770\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.0762\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0754\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0738 - val_loss: 0.0746\n",
      "19/19 [==============================] - 0s 915us/step - loss: 0.0760\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4167 - val_loss: 0.2894\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2619 - val_loss: 0.2225\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2111 - val_loss: 0.1873\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1823 - val_loss: 0.1662\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1629 - val_loss: 0.1505\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1487 - val_loss: 0.1390\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1378 - val_loss: 0.1305\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1294 - val_loss: 0.1229\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1223 - val_loss: 0.1173\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1167 - val_loss: 0.1124\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1119 - val_loss: 0.1082\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1078 - val_loss: 0.1048\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1043 - val_loss: 0.1018\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1013 - val_loss: 0.0990\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0985 - val_loss: 0.0967\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0961 - val_loss: 0.0946\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0939 - val_loss: 0.0926\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0920 - val_loss: 0.0908\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.0893\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0886 - val_loss: 0.0879\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0871 - val_loss: 0.0865\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0857 - val_loss: 0.0852\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0844 - val_loss: 0.0840\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0833 - val_loss: 0.0829\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0822 - val_loss: 0.0819\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0812 - val_loss: 0.0810\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0802 - val_loss: 0.0800\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0792\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.0784\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0777 - val_loss: 0.0777\n",
      "19/19 [==============================] - 0s 777us/step - loss: 0.0732\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2903 - val_loss: 0.2064\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1942 - val_loss: 0.1725\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1654 - val_loss: 0.1523\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1466 - val_loss: 0.1376\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1332 - val_loss: 0.1274\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1230 - val_loss: 0.1196\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1152 - val_loss: 0.1135\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1090 - val_loss: 0.1085\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1040 - val_loss: 0.1042\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0999 - val_loss: 0.1007\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0964 - val_loss: 0.0979\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.0953\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0910 - val_loss: 0.0934\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0889 - val_loss: 0.0914\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0870 - val_loss: 0.0898\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0885\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.0871\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0825 - val_loss: 0.0859\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0847\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0801 - val_loss: 0.0839\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0791 - val_loss: 0.0829\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.0820\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.0813\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0765 - val_loss: 0.0806\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0799\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0792\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0787\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0738 - val_loss: 0.0781\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0776\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0771\n",
      "19/19 [==============================] - 0s 882us/step - loss: 0.0811\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5381 - val_loss: 0.2252\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2086 - val_loss: 0.1668\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1624 - val_loss: 0.1375\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1376 - val_loss: 0.1205\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1228 - val_loss: 0.1098\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1128 - val_loss: 0.1022\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1059 - val_loss: 0.0966\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1007 - val_loss: 0.0922\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0966 - val_loss: 0.0890\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0933 - val_loss: 0.0860\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0906 - val_loss: 0.0837\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0882 - val_loss: 0.0818\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0862 - val_loss: 0.0801\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0844 - val_loss: 0.0785\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0829 - val_loss: 0.0772\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0760\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0801 - val_loss: 0.0749\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0789 - val_loss: 0.0739\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0779 - val_loss: 0.0730\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.0722\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0714\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0707\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0701\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0695\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0690\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0685\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0680\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.0676\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0706 - val_loss: 0.0671\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0701 - val_loss: 0.0668\n",
      "19/19 [==============================] - 0s 825us/step - loss: 0.0621\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3322 - val_loss: 0.2474\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2262 - val_loss: 0.1899\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1813 - val_loss: 0.1610\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1559 - val_loss: 0.1430\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1388 - val_loss: 0.1311\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1267 - val_loss: 0.1215\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1175 - val_loss: 0.1146\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1102 - val_loss: 0.1099\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1044 - val_loss: 0.1044\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0998 - val_loss: 0.1004\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0958 - val_loss: 0.0972\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0924 - val_loss: 0.0943\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0896 - val_loss: 0.0920\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0870 - val_loss: 0.0898\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0849 - val_loss: 0.0879\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.0861\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0813 - val_loss: 0.0846\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0798 - val_loss: 0.0832\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0822\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0808\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0798\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0789\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0741 - val_loss: 0.0778\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0770\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0762\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.0755\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0747\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0741\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0735\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0729\n",
      "19/19 [==============================] - 0s 850us/step - loss: 0.0781\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.2502\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2210 - val_loss: 0.1967\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1786 - val_loss: 0.1688\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1550 - val_loss: 0.1522\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1393 - val_loss: 0.1388\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1277 - val_loss: 0.1297\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1189 - val_loss: 0.1233\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1120 - val_loss: 0.1170\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1065 - val_loss: 0.1125\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1019 - val_loss: 0.1087\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0981 - val_loss: 0.1059\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0948 - val_loss: 0.1031\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0920 - val_loss: 0.1007\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0896 - val_loss: 0.0986\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0875 - val_loss: 0.0974\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0857 - val_loss: 0.0952\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0841 - val_loss: 0.0937\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0826 - val_loss: 0.0924\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0812 - val_loss: 0.0915\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0802 - val_loss: 0.0903\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0791 - val_loss: 0.0892\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.0881\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0772 - val_loss: 0.0873\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0764 - val_loss: 0.0863\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0857\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0748 - val_loss: 0.0850\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0842\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0837\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0830\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0830\n",
      "19/19 [==============================] - 0s 800us/step - loss: 0.0850\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2798 - val_loss: 0.2143\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2092 - val_loss: 0.1720\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1722 - val_loss: 0.1467\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1490 - val_loss: 0.1311\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1332 - val_loss: 0.1202\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1219 - val_loss: 0.1121\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1133 - val_loss: 0.1074\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1069 - val_loss: 0.1018\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1017 - val_loss: 0.0986\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0976 - val_loss: 0.0953\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0943 - val_loss: 0.0927\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0915 - val_loss: 0.0914\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0893 - val_loss: 0.0894\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0872 - val_loss: 0.0877\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0854 - val_loss: 0.0865\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0839 - val_loss: 0.0850\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0824 - val_loss: 0.0839\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0811 - val_loss: 0.0828\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0818\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0789 - val_loss: 0.0808\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0778 - val_loss: 0.0800\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.0792\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.0784\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.0777\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0771\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0764\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0758\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.0752\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.0747\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.0742\n",
      "19/19 [==============================] - 0s 826us/step - loss: 0.0714\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2741 - val_loss: 0.2224\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2035 - val_loss: 0.1861\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1720 - val_loss: 0.1650\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1532 - val_loss: 0.1510\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1406 - val_loss: 0.1404\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1313 - val_loss: 0.1321\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1243 - val_loss: 0.1253\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1183 - val_loss: 0.1199\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1136 - val_loss: 0.1148\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.108 - 0s 1ms/step - loss: 0.1096 - val_loss: 0.1108\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1061 - val_loss: 0.1072\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1031 - val_loss: 0.1037\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1003 - val_loss: 0.1009\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0980 - val_loss: 0.0987\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0960 - val_loss: 0.0961\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0941 - val_loss: 0.0940\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0923 - val_loss: 0.0922\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0908 - val_loss: 0.0905\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0894 - val_loss: 0.0889\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0881 - val_loss: 0.0875\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0868 - val_loss: 0.0862\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0857 - val_loss: 0.0852\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.0837\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0836 - val_loss: 0.0826\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0827 - val_loss: 0.0816\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0807\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0799\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0789\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0781\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0775\n",
      "19/19 [==============================] - 0s 783us/step - loss: 0.1309\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.2405\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2265 - val_loss: 0.1814\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1783 - val_loss: 0.1557\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1531 - val_loss: 0.1377\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1369 - val_loss: 0.1260\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1257 - val_loss: 0.1178\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1172 - val_loss: 0.1108\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1107 - val_loss: 0.1057\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1054 - val_loss: 0.1017\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1012 - val_loss: 0.0979\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0977 - val_loss: 0.0950\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0947 - val_loss: 0.0923\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.0904\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.0887\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0880 - val_loss: 0.0869\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0865 - val_loss: 0.0855\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0849 - val_loss: 0.0843\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0837 - val_loss: 0.0832\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0825 - val_loss: 0.0821\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0811\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0804 - val_loss: 0.0804\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0796\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0788\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0779 - val_loss: 0.0780\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0772 - val_loss: 0.0775\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0765 - val_loss: 0.0771\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0763\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0752 - val_loss: 0.0759\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0747 - val_loss: 0.0754\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0741 - val_loss: 0.0748\n",
      "19/19 [==============================] - 0s 896us/step - loss: 0.0720\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3455 - val_loss: 0.2751\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2401 - val_loss: 0.2147\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1937 - val_loss: 0.1822\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1669 - val_loss: 0.1606\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1487 - val_loss: 0.1459\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1360 - val_loss: 0.1353\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1268 - val_loss: 0.1272\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1193 - val_loss: 0.1207\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1136 - val_loss: 0.1156\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1089 - val_loss: 0.1115\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1050 - val_loss: 0.1082\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1017 - val_loss: 0.1049\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0989 - val_loss: 0.1022\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0963 - val_loss: 0.0999\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0941 - val_loss: 0.0977\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.0959\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0903 - val_loss: 0.0943\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0887 - val_loss: 0.0926\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0873 - val_loss: 0.0913\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0859 - val_loss: 0.0899\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0847 - val_loss: 0.0887\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0836 - val_loss: 0.0875\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0826 - val_loss: 0.0865\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0816 - val_loss: 0.0856\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0807 - val_loss: 0.0846\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0798 - val_loss: 0.0838\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.0830\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0782 - val_loss: 0.0823\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0775 - val_loss: 0.0818\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0809\n",
      "19/19 [==============================] - 0s 803us/step - loss: 0.0800\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3461 - val_loss: 0.2282\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.207 - 0s 1ms/step - loss: 0.2083 - val_loss: 0.1651\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1625 - val_loss: 0.1379\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1399 - val_loss: 0.1230\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1267 - val_loss: 0.1140\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1177 - val_loss: 0.1077\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1109 - val_loss: 0.1025\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1060 - val_loss: 0.0991\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1018 - val_loss: 0.0958\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0984 - val_loss: 0.0933\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0955 - val_loss: 0.0909\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.0889\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0908 - val_loss: 0.0873\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0888 - val_loss: 0.0858\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0870 - val_loss: 0.0844\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0854 - val_loss: 0.0832\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0839 - val_loss: 0.0824\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0814\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0803\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0794\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0792 - val_loss: 0.0786\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0783 - val_loss: 0.0778\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0775 - val_loss: 0.0772\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0765\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0761\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0753\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0748\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0738 - val_loss: 0.0743\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0734\n",
      "19/19 [==============================] - 0s 946us/step - loss: 0.0816\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3777 - val_loss: 0.2907\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2510 - val_loss: 0.2223\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1977 - val_loss: 0.1843\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1672 - val_loss: 0.1606\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1470 - val_loss: 0.1438\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1331 - val_loss: 0.1324\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1230 - val_loss: 0.1235\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1152 - val_loss: 0.1168\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1093 - val_loss: 0.1113\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1045 - val_loss: 0.1064\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1006 - val_loss: 0.1026\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0973 - val_loss: 0.0996\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0945 - val_loss: 0.0966\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0919 - val_loss: 0.0951\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.0926\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0880 - val_loss: 0.0903\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0864 - val_loss: 0.0891\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0876\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0835 - val_loss: 0.0857\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0845\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0812 - val_loss: 0.0835\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0802 - val_loss: 0.0827\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0816\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0809\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0777 - val_loss: 0.0800\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.0794\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0763 - val_loss: 0.0788\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0781\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0774\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0773\n",
      "19/19 [==============================] - 0s 936us/step - loss: 0.0784\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3341 - val_loss: 0.2140\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2060 - val_loss: 0.1766\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1681 - val_loss: 0.1571\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1486 - val_loss: 0.1446\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1362 - val_loss: 0.1355\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1274 - val_loss: 0.1284\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1207 - val_loss: 0.1231\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1153 - val_loss: 0.1186\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1110 - val_loss: 0.1144\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1072 - val_loss: 0.1108\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1040 - val_loss: 0.1079\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1011 - val_loss: 0.1053\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0986 - val_loss: 0.1028\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0964 - val_loss: 0.1007\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0943 - val_loss: 0.0988\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0925 - val_loss: 0.0969\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0907 - val_loss: 0.0953\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0891 - val_loss: 0.0938\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0877 - val_loss: 0.0924\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0863 - val_loss: 0.0909\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.0898\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0839 - val_loss: 0.0886\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0827 - val_loss: 0.0875\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.0865\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0807 - val_loss: 0.0856\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0798 - val_loss: 0.0847\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0789 - val_loss: 0.0839\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0830\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.0823\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0765 - val_loss: 0.0815\n",
      "19/19 [==============================] - 0s 891us/step - loss: 0.0885\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3333 - val_loss: 0.2443\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2015 - val_loss: 0.1793\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1548 - val_loss: 0.1503\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1316 - val_loss: 0.1343\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1182 - val_loss: 0.1242\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1092 - val_loss: 0.1169\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1029 - val_loss: 0.1115\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0981 - val_loss: 0.1074\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0943 - val_loss: 0.1040\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0913 - val_loss: 0.1013\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0888 - val_loss: 0.0987\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0866 - val_loss: 0.0968\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0849 - val_loss: 0.0949\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0832 - val_loss: 0.0930\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0924\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0902\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0893\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0883\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0775 - val_loss: 0.0869\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0861\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0851\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0844\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0836\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0830\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0821\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0815\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0807\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.0801\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0796\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0793\n",
      "19/19 [==============================] - 0s 852us/step - loss: 0.0786\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3496 - val_loss: 0.2849\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2388 - val_loss: 0.2196\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1905 - val_loss: 0.1832\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1631 - val_loss: 0.1611\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1453 - val_loss: 0.1462\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1329 - val_loss: 0.1353\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1238 - val_loss: 0.1268\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1167 - val_loss: 0.1201\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1111 - val_loss: 0.1147\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1065 - val_loss: 0.1100\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1027 - val_loss: 0.1062\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0994 - val_loss: 0.1028\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0967 - val_loss: 0.0998\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0942 - val_loss: 0.0971\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.0947\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.0926\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0884 - val_loss: 0.0908\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.0893\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0856 - val_loss: 0.0875\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0842 - val_loss: 0.0861\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0831 - val_loss: 0.0848\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0820 - val_loss: 0.0835\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0824\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0801 - val_loss: 0.0814\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0792 - val_loss: 0.0804\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.0795\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0777 - val_loss: 0.0787\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0770 - val_loss: 0.0779\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0763 - val_loss: 0.0771\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0764\n",
      "19/19 [==============================] - 0s 866us/step - loss: 0.0756\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.2632\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2512 - val_loss: 0.2010\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1983 - val_loss: 0.1656\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1651 - val_loss: 0.1409\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1431 - val_loss: 0.1253\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1284 - val_loss: 0.1149\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1180 - val_loss: 0.1074\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1105 - val_loss: 0.1020\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1049 - val_loss: 0.0981\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0949\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0972 - val_loss: 0.0925\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0944 - val_loss: 0.0902\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.0883\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.0868\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0884 - val_loss: 0.0854\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.0841\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0855 - val_loss: 0.0829\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0843 - val_loss: 0.0818\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0831 - val_loss: 0.0808\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0820 - val_loss: 0.0799\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0793\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0802 - val_loss: 0.0783\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0792 - val_loss: 0.0777\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0769\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.0763\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0770 - val_loss: 0.0758\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0763 - val_loss: 0.0752\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0746\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0741\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0736\n",
      "19/19 [==============================] - 0s 889us/step - loss: 0.0775\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6572 - val_loss: 0.2240\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2356 - val_loss: 0.1737\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1881 - val_loss: 0.1450\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1593 - val_loss: 0.1275\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1405 - val_loss: 0.1143\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1271 - val_loss: 0.1050\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1169 - val_loss: 0.0986\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1092 - val_loss: 0.0929\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1031 - val_loss: 0.0887\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0981 - val_loss: 0.0851\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0940 - val_loss: 0.0821\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0906 - val_loss: 0.0796\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0877 - val_loss: 0.0774\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0852 - val_loss: 0.0755\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0738\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0811 - val_loss: 0.0724\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0794 - val_loss: 0.0711\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0700\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0690\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0682\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0673\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0666\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0659\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0654\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0654\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.0642\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0637\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.0633\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0629\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0683 - val_loss: 0.0625\n",
      "19/19 [==============================] - 0s 849us/step - loss: 0.0780\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3119 - val_loss: 0.2111\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1860 - val_loss: 0.1592\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1508 - val_loss: 0.1326\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1318 - val_loss: 0.1225\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1205 - val_loss: 0.1103\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1124 - val_loss: 0.1044\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1067 - val_loss: 0.1002\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1022 - val_loss: 0.0973\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0986 - val_loss: 0.0943\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0957 - val_loss: 0.0926\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0933 - val_loss: 0.0906\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0912 - val_loss: 0.0890\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0894 - val_loss: 0.0881\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0878 - val_loss: 0.0862\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0864 - val_loss: 0.0855\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.0843\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0837 - val_loss: 0.0840\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0826 - val_loss: 0.0823\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0815 - val_loss: 0.0820\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0805 - val_loss: 0.0812\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.0799\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0791\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0789\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0772 - val_loss: 0.0781\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0777\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0758 - val_loss: 0.0766\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0760\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0754\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0749\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0748\n",
      "19/19 [==============================] - 0s 789us/step - loss: 0.0730\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3781 - val_loss: 0.2316\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2220 - val_loss: 0.1957\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1888 - val_loss: 0.1700\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1649 - val_loss: 0.1522\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1475 - val_loss: 0.1386\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1343 - val_loss: 0.1283\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1242 - val_loss: 0.1200\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1162 - val_loss: 0.1134\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1098 - val_loss: 0.1081\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1047 - val_loss: 0.1038\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1004 - val_loss: 0.1000\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0968 - val_loss: 0.0969\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0938 - val_loss: 0.0942\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0913 - val_loss: 0.0920\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.0898\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0870 - val_loss: 0.0879\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0863\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0837 - val_loss: 0.0848\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0835\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0824\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0798 - val_loss: 0.0811\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0802\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0777 - val_loss: 0.0791\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0786\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0775\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0752 - val_loss: 0.0767\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0760\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0738 - val_loss: 0.0753\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0747\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.0742\n",
      "19/19 [==============================] - 0s 943us/step - loss: 0.0827\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3482 - val_loss: 0.2607\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2253 - val_loss: 0.2007\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1793 - val_loss: 0.1748\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1551 - val_loss: 0.1582\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1396 - val_loss: 0.1462\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1283 - val_loss: 0.1370\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1203 - val_loss: 0.1301\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1137 - val_loss: 0.1232\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1083 - val_loss: 0.1179\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1039 - val_loss: 0.1135\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1000 - val_loss: 0.1096\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0968 - val_loss: 0.1067\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0941 - val_loss: 0.1037\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.1008\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0896 - val_loss: 0.0986\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0878 - val_loss: 0.0966\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0862 - val_loss: 0.0947\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0847 - val_loss: 0.0929\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0833 - val_loss: 0.0915\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0821 - val_loss: 0.0900\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0891\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0877\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.0868\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0782 - val_loss: 0.0856\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0774 - val_loss: 0.0846\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0837\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0830\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0752 - val_loss: 0.0821\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0815\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0741 - val_loss: 0.0808\n",
      "19/19 [==============================] - 0s 861us/step - loss: 0.1215\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3991 - val_loss: 0.2539\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2534 - val_loss: 0.1954\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1954 - val_loss: 0.1624\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1636 - val_loss: 0.1426\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1435 - val_loss: 0.1290\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1298 - val_loss: 0.1199\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1201 - val_loss: 0.1121\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1127 - val_loss: 0.1068\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1069 - val_loss: 0.1023\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1023 - val_loss: 0.1003\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0988 - val_loss: 0.0954\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0955 - val_loss: 0.0932\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0928 - val_loss: 0.0915\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0905 - val_loss: 0.0896\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.0873\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0867 - val_loss: 0.0858\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0851 - val_loss: 0.0845\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0835 - val_loss: 0.0833\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0824\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0811 - val_loss: 0.0813\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0804\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.0796\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.0789\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.0782\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0764 - val_loss: 0.0775\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0769\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0764\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0757\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0756\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0731 - val_loss: 0.0749\n",
      "19/19 [==============================] - 0s 883us/step - loss: 0.0809\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1131 - val_loss: 0.0723\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0645\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0622\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0581\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0570\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0564\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0557\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0550\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.0549\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0542\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0538\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0533\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0532\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0530\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0530\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0528\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0527\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0529\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0520\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0520\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0519\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0516\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0519\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0518\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0521\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0514\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0519\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0519\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0512\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0589\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.0848\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0708\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0684\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0620\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0593\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0575\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0572\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0570\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0577\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0558\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0554\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0547\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0549\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0559\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0541\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0547\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0555\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0536\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0537\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0536\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0533\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0548\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0532\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0545\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0529\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0548\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0569\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0527\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0526\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0526\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0505\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1157 - val_loss: 0.0736\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0625\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.0575\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0566\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0556\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.0565\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.0546\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0599\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0568\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0542\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0535\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0531\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0530\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0553\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0528\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0527\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0534\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0530\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0522\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0521\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0523\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0524\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0564\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0523\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0519\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0535\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0521\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0524\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0516\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0550\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1363 - val_loss: 0.0823\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0765\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0616\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.0610\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0594\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.0584\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0585\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0583\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0575\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0529 - val_loss: 0.0572\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0565\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0571\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0564\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0562\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0560\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0569\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0557\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0560\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0552\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0555\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0556\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0555\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0548\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0547\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0556\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0548\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0545\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0551\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0555\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0546\n",
      "19/19 [==============================] - 0s 995us/step - loss: 0.0580\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1162 - val_loss: 0.0741\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0640\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0583\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.0574\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0622\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0549\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0533\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0525\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0517\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0512\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0513\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0512\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0514 - val_loss: 0.0512\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.0501\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0502\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0500\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0499\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0500\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0496\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0495\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0528\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0489\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0517\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0493\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0536\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0490\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0494\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0496\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0522\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0484\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0581\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1327 - val_loss: 0.0891\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0674\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0643\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0610\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0601\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0587\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.0584\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0584\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0573\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0572\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0568\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0567\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0572\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0562\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0559\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0509 - val_loss: 0.0557\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0555\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0557\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0556\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0551\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0555\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0551\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0549\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0549\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0550\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0549\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0551\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0547\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0557\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0547\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0572\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1326 - val_loss: 0.0808\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.0695\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0674\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.0615\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0614\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0597\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0596\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0583\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0578\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.0576\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0572\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0575\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0563\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0566\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0561\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0560\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0555\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0567\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0552\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0552\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0552\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0554\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0550\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0550\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0552\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0548\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0584\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0545\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0546\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.0546\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0520\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1105 - val_loss: 0.0837\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.0663\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0599\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0581\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0571 - val_loss: 0.0569\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0562\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.0566\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0552\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0556\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0546\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0529 - val_loss: 0.0541\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0539\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0562\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0540\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0541\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0536\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0548\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0535\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0529\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0529\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0543\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0564\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0533\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0569\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0527\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0530\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0531\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0546\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0528\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0525\n",
      "19/19 [==============================] - 0s 976us/step - loss: 0.0516\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 0.0756\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0673\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0618\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0595\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0585\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0601\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0573\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0561\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0565\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0549\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0550\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0560\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0546\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0542\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0560\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0537\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0543\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0574\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0535\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0532\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0544\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0529\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0541\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0528\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0528\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0530\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0525\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0524\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0524\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0547\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1140 - val_loss: 0.0735\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0652\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0644\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0623\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0603\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0569 - val_loss: 0.0590\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0576\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0568\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0567\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0562\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0555\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0558\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0551\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0550\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0558\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0555\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0541\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0568\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0540\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0534\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0537\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0564\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0536\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0530\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0538\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0528\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0528\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0531\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0536\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0532\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0581\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1276 - val_loss: 0.1073\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0670\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.0576\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.0547\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0538\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0529\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0535\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0525\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0512\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0514\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0507\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0511\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0510\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0505\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0508\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0505\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0503\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0502\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0514\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0500\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0503\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0496\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0501\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0502\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0493\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0499\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0494\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0493\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0492\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0493\n",
      "19/19 [==============================] - 0s 976us/step - loss: 0.0517\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1156 - val_loss: 0.0852\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0712 - val_loss: 0.0666\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.0623\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0576\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0567\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0557\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0555\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0562\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0529 - val_loss: 0.0550\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0556\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0540\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0553\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0539\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0540\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0545\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0539\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0536\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0549\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0535\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0537\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0556\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0548\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0525\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0521\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0523\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0532\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0542\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0521\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0521\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0547\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1202 - val_loss: 0.0712\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0639\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0613\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0580\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0572\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.0564\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0558\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0550\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.0547\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0544\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0541\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0545\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0539\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.0550\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0536\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0535\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0530\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0538\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0531\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0549\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0530\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0528\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0527\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0524\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0526\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0523\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0530\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0523\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0522\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0550\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 0.0752\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0640\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0602\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0597\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0574\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0568\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.0568\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0609\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0549\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0547\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.0542\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0546\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0539\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0535\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0533\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0539\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0534\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0529\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0528\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0527\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0526\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0526\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0531\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0525\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0527\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0524\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0523\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0533\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0532\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0521\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0591\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1424 - val_loss: 0.1054\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0686\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0597\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0576\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0564\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0571\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0559\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0548\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0529 - val_loss: 0.0543\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0546\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0545\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0530\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0549\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0531\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0526\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0524\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0520\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0523\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0531\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0518\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0518\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0519\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0516\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0514\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0514\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0514\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0517\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0552\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0515\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0512\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0627\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1339 - val_loss: 0.0775\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.0635\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0603\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0575\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0568\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0567\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.0555\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0553\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.0549\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0554\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0546\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0572\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0562\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0544\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0539\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0549\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0541\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0540\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0538\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0536\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0535\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0547\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0533\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0538\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0534\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0533\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0555\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0534\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0532\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0533\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0539\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1057 - val_loss: 0.0742\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0654\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0592\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0570\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0560\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0553\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0542\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0552\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0532\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0532\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0535\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0529 - val_loss: 0.0525\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0527\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0521\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0535\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0520\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0520\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0516\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0517\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0530\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0514\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0515\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0513\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0510\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0511\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0517\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0528\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0515\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0512\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0509\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0666\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1329 - val_loss: 0.0974\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0929 - val_loss: 0.0706\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.2963\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0611\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0579\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0576\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0576\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0573\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0567\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0565\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.0564\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0563\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0563\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0562\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0561\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0566\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0564\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0557\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0558\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0558\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0559\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0558\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0560\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0552\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0572\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0553\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0552\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0556\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0554\n",
      "19/19 [==============================] - 0s 988us/step - loss: 0.0557\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 0.0787\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0721\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0657\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0630\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0627\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.0615\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0606\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.0595\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.0584\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0602\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.0588\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0589\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0578\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0573\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0580\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0588\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0571\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0566\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0573\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0567\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0564\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0571\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0563\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0560\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0562\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0571\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0558\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0561\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0562\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0556\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0514\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1552 - val_loss: 0.0737\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0655\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0628\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0622\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0601\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0592\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0596\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0597\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0577\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0574\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.0572\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0570\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0570\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0567\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0564\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0569\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0563\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0563\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0558\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0557\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0561\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0558\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0559\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0572\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0560\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0552\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0552\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0482 - val_loss: 0.0564\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0572\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0551\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0534\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1199 - val_loss: 0.0733\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0655\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0606\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0601\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0571\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0570\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.0555\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0555\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0545\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0599\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0552\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.0541\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0542\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0538\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0541\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0533\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0534\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0532\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0533\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0533\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0532\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0529\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0566\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0544\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0540\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0532\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0528\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0527\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0554\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0526\n",
      "19/19 [==============================] - 0s 998us/step - loss: 0.0531\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1608 - val_loss: 0.0807\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.0664\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0630\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0611\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0599\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0590\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0583\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0579\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0573\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0606\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0563\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0560\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0568\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0563\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0560\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0553\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0575\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0562\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0549\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0553\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0543\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0556\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0547\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0539\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0540\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0540\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0544\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0539\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0552\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0554\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0547\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1258 - val_loss: 0.0815\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0656\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0614\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.0613\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0589\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0587\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.0571\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0570\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0564\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0529 - val_loss: 0.0566\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0562\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0569\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0558\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0557\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0571\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0564\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0553\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0555\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0549\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0550\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0557\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0556\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0552\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0554\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0546\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0547\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0547\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0545\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0545\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0551\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0580\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1577 - val_loss: 0.0729\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0734\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0628\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0600\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0587\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0581\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0572\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0562\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0557\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0565\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0560\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0529 - val_loss: 0.0560\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0554\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0544\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0553\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0562\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0546\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0542\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0585\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0540\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0539\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0566\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0543\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0541\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0535\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0540\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0533\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0555\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0536\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0539\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0528\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1149 - val_loss: 0.0944\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1043 - val_loss: 0.0783\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.2761\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0612\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0607\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0576\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0570\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0569\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0568\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0568\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.0561\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0557\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0560\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0554\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0554\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0555\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0551\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0598\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0562\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0492 - val_loss: 0.0559\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0552\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0548\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0545\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0547\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.0482 - val_loss: 0.0549\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0557\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0544\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0543\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0555\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0547\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0548\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1288 - val_loss: 0.0937\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0594\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0561\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0547\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0538\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0538\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0553 - val_loss: 0.0533\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.0520\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0556\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0514\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.0517\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0509\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0518\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0509\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0512\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0508\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0508\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0510\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0516\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0509\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0506\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0511\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0505\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0503\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0503\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0502\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0504\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0505\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0509\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0506\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0575\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1412 - val_loss: 0.0866\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0726\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0665\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0819\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0632\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0623\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0595\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0593\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0586\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0585\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0577\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0575\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0573\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0574\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0576\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0570\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0566\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0566\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0564\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0567\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0570\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0568\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0565\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0557\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0558\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0558\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0567\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0564\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0554\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0550\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1432 - val_loss: 0.0774\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0620\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.1378\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0574\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0549\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0545\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0538\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0530\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0536\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0527\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0523\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0521\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0521\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0518\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0535\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0516\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0517\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0512\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0512\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0531\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0510\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0515\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0508\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0521\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0518\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0511\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0507\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0509\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0508\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0518\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0546\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.0849\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0663\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0616\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.0590\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0575\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.0564\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0558\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0545\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0547\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0543\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0539\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0533\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0534\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0536\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0529\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0526\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0522\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0541\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0519\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0518\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0521\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0514\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0516\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0530\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0515\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0525\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0515\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0516\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0521\n",
      "19/19 [==============================] - 0s 983us/step - loss: 0.0675\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1353 - val_loss: 0.0716\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0601\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0572\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0573\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0552\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0556\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0543\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0537\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0538\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0536\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0532\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0528\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0528\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0525\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0526\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0522\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0540\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0521\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0522\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0528\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0517\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0514\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0530\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0543\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0521\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0513\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0528\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0512\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0515\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0509\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0572\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.2217 - val_loss: 0.5492\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.4396 - val_loss: 0.3001\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2672 - val_loss: 0.2105\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1954 - val_loss: 0.1662\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1571 - val_loss: 0.1417\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1344 - val_loss: 0.1267\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1201 - val_loss: 0.1174\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1106 - val_loss: 0.1090\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1035 - val_loss: 0.1029\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0982 - val_loss: 0.0983\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0938 - val_loss: 0.0945\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0903 - val_loss: 0.0911\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0872 - val_loss: 0.0887\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0846 - val_loss: 0.0859\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0824 - val_loss: 0.0838\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0804 - val_loss: 0.0819\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0800\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0782\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0771\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0755\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0744\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0732\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 950us/step - loss: 0.0711 - val_loss: 0.0722\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 989us/step - loss: 0.0703 - val_loss: 0.0714\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0706\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0699\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0680 - val_loss: 0.0689\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0674 - val_loss: 0.0682\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0676\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0661 - val_loss: 0.0670\n",
      "19/19 [==============================] - 0s 827us/step - loss: 0.0701\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4757 - val_loss: 0.2468\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2296 - val_loss: 0.1764\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1729 - val_loss: 0.1442\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1433 - val_loss: 0.1240\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1260 - val_loss: 0.1127\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1152 - val_loss: 0.1038\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1074 - val_loss: 0.0982\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1016 - val_loss: 0.0942\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0972 - val_loss: 0.0900\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.0871\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0904 - val_loss: 0.0844\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0879 - val_loss: 0.0824\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0856 - val_loss: 0.0805\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0836 - val_loss: 0.0789\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0775\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0760\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0748\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0776 - val_loss: 0.0739\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0764 - val_loss: 0.0729\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0754 - val_loss: 0.0722\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0710\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.0706\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.0696\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0687\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0683\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0703 - val_loss: 0.0677\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0697 - val_loss: 0.0669\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0664\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.0662\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0680 - val_loss: 0.0655\n",
      "19/19 [==============================] - 0s 805us/step - loss: 0.0707\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5305 - val_loss: 0.2947\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2353 - val_loss: 0.2117\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1748 - val_loss: 0.1728\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1454 - val_loss: 0.1506\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1280 - val_loss: 0.1368\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1164 - val_loss: 0.1260\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1084 - val_loss: 0.1179\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1022 - val_loss: 0.1124\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0974 - val_loss: 0.1070\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0935 - val_loss: 0.1029\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0904 - val_loss: 0.0995\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0876 - val_loss: 0.0970\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0852 - val_loss: 0.0940\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0833 - val_loss: 0.0919\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0815 - val_loss: 0.0905\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0879\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0786 - val_loss: 0.0862\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0772 - val_loss: 0.0847\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0832\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0819\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0807\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0731 - val_loss: 0.0798\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0785\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0774\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0706 - val_loss: 0.0770\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0700 - val_loss: 0.0757\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.0749\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.0742\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0734\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0727\n",
      "19/19 [==============================] - 0s 829us/step - loss: 0.0707\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3990 - val_loss: 0.2313\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2189 - val_loss: 0.1701\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1699 - val_loss: 0.1415\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1459 - val_loss: 0.1250\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1315 - val_loss: 0.1153\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1218 - val_loss: 0.1075\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1144 - val_loss: 0.1019\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1086 - val_loss: 0.0978\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1037 - val_loss: 0.0950\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0998 - val_loss: 0.0913\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0963 - val_loss: 0.0888\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0934 - val_loss: 0.0867\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0908 - val_loss: 0.0846\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.0828\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0865 - val_loss: 0.0813\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0846 - val_loss: 0.0806\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0786\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0815 - val_loss: 0.0780\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0802 - val_loss: 0.0763\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0754\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0776 - val_loss: 0.0743\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0736\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0729\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0747 - val_loss: 0.0721\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0714\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0730 - val_loss: 0.0707\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0701\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.0699\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0689\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0703 - val_loss: 0.0684\n",
      "19/19 [==============================] - 0s 773us/step - loss: 0.0681\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7030 - val_loss: 0.3552\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2915 - val_loss: 0.2314\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2107 - val_loss: 0.1862\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1753 - val_loss: 0.1634\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1550 - val_loss: 0.1483\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1418 - val_loss: 0.1392\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1323 - val_loss: 0.1292\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1249 - val_loss: 0.1224\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1187 - val_loss: 0.1169\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1136 - val_loss: 0.1120\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1092 - val_loss: 0.1076\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1054 - val_loss: 0.1039\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1020 - val_loss: 0.1006\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0991 - val_loss: 0.0979\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0964 - val_loss: 0.0950\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0940 - val_loss: 0.0926\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.0906\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.0885\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0881 - val_loss: 0.0866\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0865 - val_loss: 0.0856\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.0832\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0837 - val_loss: 0.0817\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0804\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0793\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0788\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.0768\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0778 - val_loss: 0.0763\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.0755\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0762 - val_loss: 0.0738\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.0730\n",
      "19/19 [==============================] - 0s 882us/step - loss: 0.1098\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5965 - val_loss: 0.3184\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 0.2280\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2112 - val_loss: 0.1903\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1772 - val_loss: 0.1670\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1562 - val_loss: 0.1523\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1419 - val_loss: 0.1385\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1309 - val_loss: 0.1300\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1230 - val_loss: 0.1238\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1162 - val_loss: 0.1174\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1109 - val_loss: 0.1125\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1062 - val_loss: 0.1101\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1025 - val_loss: 0.1055\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0990 - val_loss: 0.1013\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0959 - val_loss: 0.0986\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0934 - val_loss: 0.0959\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0910 - val_loss: 0.0936\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0889 - val_loss: 0.0914\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0870 - val_loss: 0.0899\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0885\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0836 - val_loss: 0.0864\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0862\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0843\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0797 - val_loss: 0.0825\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0817\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0776 - val_loss: 0.0803\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0797\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0758 - val_loss: 0.0785\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0748 - val_loss: 0.0777\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0779\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0763\n",
      "19/19 [==============================] - 0s 816us/step - loss: 0.0723\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6116 - val_loss: 0.3552\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2723 - val_loss: 0.2236\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1895 - val_loss: 0.1760\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1548 - val_loss: 0.1511\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1359 - val_loss: 0.1369\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1244 - val_loss: 0.1259\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1160 - val_loss: 0.1184\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1100 - val_loss: 0.1126\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1051 - val_loss: 0.1077\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1010 - val_loss: 0.1036\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0976 - val_loss: 0.0999\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0947 - val_loss: 0.0977\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.0942\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0897 - val_loss: 0.0918\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0877 - val_loss: 0.0905\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0858 - val_loss: 0.0875\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0841 - val_loss: 0.0861\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0826 - val_loss: 0.0842\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0826\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0816\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0800\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0776 - val_loss: 0.0790\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0784\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0768\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0747 - val_loss: 0.0760\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0738 - val_loss: 0.0753\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0730 - val_loss: 0.0744\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0737\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.0728\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0720\n",
      "19/19 [==============================] - 0s 836us/step - loss: 0.0775\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.8055 - val_loss: 0.3965\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3280 - val_loss: 0.2276\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2161 - val_loss: 0.1670\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1686 - val_loss: 0.1362\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1430 - val_loss: 0.1185\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1268 - val_loss: 0.1073\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1160 - val_loss: 0.0997\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1082 - val_loss: 0.0941\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1022 - val_loss: 0.0900\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0975 - val_loss: 0.0867\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0938 - val_loss: 0.0840\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0906 - val_loss: 0.0818\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0880 - val_loss: 0.0799\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0857 - val_loss: 0.0786\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0837 - val_loss: 0.0769\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0820 - val_loss: 0.0756\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0805 - val_loss: 0.0745\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.0735\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0778 - val_loss: 0.0726\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0717\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0709\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0704\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0696\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0690\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0684\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0680\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.0673\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0701 - val_loss: 0.0670\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0664\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0661\n",
      "19/19 [==============================] - 0s 810us/step - loss: 0.0648\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.2144 - val_loss: 0.5236\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.4126 - val_loss: 0.2888\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2506 - val_loss: 0.1964\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1802 - val_loss: 0.1500\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1433 - val_loss: 0.1240\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1217 - val_loss: 0.1081\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1081 - val_loss: 0.0978\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0989 - val_loss: 0.0906\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0924 - val_loss: 0.0854\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0876 - val_loss: 0.0815\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0839 - val_loss: 0.0786\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0761\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0786 - val_loss: 0.0741\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0765 - val_loss: 0.0724\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0749 - val_loss: 0.0710\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.0697\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0686\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0677\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0700 - val_loss: 0.0667\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0659\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0683 - val_loss: 0.0652\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.0645\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0669 - val_loss: 0.0639\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0662 - val_loss: 0.0633\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0657 - val_loss: 0.0628\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0651 - val_loss: 0.0623\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0646 - val_loss: 0.0619\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0642 - val_loss: 0.0615\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.0611\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0634 - val_loss: 0.0607\n",
      "19/19 [==============================] - 0s 883us/step - loss: 0.0616\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5946 - val_loss: 0.3685\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3004 - val_loss: 0.2470\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2191 - val_loss: 0.1972\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1795 - val_loss: 0.1704\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1568 - val_loss: 0.1515\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1405 - val_loss: 0.1375\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1289 - val_loss: 0.1274\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1199 - val_loss: 0.1193\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1126 - val_loss: 0.1126\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1071 - val_loss: 0.1073\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1023 - val_loss: 0.1029\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0982 - val_loss: 0.0992\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0950 - val_loss: 0.0962\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.0931\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0892 - val_loss: 0.0903\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.0879\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0859\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0841\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0826\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0810\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0786 - val_loss: 0.0795\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0774 - val_loss: 0.0784\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.0772\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0763\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0751\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0741\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0724 - val_loss: 0.0733\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0724\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0716\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0710\n",
      "19/19 [==============================] - 0s 800us/step - loss: 0.0755\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.8470 - val_loss: 0.3458\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2584 - val_loss: 0.2122\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1845 - val_loss: 0.1642\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1524 - val_loss: 0.1404\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1349 - val_loss: 0.1250\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1235 - val_loss: 0.1151\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1154 - val_loss: 0.1076\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1090 - val_loss: 0.1019\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1041 - val_loss: 0.0969\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0999 - val_loss: 0.0935\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0964 - val_loss: 0.0897\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0934 - val_loss: 0.0866\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0906 - val_loss: 0.0851\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0882 - val_loss: 0.0818\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0862 - val_loss: 0.0803\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0843 - val_loss: 0.0785\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0826 - val_loss: 0.0764\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0811 - val_loss: 0.0748\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0797 - val_loss: 0.0736\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.0724\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0772 - val_loss: 0.0714\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.0703\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0692\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0694\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.0675\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.0669\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0660\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.0652\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.0652\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0640\n",
      "19/19 [==============================] - 0s 969us/step - loss: 0.0661\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5777 - val_loss: 0.2684\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2299 - val_loss: 0.1945\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1776 - val_loss: 0.1670\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1520 - val_loss: 0.1464\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1362 - val_loss: 0.1334\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1248 - val_loss: 0.1239\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1160 - val_loss: 0.1177\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1091 - val_loss: 0.1113\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1035 - val_loss: 0.1054\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0988 - val_loss: 0.1009\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0948 - val_loss: 0.0973\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0915 - val_loss: 0.0948\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.0913\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0859 - val_loss: 0.0890\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0837 - val_loss: 0.0868\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.0849\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0835\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0783 - val_loss: 0.0821\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.0804\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0790\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0779\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0771\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0770\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.0751\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.0741\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0697 - val_loss: 0.0733\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0728\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0724\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0677 - val_loss: 0.0714\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0670 - val_loss: 0.0707\n",
      "19/19 [==============================] - 0s 843us/step - loss: 0.0855\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6064 - val_loss: 0.2640\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2623 - val_loss: 0.1895\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1963 - val_loss: 0.1572\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1629 - val_loss: 0.1390\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1435 - val_loss: 0.1269\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1299 - val_loss: 0.1184\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1203 - val_loss: 0.1115\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1126 - val_loss: 0.1055\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1068 - val_loss: 0.1017\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1018 - val_loss: 0.0978\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0977 - val_loss: 0.0946\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0941 - val_loss: 0.0917\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.0898\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.0871\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0862 - val_loss: 0.0850\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0842 - val_loss: 0.0835\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0824 - val_loss: 0.0816\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0806\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0794 - val_loss: 0.0793\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.0782\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0770\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0758 - val_loss: 0.0760\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0748 - val_loss: 0.0750\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0742\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0730 - val_loss: 0.0735\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0726\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0715 - val_loss: 0.0721\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0714\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0701 - val_loss: 0.0708\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0701\n",
      "19/19 [==============================] - 0s 819us/step - loss: 0.0730\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4787 - val_loss: 0.2912\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2706 - val_loss: 0.2089\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2048 - val_loss: 0.1672\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1698 - val_loss: 0.1450\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1478 - val_loss: 0.1310\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1330 - val_loss: 0.1198\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1219 - val_loss: 0.1114\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1137 - val_loss: 0.1067\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1073 - val_loss: 0.0999\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1019 - val_loss: 0.0959\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0975 - val_loss: 0.0919\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0938 - val_loss: 0.0889\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0906 - val_loss: 0.0862\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0879 - val_loss: 0.0838\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0855 - val_loss: 0.0817\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0833 - val_loss: 0.0799\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0815 - val_loss: 0.0782\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0798 - val_loss: 0.0766\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0782 - val_loss: 0.0753\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0739\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0728\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0717\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.0709\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0724 - val_loss: 0.0700\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0715 - val_loss: 0.0691\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0686\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0676\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.0670\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.0663\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0658\n",
      "19/19 [==============================] - 0s 786us/step - loss: 0.0694\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4986 - val_loss: 0.3573\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2772 - val_loss: 0.2565\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2092 - val_loss: 0.2094\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1741 - val_loss: 0.1827\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1529 - val_loss: 0.1657\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1387 - val_loss: 0.1536\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1282 - val_loss: 0.1446\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1204 - val_loss: 0.1364\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1142 - val_loss: 0.1300\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1090 - val_loss: 0.1250\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1048 - val_loss: 0.1202\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1011 - val_loss: 0.1168\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0979 - val_loss: 0.1134\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0950 - val_loss: 0.1097\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0924 - val_loss: 0.1067\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.1044\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0881 - val_loss: 0.1016\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0862 - val_loss: 0.0996\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0844 - val_loss: 0.0981\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0961\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0815 - val_loss: 0.0946\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0802 - val_loss: 0.0931\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.0914\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0778 - val_loss: 0.0902\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0891\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0758 - val_loss: 0.0880\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0749 - val_loss: 0.0867\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0857\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.0846\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.0843\n",
      "19/19 [==============================] - 0s 797us/step - loss: 0.0929\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6426 - val_loss: 0.3339\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3026 - val_loss: 0.2271\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2144 - val_loss: 0.1780\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1705 - val_loss: 0.1499\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1446 - val_loss: 0.1318\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1277 - val_loss: 0.1191\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1158 - val_loss: 0.1100\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1070 - val_loss: 0.1024\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1003 - val_loss: 0.0969\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0952 - val_loss: 0.0925\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0909 - val_loss: 0.0891\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0876 - val_loss: 0.0859\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0847 - val_loss: 0.0832\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0807\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0801 - val_loss: 0.0788\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0783 - val_loss: 0.0769\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0754\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.0740\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0726\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0715\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0705\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0696\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0700 - val_loss: 0.0688\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.0680\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.0672\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0666\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0672 - val_loss: 0.0661\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0654\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.0648\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0655 - val_loss: 0.0643\n",
      "19/19 [==============================] - 0s 781us/step - loss: 0.0674\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5703 - val_loss: 0.2887\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3115 - val_loss: 0.2108\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2301 - val_loss: 0.1776\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1890 - val_loss: 0.1523\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1638 - val_loss: 0.1378\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1464 - val_loss: 0.1272\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1339 - val_loss: 0.1188\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1244 - val_loss: 0.1126\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1171 - val_loss: 0.1076\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1111 - val_loss: 0.1034\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1061 - val_loss: 0.0992\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1022 - val_loss: 0.0956\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0987 - val_loss: 0.0927\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0956 - val_loss: 0.0902\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.0879\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0906 - val_loss: 0.0859\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.0841\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0867 - val_loss: 0.0825\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.0808\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0835 - val_loss: 0.0794\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0821 - val_loss: 0.0781\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0769\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0797 - val_loss: 0.0758\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0786 - val_loss: 0.0748\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0776 - val_loss: 0.0738\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0731\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0721\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0749 - val_loss: 0.0713\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0705\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.0698\n",
      "19/19 [==============================] - 0s 786us/step - loss: 0.0772\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5655 - val_loss: 0.3202\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3030 - val_loss: 0.2215\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2155 - val_loss: 0.1760\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1722 - val_loss: 0.1497\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1468 - val_loss: 0.1335\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1303 - val_loss: 0.1217\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1184 - val_loss: 0.1131\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1102 - val_loss: 0.1058\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1034 - val_loss: 0.1009\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0980 - val_loss: 0.0960\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0936 - val_loss: 0.0922\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.0895\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0873 - val_loss: 0.0867\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0846\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0826 - val_loss: 0.0824\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0808\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.0789\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0774 - val_loss: 0.0777\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.0759\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0748 - val_loss: 0.0745\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0738 - val_loss: 0.0735\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0726\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0716\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0708\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0700\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0696\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0687\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0683 - val_loss: 0.0680\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0677 - val_loss: 0.0677\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0671 - val_loss: 0.0671\n",
      "19/19 [==============================] - 0s 854us/step - loss: 0.0661\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.8846 - val_loss: 0.4102\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3359 - val_loss: 0.2799\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2475 - val_loss: 0.2229\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2064 - val_loss: 0.1903\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1808 - val_loss: 0.1692\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1625 - val_loss: 0.1544\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1496 - val_loss: 0.1436\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1391 - val_loss: 0.1348\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1302 - val_loss: 0.1278\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1230 - val_loss: 0.1214\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1171 - val_loss: 0.1166\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1119 - val_loss: 0.1121\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1073 - val_loss: 0.1082\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1034 - val_loss: 0.1045\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1000 - val_loss: 0.1014\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0968 - val_loss: 0.0990\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0941 - val_loss: 0.0966\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0916 - val_loss: 0.0942\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0893 - val_loss: 0.0919\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0873 - val_loss: 0.0900\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0854 - val_loss: 0.0881\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0837 - val_loss: 0.0865\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0822 - val_loss: 0.0852\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0838\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0824\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.0811\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0770 - val_loss: 0.0803\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0794\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0749 - val_loss: 0.0783\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0776\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0693\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.8423 - val_loss: 0.4061\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3384 - val_loss: 0.2451\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2218 - val_loss: 0.1867\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1747 - val_loss: 0.1563\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1497 - val_loss: 0.1393\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1339 - val_loss: 0.1275\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1229 - val_loss: 0.1192\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1149 - val_loss: 0.1128\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1085 - val_loss: 0.1075\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1033 - val_loss: 0.1035\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0991 - val_loss: 0.0998\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0956 - val_loss: 0.0969\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0926 - val_loss: 0.0943\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.0921\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0877 - val_loss: 0.0901\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0857 - val_loss: 0.0882\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0840 - val_loss: 0.0866\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0852\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0838\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.0826\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.0814\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.0804\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0763 - val_loss: 0.0794\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.0785\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0777\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0768\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0761\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0753\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0715 - val_loss: 0.0747\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.0742\n",
      "19/19 [==============================] - 0s 831us/step - loss: 0.0762\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6064 - val_loss: 0.3124\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2541 - val_loss: 0.2081\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1788 - val_loss: 0.1611\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1466 - val_loss: 0.1388\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1286 - val_loss: 0.1246\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1172 - val_loss: 0.1148\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1091 - val_loss: 0.1081\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1027 - val_loss: 0.1020\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0977 - val_loss: 0.0977\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0935 - val_loss: 0.0937\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.0908\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0872 - val_loss: 0.0878\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0846 - val_loss: 0.0854\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.0835\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0816\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0798\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0784\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0768\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0757\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0745\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0735\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0726\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.0717\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0709\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0703\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0683 - val_loss: 0.0695\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0689\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0670 - val_loss: 0.0682\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0664 - val_loss: 0.0682\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.0672\n",
      "19/19 [==============================] - 0s 984us/step - loss: 0.0647\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7762 - val_loss: 0.4467\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.2958\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2616 - val_loss: 0.2268\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2054 - val_loss: 0.1873\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1716 - val_loss: 0.1610\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1503 - val_loss: 0.1450\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1354 - val_loss: 0.1323\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1248 - val_loss: 0.1239\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1166 - val_loss: 0.1173\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1102 - val_loss: 0.1124\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1050 - val_loss: 0.1072\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1007 - val_loss: 0.1026\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0971 - val_loss: 0.0998\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0940 - val_loss: 0.0966\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0913 - val_loss: 0.0941\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.0919\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0900\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 925us/step - loss: 0.0850 - val_loss: 0.0887\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0833 - val_loss: 0.0867\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0853\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0804 - val_loss: 0.0839\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0792 - val_loss: 0.0827\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0820\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.0806\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0758 - val_loss: 0.0797\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0749 - val_loss: 0.0789\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0779\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0772\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0765\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0757\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0720\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4863 - val_loss: 0.2768\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2627 - val_loss: 0.2071\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2052 - val_loss: 0.1752\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1751 - val_loss: 0.1559\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1555 - val_loss: 0.1420\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1413 - val_loss: 0.1331\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1305 - val_loss: 0.1234\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1223 - val_loss: 0.1164\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1157 - val_loss: 0.1109\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1101 - val_loss: 0.1065\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1054 - val_loss: 0.1026\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1014 - val_loss: 0.0993\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0979 - val_loss: 0.0960\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0949 - val_loss: 0.0934\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0919 - val_loss: 0.0911\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0896 - val_loss: 0.0894\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0875 - val_loss: 0.0871\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0854 - val_loss: 0.0855\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0836 - val_loss: 0.0839\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0820 - val_loss: 0.0827\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0811\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0792 - val_loss: 0.0799\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0778 - val_loss: 0.0788\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0777\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0768\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0759\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0751\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0743\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0735\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.0728\n",
      "19/19 [==============================] - 0s 842us/step - loss: 0.0746\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7023 - val_loss: 0.2505\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2319 - val_loss: 0.1736\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1644 - val_loss: 0.1442\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1385 - val_loss: 0.1276\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1241 - val_loss: 0.1183\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1145 - val_loss: 0.1094\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1075 - val_loss: 0.1035\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1017 - val_loss: 0.0981\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0972 - val_loss: 0.0942\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0933 - val_loss: 0.0906\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.0876\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0873 - val_loss: 0.0855\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0830\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0827 - val_loss: 0.0809\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0794\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0791 - val_loss: 0.0778\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0776 - val_loss: 0.0763\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0762 - val_loss: 0.0749\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0739\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0726\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0720\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0705\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0697\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0701 - val_loss: 0.0696\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0694 - val_loss: 0.0681\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0676\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0668\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.0663\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0669 - val_loss: 0.0658\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0664 - val_loss: 0.0649\n",
      "19/19 [==============================] - 0s 802us/step - loss: 0.0638\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4704 - val_loss: 0.2560\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2624 - val_loss: 0.1840\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1907 - val_loss: 0.1507\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1543 - val_loss: 0.1309\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1336 - val_loss: 0.1195\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1203 - val_loss: 0.1110\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1110 - val_loss: 0.1051\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1043 - val_loss: 0.1004\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0989 - val_loss: 0.0968\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0950 - val_loss: 0.0940\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0916 - val_loss: 0.0912\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0887 - val_loss: 0.0891\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0864 - val_loss: 0.0869\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0843 - val_loss: 0.0853\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0824 - val_loss: 0.0840\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0808 - val_loss: 0.0827\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0794 - val_loss: 0.0811\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0798\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.0787\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0780\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0747 - val_loss: 0.0770\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0738 - val_loss: 0.0760\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0730 - val_loss: 0.0751\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0744\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0736\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0732\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0700 - val_loss: 0.0726\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0717\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0689 - val_loss: 0.0712\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0707\n",
      "19/19 [==============================] - 0s 829us/step - loss: 0.0697\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6452 - val_loss: 0.4149\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.2792\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2468 - val_loss: 0.2188\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2052 - val_loss: 0.1904\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1788 - val_loss: 0.1702\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1616 - val_loss: 0.1550\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1485 - val_loss: 0.1441\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1382 - val_loss: 0.1351\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1311 - val_loss: 0.1294\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1243 - val_loss: 0.1215\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1189 - val_loss: 0.1173\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1146 - val_loss: 0.1123\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1105 - val_loss: 0.1099\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1073 - val_loss: 0.1056\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1040 - val_loss: 0.1024\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1011 - val_loss: 0.1000\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0986 - val_loss: 0.0978\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0963 - val_loss: 0.0952\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0943 - val_loss: 0.0949\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0925 - val_loss: 0.0918\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0907 - val_loss: 0.0900\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.0905\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0876 - val_loss: 0.0870\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0861 - val_loss: 0.0853\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0846\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0837 - val_loss: 0.0831\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0826 - val_loss: 0.0835\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0816 - val_loss: 0.0809\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0805 - val_loss: 0.0801\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0793\n",
      "19/19 [==============================] - 0s 777us/step - loss: 0.0889\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9051 - val_loss: 0.4102\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.3331 - val_loss: 0.2656\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2304 - val_loss: 0.2095\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1878 - val_loss: 0.1795\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1630 - val_loss: 0.1594\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1462 - val_loss: 0.1441\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1337 - val_loss: 0.1329\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1240 - val_loss: 0.1239\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1164 - val_loss: 0.1167\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1100 - val_loss: 0.1112\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1048 - val_loss: 0.1061\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1003 - val_loss: 0.1021\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0965 - val_loss: 0.0983\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0931 - val_loss: 0.0952\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0903 - val_loss: 0.0921\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0877 - val_loss: 0.0897\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0855 - val_loss: 0.0874\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0834 - val_loss: 0.0857\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0816 - val_loss: 0.0840\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0823\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.0808\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0794\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0758 - val_loss: 0.0782\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0772\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0761\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0751\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0742\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0734\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0726\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0719\n",
      "19/19 [==============================] - 0s 854us/step - loss: 0.0706\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5451 - val_loss: 0.3477\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2646 - val_loss: 0.2287\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1938 - val_loss: 0.1792\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1612 - val_loss: 0.1513\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1415 - val_loss: 0.1336\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1286 - val_loss: 0.1216\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1191 - val_loss: 0.1127\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1117 - val_loss: 0.1056\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1060 - val_loss: 0.1001\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1011 - val_loss: 0.0951\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0970 - val_loss: 0.0913\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0935 - val_loss: 0.0880\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0904 - val_loss: 0.0852\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0879 - val_loss: 0.0829\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0856 - val_loss: 0.0809\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0836 - val_loss: 0.0787\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0770\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0801 - val_loss: 0.0757\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.0742\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.0730\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0717\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0749 - val_loss: 0.0707\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0698\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0689\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.0680\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0674\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0703 - val_loss: 0.0666\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0697 - val_loss: 0.0666\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0657\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0648\n",
      "19/19 [==============================] - 0s 790us/step - loss: 0.0669\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6091 - val_loss: 0.2968\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2589 - val_loss: 0.2056\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1926 - val_loss: 0.1692\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1621 - val_loss: 0.1482\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1439 - val_loss: 0.1349\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1317 - val_loss: 0.1252\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1232 - val_loss: 0.1182\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1163 - val_loss: 0.1121\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1108 - val_loss: 0.1073\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1063 - val_loss: 0.1032\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1023 - val_loss: 0.0994\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0988 - val_loss: 0.0962\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0958 - val_loss: 0.0938\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0932 - val_loss: 0.0909\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0907 - val_loss: 0.0888\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0886 - val_loss: 0.0869\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0867 - val_loss: 0.0849\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0849 - val_loss: 0.0832\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0831 - val_loss: 0.0818\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0803\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0804 - val_loss: 0.0792\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0792 - val_loss: 0.0778\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0770\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0770 - val_loss: 0.0758\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0748\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0739\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0732\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.0724\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0716\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.0709\n",
      "19/19 [==============================] - 0s 809us/step - loss: 0.1192\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7587 - val_loss: 0.3632\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2823 - val_loss: 0.2284\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.2030 - val_loss: 0.1769\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1676 - val_loss: 0.1518\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1479 - val_loss: 0.1369\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1351 - val_loss: 0.1272\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1261 - val_loss: 0.1197\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1187 - val_loss: 0.1139\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1129 - val_loss: 0.1096\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1082 - val_loss: 0.1057\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1041 - val_loss: 0.1012\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.1007 - val_loss: 0.0987\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0976 - val_loss: 0.0958\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0948 - val_loss: 0.0939\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0924 - val_loss: 0.0909\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0903 - val_loss: 0.0897\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0883 - val_loss: 0.0877\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0866 - val_loss: 0.0859\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.0847\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0835 - val_loss: 0.0832\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0821 - val_loss: 0.0821\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0808 - val_loss: 0.0809\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0798\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0793\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.0782\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0765 - val_loss: 0.0771\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0763\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0747 - val_loss: 0.0758\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0751\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0743\n",
      "19/19 [==============================] - 0s 993us/step - loss: 0.0710\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x153c8d278>, as the constructor either does not set or modifies parameter learning_rate",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-2c69256d6bf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m rnd_search_cv.fit(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVAL_SPLIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 762\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     97\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x153c8d278>, as the constructor either does not set or modifies parameter learning_rate"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "rnd_search_cv.fit(\n",
    "    X_train, y_train, epochs=EPOCHS, validation_split=VAL_SPLIT, callbacks=[EarlyStopping(patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_points = 7500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.6 ms, sys: 5.05 ms, total: 67.7 ms\n",
      "Wall time: 97.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total = len(trim_df4)\n",
    "for col in trim_df4.columns.tolist():\n",
    "    if col in code_cols:\n",
    "        counts = trim_df4[col].value_counts()\n",
    "        choices = list(counts.index)\n",
    "        weights = [count/total for count in counts.values]\n",
    "        new_data[col] = np.random.choice(\n",
    "            a=choices, p=weights, size=(new_data_points,)\n",
    "        )\n",
    "    else:\n",
    "        new_data[col] = np.random.normal(\n",
    "            loc=trim_df4[col].mean(), scale=trim_df4[col].std(), size=new_data_points\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admitted</th>\n",
       "      <th>Age</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pulse_ox</th>\n",
       "      <th>resp_rate</th>\n",
       "      <th>cbc_wbc</th>\n",
       "      <th>cbc_hematocrit</th>\n",
       "      <th>cbc_hemoglobin</th>\n",
       "      <th>...</th>\n",
       "      <th>cmp_alt</th>\n",
       "      <th>cmp_ast</th>\n",
       "      <th>cmp_alkaline_phosphatase</th>\n",
       "      <th>cmp_total_protein</th>\n",
       "      <th>cmp_albumin</th>\n",
       "      <th>cmp_bilirubin</th>\n",
       "      <th>COVIDResult_Encoded</th>\n",
       "      <th>FirstRace_Encoded</th>\n",
       "      <th>Ethnicity_Encoded</th>\n",
       "      <th>Sex_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>78.438444</td>\n",
       "      <td>73.277885</td>\n",
       "      <td>156.881486</td>\n",
       "      <td>76.346841</td>\n",
       "      <td>97.711297</td>\n",
       "      <td>18.817744</td>\n",
       "      <td>15.862348</td>\n",
       "      <td>45.024476</td>\n",
       "      <td>11.500963</td>\n",
       "      <td>...</td>\n",
       "      <td>136.648429</td>\n",
       "      <td>129.490561</td>\n",
       "      <td>67.069754</td>\n",
       "      <td>7.851282</td>\n",
       "      <td>4.570266</td>\n",
       "      <td>1.280431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>52.772321</td>\n",
       "      <td>100.576372</td>\n",
       "      <td>154.224812</td>\n",
       "      <td>79.056662</td>\n",
       "      <td>97.471674</td>\n",
       "      <td>31.451582</td>\n",
       "      <td>12.083587</td>\n",
       "      <td>29.666454</td>\n",
       "      <td>15.946343</td>\n",
       "      <td>...</td>\n",
       "      <td>256.838327</td>\n",
       "      <td>-89.741361</td>\n",
       "      <td>218.627968</td>\n",
       "      <td>7.188622</td>\n",
       "      <td>2.871096</td>\n",
       "      <td>3.502710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>64.131080</td>\n",
       "      <td>79.989263</td>\n",
       "      <td>110.997963</td>\n",
       "      <td>57.555526</td>\n",
       "      <td>93.152107</td>\n",
       "      <td>33.090349</td>\n",
       "      <td>5.980147</td>\n",
       "      <td>33.124933</td>\n",
       "      <td>10.481041</td>\n",
       "      <td>...</td>\n",
       "      <td>-238.210894</td>\n",
       "      <td>169.635051</td>\n",
       "      <td>171.204837</td>\n",
       "      <td>6.135956</td>\n",
       "      <td>2.600180</td>\n",
       "      <td>2.271566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>50.906483</td>\n",
       "      <td>88.074400</td>\n",
       "      <td>135.935841</td>\n",
       "      <td>64.949152</td>\n",
       "      <td>102.002380</td>\n",
       "      <td>24.481826</td>\n",
       "      <td>11.416264</td>\n",
       "      <td>41.283126</td>\n",
       "      <td>9.271202</td>\n",
       "      <td>...</td>\n",
       "      <td>99.095210</td>\n",
       "      <td>43.246308</td>\n",
       "      <td>-91.439342</td>\n",
       "      <td>7.727635</td>\n",
       "      <td>3.959345</td>\n",
       "      <td>0.223195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7.751812</td>\n",
       "      <td>118.415307</td>\n",
       "      <td>153.297936</td>\n",
       "      <td>84.453330</td>\n",
       "      <td>87.529000</td>\n",
       "      <td>10.295213</td>\n",
       "      <td>16.778923</td>\n",
       "      <td>30.264456</td>\n",
       "      <td>13.196143</td>\n",
       "      <td>...</td>\n",
       "      <td>215.307924</td>\n",
       "      <td>92.267308</td>\n",
       "      <td>98.727583</td>\n",
       "      <td>6.907905</td>\n",
       "      <td>3.153272</td>\n",
       "      <td>-1.888499</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Admitted        Age  heart_rate         sbp        dbp    pulse_ox  \\\n",
       "0         0  78.438444   73.277885  156.881486  76.346841   97.711297   \n",
       "1         1  52.772321  100.576372  154.224812  79.056662   97.471674   \n",
       "2         1  64.131080   79.989263  110.997963  57.555526   93.152107   \n",
       "3         1  50.906483   88.074400  135.935841  64.949152  102.002380   \n",
       "4         0   7.751812  118.415307  153.297936  84.453330   87.529000   \n",
       "\n",
       "   resp_rate    cbc_wbc  cbc_hematocrit  cbc_hemoglobin  ...     cmp_alt  \\\n",
       "0  18.817744  15.862348       45.024476       11.500963  ...  136.648429   \n",
       "1  31.451582  12.083587       29.666454       15.946343  ...  256.838327   \n",
       "2  33.090349   5.980147       33.124933       10.481041  ... -238.210894   \n",
       "3  24.481826  11.416264       41.283126        9.271202  ...   99.095210   \n",
       "4  10.295213  16.778923       30.264456       13.196143  ...  215.307924   \n",
       "\n",
       "      cmp_ast  cmp_alkaline_phosphatase  cmp_total_protein  cmp_albumin  \\\n",
       "0  129.490561                 67.069754           7.851282     4.570266   \n",
       "1  -89.741361                218.627968           7.188622     2.871096   \n",
       "2  169.635051                171.204837           6.135956     2.600180   \n",
       "3   43.246308                -91.439342           7.727635     3.959345   \n",
       "4   92.267308                 98.727583           6.907905     3.153272   \n",
       "\n",
       "   cmp_bilirubin  COVIDResult_Encoded  FirstRace_Encoded  Ethnicity_Encoded  \\\n",
       "0       1.280431                  1.0                9.0                2.0   \n",
       "1       3.502710                  1.0                0.0                2.0   \n",
       "2       2.271566                  1.0                9.0                2.0   \n",
       "3       0.223195                  1.0                5.0                2.0   \n",
       "4      -1.888499                  1.0                0.0                2.0   \n",
       "\n",
       "   Sex_Encoded  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          1.0  \n",
       "3          0.0  \n",
       "4          1.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 36)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admitted</th>\n",
       "      <th>Age</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pulse_ox</th>\n",
       "      <th>resp_rate</th>\n",
       "      <th>cbc_wbc</th>\n",
       "      <th>cbc_hematocrit</th>\n",
       "      <th>cbc_hemoglobin</th>\n",
       "      <th>...</th>\n",
       "      <th>cmp_alt</th>\n",
       "      <th>cmp_ast</th>\n",
       "      <th>cmp_alkaline_phosphatase</th>\n",
       "      <th>cmp_total_protein</th>\n",
       "      <th>cmp_albumin</th>\n",
       "      <th>cmp_bilirubin</th>\n",
       "      <th>COVIDResult_Encoded</th>\n",
       "      <th>FirstRace_Encoded</th>\n",
       "      <th>Ethnicity_Encoded</th>\n",
       "      <th>Sex_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.401467</td>\n",
       "      <td>48.977792</td>\n",
       "      <td>94.827625</td>\n",
       "      <td>135.892879</td>\n",
       "      <td>75.739349</td>\n",
       "      <td>97.112193</td>\n",
       "      <td>21.021449</td>\n",
       "      <td>10.180191</td>\n",
       "      <td>38.709594</td>\n",
       "      <td>12.657374</td>\n",
       "      <td>...</td>\n",
       "      <td>43.346349</td>\n",
       "      <td>53.967180</td>\n",
       "      <td>114.207521</td>\n",
       "      <td>7.209553</td>\n",
       "      <td>3.852652</td>\n",
       "      <td>0.859927</td>\n",
       "      <td>0.935733</td>\n",
       "      <td>6.612133</td>\n",
       "      <td>1.952000</td>\n",
       "      <td>0.496933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.490228</td>\n",
       "      <td>23.559729</td>\n",
       "      <td>23.501569</td>\n",
       "      <td>26.710879</td>\n",
       "      <td>15.456168</td>\n",
       "      <td>3.810889</td>\n",
       "      <td>6.676661</td>\n",
       "      <td>7.426270</td>\n",
       "      <td>6.247412</td>\n",
       "      <td>2.202478</td>\n",
       "      <td>...</td>\n",
       "      <td>144.131031</td>\n",
       "      <td>124.924238</td>\n",
       "      <td>76.709748</td>\n",
       "      <td>0.698645</td>\n",
       "      <td>0.495229</td>\n",
       "      <td>1.468927</td>\n",
       "      <td>0.245244</td>\n",
       "      <td>3.757602</td>\n",
       "      <td>0.353807</td>\n",
       "      <td>0.501356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-43.299418</td>\n",
       "      <td>4.645046</td>\n",
       "      <td>36.969653</td>\n",
       "      <td>8.107169</td>\n",
       "      <td>83.177313</td>\n",
       "      <td>-7.884580</td>\n",
       "      <td>-14.911363</td>\n",
       "      <td>12.743121</td>\n",
       "      <td>4.147882</td>\n",
       "      <td>...</td>\n",
       "      <td>-456.295836</td>\n",
       "      <td>-423.734074</td>\n",
       "      <td>-166.816802</td>\n",
       "      <td>4.381355</td>\n",
       "      <td>1.663546</td>\n",
       "      <td>-4.490048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.173811</td>\n",
       "      <td>78.937922</td>\n",
       "      <td>117.194061</td>\n",
       "      <td>65.222349</td>\n",
       "      <td>94.494904</td>\n",
       "      <td>16.599991</td>\n",
       "      <td>5.169603</td>\n",
       "      <td>34.438037</td>\n",
       "      <td>11.165448</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.885383</td>\n",
       "      <td>-29.196799</td>\n",
       "      <td>62.605715</td>\n",
       "      <td>6.740892</td>\n",
       "      <td>3.513387</td>\n",
       "      <td>-0.146897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.881006</td>\n",
       "      <td>94.947328</td>\n",
       "      <td>135.973359</td>\n",
       "      <td>75.781082</td>\n",
       "      <td>97.101627</td>\n",
       "      <td>21.075594</td>\n",
       "      <td>10.234808</td>\n",
       "      <td>38.742682</td>\n",
       "      <td>12.662030</td>\n",
       "      <td>...</td>\n",
       "      <td>43.459031</td>\n",
       "      <td>54.534232</td>\n",
       "      <td>115.042789</td>\n",
       "      <td>7.220184</td>\n",
       "      <td>3.846401</td>\n",
       "      <td>0.851475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.820759</td>\n",
       "      <td>110.976791</td>\n",
       "      <td>154.096438</td>\n",
       "      <td>86.363614</td>\n",
       "      <td>99.726895</td>\n",
       "      <td>25.484283</td>\n",
       "      <td>15.275722</td>\n",
       "      <td>42.942989</td>\n",
       "      <td>14.129651</td>\n",
       "      <td>...</td>\n",
       "      <td>141.954348</td>\n",
       "      <td>138.085115</td>\n",
       "      <td>165.442869</td>\n",
       "      <td>7.683667</td>\n",
       "      <td>4.183891</td>\n",
       "      <td>1.875452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>132.001000</td>\n",
       "      <td>198.928685</td>\n",
       "      <td>233.842087</td>\n",
       "      <td>132.739792</td>\n",
       "      <td>110.588693</td>\n",
       "      <td>43.928290</td>\n",
       "      <td>37.676143</td>\n",
       "      <td>60.304864</td>\n",
       "      <td>21.030687</td>\n",
       "      <td>...</td>\n",
       "      <td>587.019769</td>\n",
       "      <td>507.084156</td>\n",
       "      <td>397.237740</td>\n",
       "      <td>9.660924</td>\n",
       "      <td>5.543099</td>\n",
       "      <td>6.153701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Admitted          Age   heart_rate          sbp          dbp  \\\n",
       "count  7500.000000  7500.000000  7500.000000  7500.000000  7500.000000   \n",
       "mean      0.401467    48.977792    94.827625   135.892879    75.739349   \n",
       "std       0.490228    23.559729    23.501569    26.710879    15.456168   \n",
       "min       0.000000   -43.299418     4.645046    36.969653     8.107169   \n",
       "25%       0.000000    33.173811    78.937922   117.194061    65.222349   \n",
       "50%       0.000000    48.881006    94.947328   135.973359    75.781082   \n",
       "75%       1.000000    64.820759   110.976791   154.096438    86.363614   \n",
       "max       1.000000   132.001000   198.928685   233.842087   132.739792   \n",
       "\n",
       "          pulse_ox    resp_rate      cbc_wbc  cbc_hematocrit  cbc_hemoglobin  \\\n",
       "count  7500.000000  7500.000000  7500.000000     7500.000000     7500.000000   \n",
       "mean     97.112193    21.021449    10.180191       38.709594       12.657374   \n",
       "std       3.810889     6.676661     7.426270        6.247412        2.202478   \n",
       "min      83.177313    -7.884580   -14.911363       12.743121        4.147882   \n",
       "25%      94.494904    16.599991     5.169603       34.438037       11.165448   \n",
       "50%      97.101627    21.075594    10.234808       38.742682       12.662030   \n",
       "75%      99.726895    25.484283    15.275722       42.942989       14.129651   \n",
       "max     110.588693    43.928290    37.676143       60.304864       21.030687   \n",
       "\n",
       "       ...      cmp_alt      cmp_ast  cmp_alkaline_phosphatase  \\\n",
       "count  ...  7500.000000  7500.000000               7500.000000   \n",
       "mean   ...    43.346349    53.967180                114.207521   \n",
       "std    ...   144.131031   124.924238                 76.709748   \n",
       "min    ...  -456.295836  -423.734074               -166.816802   \n",
       "25%    ...   -54.885383   -29.196799                 62.605715   \n",
       "50%    ...    43.459031    54.534232                115.042789   \n",
       "75%    ...   141.954348   138.085115                165.442869   \n",
       "max    ...   587.019769   507.084156                397.237740   \n",
       "\n",
       "       cmp_total_protein  cmp_albumin  cmp_bilirubin  COVIDResult_Encoded  \\\n",
       "count        7500.000000  7500.000000    7500.000000          7500.000000   \n",
       "mean            7.209553     3.852652       0.859927             0.935733   \n",
       "std             0.698645     0.495229       1.468927             0.245244   \n",
       "min             4.381355     1.663546      -4.490048             0.000000   \n",
       "25%             6.740892     3.513387      -0.146897             1.000000   \n",
       "50%             7.220184     3.846401       0.851475             1.000000   \n",
       "75%             7.683667     4.183891       1.875452             1.000000   \n",
       "max             9.660924     5.543099       6.153701             1.000000   \n",
       "\n",
       "       FirstRace_Encoded  Ethnicity_Encoded  Sex_Encoded  \n",
       "count        7500.000000        7500.000000  7500.000000  \n",
       "mean            6.612133           1.952000     0.496933  \n",
       "std             3.757602           0.353807     0.501356  \n",
       "min             0.000000           0.000000     0.000000  \n",
       "25%             5.000000           2.000000     0.000000  \n",
       "50%             9.000000           2.000000     0.000000  \n",
       "75%             9.000000           2.000000     1.000000  \n",
       "max             9.000000           4.000000     2.000000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = trim_df4.describe()\n",
    "fake = new_data.describe()\n",
    "fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_real = real.iloc[1]\n",
    "mean_fake = fake.iloc[1]\n",
    "std_real = real.iloc[2]\n",
    "std_fake = fake.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09163648391432695"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_real - mean_fake).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05858454513701034"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(std_real - std_fake).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([trim_df4, new_data], axis=0).reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admitted</th>\n",
       "      <th>Age</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pulse_ox</th>\n",
       "      <th>resp_rate</th>\n",
       "      <th>cbc_wbc</th>\n",
       "      <th>cbc_hematocrit</th>\n",
       "      <th>cbc_hemoglobin</th>\n",
       "      <th>...</th>\n",
       "      <th>cmp_alt</th>\n",
       "      <th>cmp_ast</th>\n",
       "      <th>cmp_alkaline_phosphatase</th>\n",
       "      <th>cmp_total_protein</th>\n",
       "      <th>cmp_albumin</th>\n",
       "      <th>cmp_bilirubin</th>\n",
       "      <th>COVIDResult_Encoded</th>\n",
       "      <th>FirstRace_Encoded</th>\n",
       "      <th>Ethnicity_Encoded</th>\n",
       "      <th>Sex_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>78.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.01</td>\n",
       "      <td>34.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.04</td>\n",
       "      <td>36.2</td>\n",
       "      <td>11.9</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>55.627858</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.13</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>106.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>32.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>55.627858</td>\n",
       "      <td>78.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.56</td>\n",
       "      <td>31.7</td>\n",
       "      <td>9.8</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>122.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Admitted   Age  heart_rate    sbp   dbp  pulse_ox  resp_rate  cbc_wbc  \\\n",
       "0         1  78.0        94.0  138.0  82.0      96.0       29.0    14.01   \n",
       "1         0  23.0       121.0  134.0  88.0      98.0       18.0     5.04   \n",
       "2         0  55.0        83.0  152.0  76.0      98.0       21.0     7.13   \n",
       "3         1  50.0        88.0  138.0  65.0      87.0       18.0     5.74   \n",
       "4         0  67.0        90.0  128.0  69.0      98.0       18.0    10.56   \n",
       "\n",
       "   cbc_hematocrit  cbc_hemoglobin  ...  cmp_alt    cmp_ast  \\\n",
       "0            34.1            11.0  ...     14.0  26.000000   \n",
       "1            36.2            11.9  ...     73.0  55.627858   \n",
       "2            36.0            12.0  ...     26.0  29.000000   \n",
       "3            32.9            11.6  ...     22.0  55.627858   \n",
       "4            31.7             9.8  ...     12.0  18.000000   \n",
       "\n",
       "   cmp_alkaline_phosphatase  cmp_total_protein  cmp_albumin  cmp_bilirubin  \\\n",
       "0                      80.0                8.5          4.3            0.5   \n",
       "1                     100.0                8.1          4.6            0.6   \n",
       "2                     106.0                7.1          4.0            0.7   \n",
       "3                      78.0                7.8          3.7            0.5   \n",
       "4                     122.0                7.4          3.5            0.2   \n",
       "\n",
       "   COVIDResult_Encoded  FirstRace_Encoded  Ethnicity_Encoded  Sex_Encoded  \n",
       "0                  1.0                9.0                2.0          0.0  \n",
       "1                  1.0                9.0                2.0          0.0  \n",
       "2                  1.0                0.0                2.0          1.0  \n",
       "3                  1.0                9.0                2.0          1.0  \n",
       "4                  1.0                0.0                2.0          0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14880, 36)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pulse_ox</th>\n",
       "      <th>resp_rate</th>\n",
       "      <th>cbc_wbc</th>\n",
       "      <th>cbc_hematocrit</th>\n",
       "      <th>cbc_hemoglobin</th>\n",
       "      <th>cbc_platelets</th>\n",
       "      <th>...</th>\n",
       "      <th>cmp_ast</th>\n",
       "      <th>cmp_alkaline_phosphatase</th>\n",
       "      <th>cmp_total_protein</th>\n",
       "      <th>cmp_albumin</th>\n",
       "      <th>cmp_bilirubin</th>\n",
       "      <th>Admitted</th>\n",
       "      <th>FirstRace_Encoded</th>\n",
       "      <th>Ethnicity_Encoded</th>\n",
       "      <th>Sex_Encoded</th>\n",
       "      <th>COVIDResult_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.232826</td>\n",
       "      <td>-0.029050</td>\n",
       "      <td>0.076388</td>\n",
       "      <td>0.398710</td>\n",
       "      <td>-0.285183</td>\n",
       "      <td>1.189659</td>\n",
       "      <td>0.517899</td>\n",
       "      <td>-0.729687</td>\n",
       "      <td>-0.747168</td>\n",
       "      <td>0.620033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231434</td>\n",
       "      <td>-0.444896</td>\n",
       "      <td>1.836084</td>\n",
       "      <td>0.910591</td>\n",
       "      <td>-0.239664</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.103498</td>\n",
       "      <td>1.124564</td>\n",
       "      <td>-0.072313</td>\n",
       "      <td>0.789975</td>\n",
       "      <td>0.238753</td>\n",
       "      <td>-0.451303</td>\n",
       "      <td>-0.697223</td>\n",
       "      <td>-0.392674</td>\n",
       "      <td>-0.340862</td>\n",
       "      <td>0.725198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006728</td>\n",
       "      <td>-0.184581</td>\n",
       "      <td>1.266752</td>\n",
       "      <td>1.516856</td>\n",
       "      <td>-0.171663</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.255818</td>\n",
       "      <td>-0.499041</td>\n",
       "      <td>0.596844</td>\n",
       "      <td>0.007445</td>\n",
       "      <td>0.238753</td>\n",
       "      <td>-0.003768</td>\n",
       "      <td>-0.414101</td>\n",
       "      <td>-0.424770</td>\n",
       "      <td>-0.295717</td>\n",
       "      <td>-0.084577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207319</td>\n",
       "      <td>-0.106487</td>\n",
       "      <td>-0.156580</td>\n",
       "      <td>0.304327</td>\n",
       "      <td>-0.103662</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043425</td>\n",
       "      <td>-0.285409</td>\n",
       "      <td>0.076388</td>\n",
       "      <td>-0.709874</td>\n",
       "      <td>-2.642894</td>\n",
       "      <td>-0.451303</td>\n",
       "      <td>-0.602397</td>\n",
       "      <td>-0.922266</td>\n",
       "      <td>-0.476298</td>\n",
       "      <td>-1.304499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006728</td>\n",
       "      <td>-0.470928</td>\n",
       "      <td>0.839752</td>\n",
       "      <td>-0.301937</td>\n",
       "      <td>-0.239664</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.765562</td>\n",
       "      <td>-0.199956</td>\n",
       "      <td>-0.295366</td>\n",
       "      <td>-0.449031</td>\n",
       "      <td>0.238753</td>\n",
       "      <td>-0.451303</td>\n",
       "      <td>0.050544</td>\n",
       "      <td>-1.114844</td>\n",
       "      <td>-1.288910</td>\n",
       "      <td>0.609516</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.295742</td>\n",
       "      <td>0.101765</td>\n",
       "      <td>0.270419</td>\n",
       "      <td>-0.706113</td>\n",
       "      <td>-0.443665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  heart_rate       sbp       dbp  pulse_ox  resp_rate   cbc_wbc  \\\n",
       "0  1.232826   -0.029050  0.076388  0.398710 -0.285183   1.189659  0.517899   \n",
       "1 -1.103498    1.124564 -0.072313  0.789975  0.238753  -0.451303 -0.697223   \n",
       "2  0.255818   -0.499041  0.596844  0.007445  0.238753  -0.003768 -0.414101   \n",
       "3  0.043425   -0.285409  0.076388 -0.709874 -2.642894  -0.451303 -0.602397   \n",
       "4  0.765562   -0.199956 -0.295366 -0.449031  0.238753  -0.451303  0.050544   \n",
       "\n",
       "   cbc_hematocrit  cbc_hemoglobin  cbc_platelets  ...   cmp_ast  \\\n",
       "0       -0.729687       -0.747168       0.620033  ... -0.231434   \n",
       "1       -0.392674       -0.340862       0.725198  ...  0.006728   \n",
       "2       -0.424770       -0.295717      -0.084577  ... -0.207319   \n",
       "3       -0.922266       -0.476298      -1.304499  ...  0.006728   \n",
       "4       -1.114844       -1.288910       0.609516  ... -0.295742   \n",
       "\n",
       "   cmp_alkaline_phosphatase  cmp_total_protein  cmp_albumin  cmp_bilirubin  \\\n",
       "0                 -0.444896           1.836084     0.910591      -0.239664   \n",
       "1                 -0.184581           1.266752     1.516856      -0.171663   \n",
       "2                 -0.106487          -0.156580     0.304327      -0.103662   \n",
       "3                 -0.470928           0.839752    -0.301937      -0.239664   \n",
       "4                  0.101765           0.270419    -0.706113      -0.443665   \n",
       "\n",
       "   Admitted  FirstRace_Encoded  Ethnicity_Encoded  Sex_Encoded  \\\n",
       "0         1                9.0                2.0          0.0   \n",
       "1         0                9.0                2.0          0.0   \n",
       "2         0                0.0                2.0          1.0   \n",
       "3         1                9.0                2.0          1.0   \n",
       "4         0                0.0                2.0          0.0   \n",
       "\n",
       "   COVIDResult_Encoded  \n",
       "0                  1.0  \n",
       "1                  1.0  \n",
       "2                  1.0  \n",
       "3                  1.0  \n",
       "4                  1.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes_df2 = new_df[code_cols]\n",
    "trim_df6 = new_df.drop(columns=code_cols)\n",
    "scaler2 = StandardScaler()\n",
    "scaled_df2 = pd.DataFrame(data=scaler2.fit_transform(trim_df6), columns=trim_df6.columns.tolist())\n",
    "merged_df2 = pd.concat([scaled_df2, codes_df2], axis=1)\n",
    "merged_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2, test2 = train_test_split(merged_df2, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data2 = merged_df2.copy()\n",
    "final_train2 = train2.copy()\n",
    "final_test2 = test2.copy()\n",
    "target = 'COVIDResult_Encoded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    11150\n",
      "0.0      754\n",
      "Name: COVIDResult_Encoded, dtype: int64\n",
      "1.0    2778\n",
      "0.0     198\n",
      "Name: COVIDResult_Encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(final_train2[target].value_counts())\n",
    "print(final_test2[target].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = final_train2.loc[:, final_train2.columns != target]\n",
    "y_train2 = final_train2[target]\n",
    "\n",
    "X_test2 = final_test2.loc[:, final_test2.columns != target]\n",
    "y_test2 = final_test2[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Model 1 – Sequential: Dense + Batch Normalization Layers, ReLU Activations"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Summary**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 35)                140       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               10500     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30000     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 42,442\n",
      "Trainable params: 41,572\n",
      "Non-trainable params: 870\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Training/Validation Loss and Accuracy**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Evaluation and Prediction**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.9294\n",
      "\n",
      "Loss: 25.15%\n",
      "Accuracy: 92.94%\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Metric Scores**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.94%\n",
      "Precision: 93.61%\n",
      "Recall: 99.21%\n",
      "F1: 96.33%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  10  188]\n",
      " [  22 2756]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Confusion Matrix**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Model 2 – Sequential: Dense Layers, ReLU Activation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Summary**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 35)                1260      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 216       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 1,490\n",
      "Trainable params: 1,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Training/Validation Loss and Accuracy**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Evaluation and Prediction**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 1ms/step - loss: 0.2416 - accuracy: 0.9335\n",
      "\n",
      "Loss: 24.16%\n",
      "Accuracy: 93.35%\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Metric Scores**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.35%\n",
      "Precision: 93.35%\n",
      "Recall: 100.00%\n",
      "F1: 96.56%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   0  198]\n",
      " [   0 2778]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Confusion Matrix**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Model 3 – Sequential: Dense Layers, PReLU Activation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Summary**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 35)                1260      \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              (None, 35)                35        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 216       \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 6)                 6         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 1,531\n",
      "Trainable params: 1,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Training/Validation Loss and Accuracy**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Evaluation and Prediction**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.9321\n",
      "\n",
      "Loss: 25.43%\n",
      "Accuracy: 93.21%\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Metric Scores**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.21%\n",
      "Precision: 93.37%\n",
      "Recall: 99.82%\n",
      "F1: 96.49%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   1  197]\n",
      " [   5 2773]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Confusion Matrix**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEGCAYAAACaSwWnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAg3klEQVR4nO3deZgV1bnv8e+vG1RUEHDAMYJKzNUMiBg15niICopxNno0Jo4BjUOiGR6Ix6Mmeo94okmMeoygOMUBcCReFec4J6AiIk5EMUKckUHBAXjvH7UaN9DD7u5d3buL38ennq69dlWt2nT79uq31qCIwMzMiqGmvW/AzMwqx0HdzKxAHNTNzArEQd3MrEAc1M3MCqRTe99AQz5ZjLvl2ErmL/q8vW/BqtAGXTurtdfost3JZcecRc9e0ur68uKWuplZgVRtS93MrE2pGG1cB3UzM4Ca2va+g4pwUDczA1DVpsmbxUHdzAycfjEzKxS31M3MCsQtdTOzAnFL3cysQNz7xcysQJx+MTMrEKdfzMwKxC11M7MCcVA3MyuQWj8oNTMrDufUzcwKxOkXM7MCcUvdzKxACtJSL8anMDNrLan8rdHLaDNJD0maLukFST9N5WdLmi1pStr2LjnnV5JmSHpZ0p4l5XulshmSRpTzMdxSNzODSk4TsBj4eUQ8I6kr8LSk+9J7v4+IC0oPlrQNcBiwLbAxcL+kL6e3LwUGAbOASZImRMT0xip3UDczg4qlXyLiLeCttL9A0ovAJo2csj9wU0R8CrwuaQbwzfTejIh4DUDSTenYRoO60y9mZtCs9IukYZIml2zD6r+kegPbAX9LRSdLmippjKQeqWwT4M2S02alsobKG+WgbmYGWUu9zC0iRkXEgJJt1EqXk9YGbgFOjYj5wGXAlkA/spb8hXl8DKdfzMygor1fJHUmC+jXR8StABHxTsn7o4E708vZwGYlp2+aymikvEFuqZuZQfagtNytEZIEXAm8GBG/KynfqOSwA4FpaX8CcJik1SX1AfoCfwcmAX0l9ZG0GtnD1AlNfQy31M3MoJKDj3YBfgg8L2lKKjsdOFxSPyCAmcDxABHxgqRxZA9AFwMnRcSS7JZ0MjARqAXGRMQLTX6MiKjUB6moTxZTnTdm7Wr+os/b+xasCm3QtXOrI3KXA68oO+Ysuu1HVTv81C11MzPwNAFmZkUiB3Uzs+JwUDczKxDVOKibmRWGW+pmZgXioG5mViAO6mZmRVKMmO6gbmYGbqmbmRVKTU0xpsJyUDczwy11M7NiKUZMd1A3MwO31M3MCsVB3cysQDxNgJlZgbilbmZWIA7qZmYF4qBuZlYgDupmZkVSjJjuoG5mBp4mwMysUJx+MTMrkmLEdAf1anbmGb/ikb8+TM+e63LrHXe29+1YGzvv12fwxGOP0KNHT64ddzsAM155iQvOO4dFCxey4cYbc+Y557PW2mtz7913cuN1Vy079x+vvsKVfx5P362/0k533/EUpaVejCRSQe1/wEFcdvkV7X0b1k6G7HsAF1z8p+XKzj/3LI4/+VSuGXsbuw7cfVkgHzxkH6664RauuuEWzvjNeWy08SYO6M0kqeytmjmoV7HtB+xAt3XWae/bsHbSr/8AunVb/vv/5htv0K//AAAG7LgzDz9430rn3T/xLnYfPKRN7rFIihLUc0m/SHoeiIbej4iv51GvWdH12XJLHv3rg+w6cHceuv9e3n3n7ZWOefDeezjvwovb4e46tqLM/ZJXS30fYF/gnrQdkba70lYvScMkTZY0+crRo3K6NbOOa8SZ53D7+Js47geHsmjhx3Tu3Hm591+YNpU11ujCFlv1bac77LjcUm9ERLwBIGlQRGxX8tYISc8AIxo4bxQwCuCTxQ239M1WVZv33oLfXToagH++MZMnH3tkufcfmHg3u+/p1EtLVHuwLlfeOXVJ2qXkxbfaoE6zwvpwzgcALF26lGuvvJz9Dz502XtLly7lofsnsofz6S0ilb9Vs7y7NB4HjJFU97RnLnBsznUWxvBf/IzJk/7O3LkfMmi3XfnxSadw0MGHtPdtWRs5+/Rf8uzTk5g3dy4H7b07xw47kUWLFnLr+JsA+Pfv7MHe+x247PjnnpnMBr02ZONNN2uvW+7QKtVSl7QZcC3Qi+zZ4qiIuEhST2As0BuYCRwaER8qq/giYG9gIXB0RDyTrnUUcEa69LkRcU2T9Ufkn+WoC+oRMa/cc5x+sfrMX/R5e9+CVaENunZudUTeevjEsmPOy+fv2WB9kjYCNoqIZyR1BZ4GDgCOBuZExEhJI4AeETFc0t7AKWRBfUfgoojYMf0SmAwMIPvl8DSwfUR82Ni95ZoKkdRL0pXATRExT9I2ko7Ls04zs5aoVPolIt6qa2lHxALgRWATYH+grqV9DVmgJ5VfG5mngO7pF8OewH0RMScF8vuAvZr6HHnnt68GJgIbp9evAKfmXKeZWbPV1KjsrbSnXtqG1XdNSb2B7YC/Ab0i4q301ttk6RnIAv6bJafNSmUNlTcq75z6ehExTtKvACJisaQlOddpZtZszUmpl/bUa/h6Whu4BTg1IuaX5uwjIiTlkmLOu6X+saR1SQORJO0ElJ1XNzNrK5Xspy6pM1lAvz4ibk3F76S0Sl3e/d1UPhsofbq9aSprqLxReQf1nwETgC0lPU72RPgnOddpZtZslcqpp94sVwIvRsTvSt6aAByV9o8C7igpP1KZnYB5KU0zERgsqYekHsDgVNaovNMvLwD/DmxNNrHly7ifuplVoQoukrEL8EPgeUlTUtnpwEhgXOos8gZQN8jgLrKeLzPIujQeAxARcySdA0xKx/0mIuY0VXneQf3JiOhPFtwBSCNK++dcr5lZs1RqUFFEPEbDs7PvXs/xAZzUwLXGAGOaU39eE3ptSPaUtouk7fjiA3YD1syjTjOz1ijKNAF5tdT3JOtovylQmlOaT/ZniJlZVSlITM9tQq9rgGskHRwRt+RRh5lZJRWlpZ73Q8vtJXWve5Ge4p6bc51mZs1WlAm98g7qQyJibt2LNNR175zrNDNrtuaMKK1mefd+qZW0ekR8CiCpC7B6znWamTVbUdIveQf164EHJNUtc34MX0xoY2ZWNQoS0/MN6hFxvqTngD1S0TkR0eSIKDOztuaWevleBBZHxP2S1pTUNU1HaWZWNQoS03OfT30ocDNweSraBLg9zzrNzFqiKA9K8+79chLZPAjzASLiVWCDnOs0M2u2Ss7S2J7yTr98GhGf1f0jSOoEXqbOzKpPtQfrcuXdUv+rpNPJ5oAZBIwH/pJznWZmzebBR+UZAbwHPA8cD9wVEf+Zc51mZs3m9Et5TomIi4DRdQWSfprKzMyqRpXH6rLl3VI/qp6yo3Ou08ys2YrS+yWv+dQPB74P9JE0oeStrkCTK3eYmbW1moI01fNKvzwBvAWsB1xYUr4AmJpTnWZmLVaQmJ7bfOpvkK3Bt7OkzYG+aURpF6ALWXA3M6sa1f4AtFxtPaJ0Uzyi1MyqUI3K36pZ3r1fTgK+CfwNshGlkjyi1MyqTrU/AC2XR5SamQHCQb0cK44oPRGPKDWzKlSQhnrbjygFzsi5TjOzZvOI0jJExFJJtwO3R8R7edZlZtYaVR6ry5ZLS12ZsyW9D7wMvCzpPUln5lGfmVlr1Uhlb9Usr/TLaWTzqO8QET0joiewI7CLpNNyqtPMrMWKMk1AXkH9h8DhEfF6XUFEvAb8ADgypzrNzFqsKFPv5pVT7xwR769YGBHvSeqcU51mZi1W7WmVcuUV1D9r4XtmZu2iGCG9kaAu6WIaGSgUET9p5LrfkDS/vssCa5R/e2ZmbaOSXRUljQH2Ad6NiK+msrOBoWTdvAFOj4i70nu/Ao4DlgA/iYiJqXwv4CKgFrgiIkY2VXdjLfXJLfo0QETUtvRcM7P2UOHnn1cDlwDXrlD++4i4oLRA0jbAYcC2wMbA/ZK+nN6+FBgEzAImSZoQEdMbq7jBoB4R1zTnE5iZdWSV7NUSEY9I6l3m4fsDN0XEp8DrkmaQzZkFMCN1MkHSTenYlgX1OpLWB4YD21CSOomI3cq8YTOzqtec9IukYcCwkqJRETGqjFNPlnQkWSbk5xHxIbAJ8FTJMbNSGcCbK5Tv2FQF5XRpvB54EegD/BqYCUwq4zwzsw6jOVPvRsSoiBhQspUT0C8DtgT6kS0idGGjR7f0c5RxzLoRcSXweUT8NSKOBdxKN7NCyXvul4h4JyKWRMRSYDRfpFhmA5uVHLppKmuovFHlBPXP09e3JH1X0nZAzzLOMzPrMNSMrUXXlzYqeXkgMC3tTwAOk7S6pD5AX+DvZBmRvpL6SFqN7GFq6ZrP9Sqnn/q5ktYBfg5cDHQjmwbAzKwwaiv4oFTSjcBAYD1Js4CzgIGS+pF1FZ9JNnMtEfGCpHFkD0AXAydFxJJ0nZOBiWRdGsdExAtN1h1RnWtWfLLYi2nYyuYv+rzpg2yVs0HXzq2OyMPGv1B2zBl1yLZVO1apnN4vV1HPIKSUWzczK4SCzBJQVvrlzpL9NchyQf/K53bMzNrHKjP3S0TcUvo65Yoey+2OzMzaQUFieosm9OoLbFDpGzErx+a7+hm9rWzRs5e0+hrVvkxducrJqS9g+Zz622QjTM3MCqN2VQnqEdG1LW7EzKw9VfmCRmVrcvCRpAfKKTMz68iaM01ANWtsPvU1gDXJOs/34IuBVN34YrIZM7NCWBVy6scDp5LN7/s0XwT1+WTzBJuZFUa1t8DL1dh86hcBF0k6JSIubsN7MjNrcwVpqJc1oddSSd3rXkjqIenE/G7JzKztdZLK3qpZOUF9aETMrXuRJnUfmtsdmZm1A6n8rZqVM/ioVpIizfwlqRZYLd/bMjNrW6vMNAHAPcBYSZen18cDd+d3S2Zmba8gMb2soD6cbC2+E9LrqcCGud2RmVk7KHzvlzoRsVTS38jW1jsUWA+4pfGzzMw6lkouktGeGht89GXg8LS9D4wFiIjvtM2tmZm1nYLE9EZb6i8BjwL7RMQMAEmeIs/MCkktXn20ujTWpfEg4C3gIUmjJe1Oy9dcNTOrakWZ+6XBoB4Rt0fEYcBXgIfIpgzYQNJlkga30f2ZmbWJwgf1OhHxcUTcEBH7ApsCz+L51M2sYCSVvVWzZq18lEaTjkqbmVlh1JYzvr4DaMlydmZmhbMqjSg1Myu8as+Vl8tB3cyMVWuaADOzwqspSI9tB3UzM9xSNzMrlE4FSao7qJuZ4Za6mVmhFKVLY0G625uZtU4ll7OTNEbSu5KmlZT1lHSfpFfT1x6pXJL+KGmGpKmS+pecc1Q6/lVJR5XzORzUzczIgmG5WxmuBvZaoWwE8EBE9AUeSK8BhgB90zYMuAyyXwLAWcCOwDeBs+p+ETT1OczMVnk1UtlbUyLiEWDOCsX7A9ek/WuAA0rKr43MU0B3SRsBewL3RcScNEXLfaz8i2IlzqmbmdG8nLqkYWSt6jqjIqKpObF6RcRbaf9toFfa3wR4s+S4WamsofJGOaibmdG8xSJSAG/xxIYREZKipec3xukXMzMq+6C0Ae+ktArp67upfDawWclxm6ayhsob5aBuZkabzKc+AajrwXIUcEdJ+ZGpF8xOwLyUppkIDJbUIz0gHZzKGuX0i5kZlW3hSroRGAisJ2kWWS+WkcA4SccBbwCHpsPvAvYGZgALgWMAImKOpHOASem430TEig9fV+KgbmZGZQcfRcThDby1ez3HBnBSA9cZA4xpTt0O6mZmUPXL1JXLQd3MjOI8YHRQNzPDLXUzs0IpRkh3UDczA6DWLXUzs+IoSEx3UDczA1BBEjAO6mZmuKVuZlYoNW6pm5kVh1vqZmYFUpQ1Sh3UzcyAmmLEdAd1MzNw7xczs0IpSPbFQb3aDRm0G2uutRa1NTXUdqrlxnG3tvctWU427dWdK845kg3W7UoEjLnlcS698WGuG3kMfXtny1l279qFuQsWsdNhIzlsyABOPWqPZed/re/G7Hz4+Ux9ZTZ3XHIiG67fjU61tTz+7D849byxLF2ay+ppheGWurWZK666hh49erb3bVjOFi9Zyojf3cqUl2ax9pqr88QNw3ngby/xwxFXLTtm5M8OZN5HiwC46e7J3HT3ZAC23Wpjxv1uKFNfyVY7+8HwMSz4+BMAbrzgRxw8qD/jJz7dxp+oYylKTr0os02adXhvvz+fKS/NAuCjhZ/y0utvs/H63Zc75uBB/Rl3z8rB+dC9tmf8xGeWva4L6J061dC5Uy3ZOgzWmBqp7K2aVTyoS1ogaX5DW6XrKzzBCUOP47BDDuLmcWPb+26sjXxpo57023pTJk2buaxsl/5b8s6cBfzjn++tdPz3Bvdn3D2TlyubcOlJ/POBkXy08FNuvf/ZvG+5w1MztmpW8aAeEV0johtwETAC2IRsFezhwB8aO1fSMEmTJU2+cvSoSt9ah3T1dTcy9ubbuPRPoxl74/U8PXlS0ydZh7ZWl9W48YIf8csLblnW4gY4dK8BjF8hcAPs8NXNWfjJ50z/x1vLle930qX0GXQ6q6/WiYE7bJ37fXd0bqk3bb+I+N+IWBAR8yPiMmD/xk6IiFERMSAiBhw3dFiOt9Zx9OqVPSBbd9112W2PQUx7fmo735HlqVOnGm68YChj757MHQ8+t6y8traG/Xf7BjeXpFjqHLLn9iu10ut8+tli/vLwVPYd+LXc7rko3FJv2seSjpBUK6lG0hHAxznWVzgLFy7k448/Wrb/5BOPs9VWfdv5rixPfzrrCF5+/W3++OcHlyvfbceteWXmO8x+d+5y5ZI4ePDyD0HX6rIaG67XDch+GQz59ra8PPOd3O+9wytIVM+z98v3yVIwFwEBPJ7KrExzPviA036SLTK+eMkS9v7uPuzyb7u2811ZXr7VbwuO2GdHnn9lNk/dNAKAsy6ZwMTHpqfW+MoPSL/dfytmvf0hM2d/sKxsrS6rc/Mfjme1zp2oqRGPTH6V0Tc/1mafo6Oq9rRKuVStT8U/WUx13pi1qx47nNzet2BVaNGzl7Q6Ik96bV7ZMWeHLdap2t8AuaVfJH1Z0gOSpqXXX5d0Rl71mZm1SkHSL3nm1EcDvwI+B4iIqcBhOdZnZtZiasZ/1SzPnPqaEfF3LZ+nWpxjfWZmLVaQlHquQf19SVuSPSRF0veAtxo/xcysfRQkpuca1E8CRgFfkTQbeB04Isf6zMxaTAVpqucZ1CMi9pC0FlATEQsk9cmxPjOzFitITM/1QektABHxcUQsSGU351ifmVmLFaTzS+Vb6pK+AmwLrCPpoJK3ugFrVLo+M7OKqGC0ljQTWAAsARZHxABJPYGxQG9gJnBoRHyoLO9zEbA3sBA4OiJWng+iTHmkX7YG9gG6A/uWlC8AhuZQn5lZq+XQVfE7EfF+yesRwAMRMVLSiPR6ODAE6Ju2HYHL0tcWqXhQj4g7gDsk7RwRT1b6+mZmeWiDnPr+wMC0fw3wMFlQ3x+4NrLh/U9J6i5po4hoUW/BPHPqJ0jqXvdCUg9JY3Ksz8ysxaTytzIEcK+kpyXVTTnbqyRQvw30SvubAG+WnDsrlbVInr1fvh4Rc+tepNzRdjnWZ2bWYs1Jv6RAXTo/+KiIKF0E4tsRMVvSBsB9kl4qPT8iQlIu81vlGdRrJPWIiA8B0kMCr4lqZlWpOemXFMAbXMknImanr+9Kug34JvBOXVpF0kbAu+nw2cBmJadvmspaJM/0y4XAk5LOkXQO8ATwPznWZ2bWYpXq0ihpLUld6/aBwcA0YAJwVDrsKOCOtD8BOFKZnYB5Lc2nQ44t54i4VtJkYLdUdFBETM+rPjOzVqncg9JewG1phGon4IaIuEfSJGCcpOOAN4BD0/F3kXVnnEHWpfGY1lSedzqkJ/BxRFwlaX1JfSLi9ZzrNDNrtkotkhERrwHfqKf8A2D3esqDbFqVisgtqEs6CxhA1m/9KqAz8Gdgl7zqNDNrqWofKVquPHPqBwL7kdYljYh/AV1zrM/MrOUKMk9AnumXz0q77aQHBmZmVanaF78oV54t9XGSLge6SxoK3A9ckWN9ZmYtVuHBR+0mz94vF0gaBMwny6ufGRH35VWfmVlrVHmsLlueD0rPj4jhwH31lJmZVZWiLJKRZ/plUD1lQ3Ksz8ysxZx+aYCkHwMnAltImlryVlfg8UrXZ2ZWCVUeq8uWR/rlBuBu4Dyy+YLrLIiIOTnUZ2bWegWJ6hVPv0TEvIiYGRGHk01Ss1tEvEE2wZfXKDWzqqRm/FfN2nJE6Wp4RKmZValqz5WXK8/BRwcC2wHPQDaitG7mMjOzalPjoN4kjyg1sw6kGFG9rUeUjs6xPjOzFnOXxiZ4RKmZdSRVHqvLlueD0u7AXGAc8EpEzMurLjOz1qr2Fni58hh8tDpwOXAA8BpZimfztE7fCRHxWaXrNDNrLU8T0LD/JFsQY7OI6B8R/YAvkf0C+a8c6jMza7WCTKeeS1A/CBgaEQvqCtL+iWTdHM3Mqo4flDZsaUQsXLEwIj6q695oZlZtqn2kaLnyCOohqQf1/5WyNIf6zMxarxgxPZegvg7wNPX/E7mlbmZVqSAxvfJBPSJ6V/qaZmZ5q6n2ZHmZ8pwmwMyswyhITM91mgAzM2tjbqmbmeGWelkkfVvSMWl/fS+SYWbVyotkNKGeRTI640UyzKxKFaWl7kUyzMxwUC+HF8kwsw6j2tMq5fIiGWZmeO6XJnmRDDPrSKo8Vpct1y6NKYg7kJtZ9StIVM8t/SLpIEmvSponab6kBZLm51WfmVlr1Ehlb9VMEfnMsSVpBrBvRLyYSwWrEEnDImJUe9+HVRf/XFh98nxQ+o4DesUMa+8bsKrknwtbSZ459cmSxgK3A5/WFUbErTnWaWa2SsszqHcDFgKDS8oCcFA3M8tJnl0aj8nr2qsg502tPv65sJXk+aB0U+Bivpjr5VHgpxExK5cKzcws1welVwETgI3T9pdUZmZmOcmzpT4lIvo1VWZmZpWTZ0v9A0k/kFSbth8AH+RYX7uTtETSFEkvSHpO0s8lNfpvLKm3pO+3os6jJW3czHN6S5rW0jpXVZJC0oUlr38h6eyc65wp6fm0TZd0rqQ1mjinu6QTW1HnAZK2acF5H7W0TqucPIP6scChwNvAW8D3gKI/PF0UEf0iYltgEDAEOKuJc3oDLQ7qwNFk6S3L36fAQZLWa+N6vxMRXwO+CWwBXN7E8d2BFgd14ACg2UHdqkNuQT0i3oiI/SJi/YjYICIOiIh/5lVftYmId8kGh5ysTK2k30qaJGmqpOPToSOBf0st/NMaOQ5Jw1OL7TlJIyV9j2whkuvT+V0kbS/pr5KeljRR0kbp3O3Tec8BJ7XxP0dRLCbrcXLaim+kv34eTN+zByR9KZVfLemPkp6Q9Fr6ntWd88uS7/Ovm6o8Ij4CTgAOkNSzkWuMBLZMPxO/bawuSUemsuckXSfpW8B+wG/T+Vum7Z70M/WopK+kc/tIejL9TJ7bsn9Sq7iIqOgGnNnI9l+Vrq+aNuCjesrmAr3IAvwZqWx1YDLQBxgI3FlyfEPHDQGeANZM7/VMXx8GBqT9zumY9dPr/wDGpP2pwK5p/7fAtPb+9+poG/AR2fiLmcA6wC+As9N7fwGOSvvHAren/auB8WQNqG2AGal8MNkvCKX37qz7/qxQ50xgvRXKpgA7NnQNsr/+ppUc39Bx2wKv1F2/5GfqauB7Jec/APRN+zsCD6b9CcCRaf+k+n7+vbX9lkc/9Y/rKVsLOA5YFzgnhzo7gsHA10taausAfYHPyjxuD+CqiFgIEBFz6qlja+CrwH3KJh2qBd6S1B3oHhGPpOOuI/slYc0UEfMlXQv8BFhU8tbOwEFp/zrgf0reuz0ilgLTJfVKZYPT9mx6vTbZ9/kRmlY3o1RD11jxL+KGjvsGMD4i3k+fbaWfKUlrA98CxuuLiaxWT193AQ5O+9cB55dx75azigf1iCh9kNQV+ClZLv0m4MKGzisiSVsAS4B3yf5HPCUiJq5wzMAVT2vguD3LqRJ4ISJ2XuHc7s26cWvKH8iWaSy3i+6nJfsq+XpeRDSVH19O+n+qN1kLu95rSOq94mkNHHdKGVXWAHOj4V5r+XSfsxbLJacuqWfKsU0l+8XRPyKGR5ZnXiVIWh/4E3BJZH+fTgR+LKlzev/Lypb4WwCUrt3a0HH3AcdIWjOV90zHl57/MrC+pJ3TMZ0lbRsRc4G5kr6djjsilw+9ikgt2nFkf33WeQI4LO0fQTbYrjETgWNTSxhJm0jaoLET0rH/S9by/7CRa9T3M1XfcQ8Ch0haN5Wv9DMVEfOB1yUdko6RpG+k4x5f4TNbNah0PocsX/sPYDiwdnvnl9pyI2uVTwFeAJ4jy7nWpPdqgP8GngemAQ+RpVY6k/3P9RzZA7h6j0vXGAFMT3X8dyo7mCyYTwG6AP3I/oR/Lt3H0HTc9qlsCllqwDn15n9/PyrZ70U2t9HZ6fXm6fs4lSwH/aVUfjXL56dLr/HT9H1+HngS2LKeOmeW/CxMB/4vsEZT1wBuSOf8tonjjkrHPQdcncp2SXU9C2xJ9kznnnTMdLJVzEjlT6Zrnotz6lWxVXzwkaSlZH9uLmb5P80ERER0q2iFZma2TG4jSs3MrO3lOfjIzMzamIO6mVmBOKibmRWIg7qZWYE4qFsu9MWMldMkja/rX9/Ca11dN8JW0hVqZAZBSQPT/CXNrWOm2n6iLrOKc1C3vNTNWPlVsqkQTih9U1KLRjNHxI8iYnojhwwkG9ZutkpyULe28CiwVWpFPyppAtk8KPXOSJlGLV4i6WVJ9wPLRlpKeljSgLS/l6Rn0gyDD6Th8ScAp6W/Ev5N0vqSbkl1TJK0Szp3XUn3Kpv7/gq+GL5v1qHltvC0GSxrkQ8hG5EI0B/4akS8LmkYMC8idpC0OvC4pHuB7cgmJ9uGbOTmdGDMCtddHxhNNrPh65J6RsQcSX8iG9l4QTruBuD3EfGYsulwJwL/h2ye+8ci4jeSvsvyQ/7NOiwHdctLF0lT0v6jwJVkaZG/R8TrqbyhGSl3BW6MiCXAvyQ9WM/1dwIeqbtW1D9rJWSzW25TMsNgtzQHyq6kWRUj4v9J+rBlH9OsujioW14Wxcpr1MLyUzM3NCPl3hW8jxpgp4j4pJ57MSsc59StPTU0I+UjwH+knPtGwHfqOfcpYFdJfdK59c1aCXAvsGyKWUn90u4jpGUEJQ0BelTqQ5m1Jwd1a09XkOXLn1G2EPblZH893ga8mt67lmwmwOVExHtkq0TdqmyJvrHprb8AB9Y9KCVbzGJAehA7nS964fya7JfCC2RpmFVmqUUrNk/oZWZWIG6pm5kViIO6mVmBOKibmRWIg7qZWYE4qJuZFYiDuplZgTiom5kVyP8HRf/EJbRj9WgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_models(model_lst, (X_train2, y_train2, X_test2, y_test2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
